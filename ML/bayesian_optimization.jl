"""
è´å¶æ–¯ä¼˜åŒ–æ¨¡å— (Bayesian Optimization)

å®ç°æŒ‡å¯¼æ–‡æ¡£ç¬¬äºŒå¤§ç‚¹ï¼šç”¨MLä¼˜åŒ–ç®—æ³•æ›¿æ¢ç½‘æ ¼æ‰«æï¼Œé«˜æ•ˆé’ˆå¯¹å¤§å‚æ•°é‡

ä¸»è¦åŠŸèƒ½ï¼š
1. æ™ºèƒ½å‚æ•°æ¢ç´¢ï¼ˆBOSS.jlè´å¶æ–¯ä¼˜åŒ–ï¼‰
2. å¤šç›®æ ‡ä¼˜åŒ–ï¼ˆMOO via ParetoFrontier.jlï¼‰
3. é‡‡é›†å‡½æ•°å¯è§†åŒ–ï¼ˆacquisition functionï¼‰
4. çƒ­åŠ›å­¦å‚æ•°ä¼˜åŒ–
5. 100-500æ¬¡æ¨¡æ‹Ÿ vs æˆåƒä¸Šä¸‡ç½‘æ ¼æ‰«æ

åŸºäºGaussian Processä»£ç†æ¨¡å‹ï¼Œç¬¦åˆé¡¹ç›®é…ç½®è¦æ±‚
"""

# using Pkg
# # æ£€æŸ¥å¹¶å®‰è£…å¿…è¦çš„åŒ…
# try
#     using BOSS
# catch
#     println("ğŸ“¦ å®‰è£…BOSS.jl...")
#     Pkg.add("BOSS")
#     using BOSS
# end

# try 
#     using Optim
# catch
#     println("ğŸ“¦ å®‰è£…Optim.jl...")
#     Pkg.add("Optim")
#     using Optim
# end

using Statistics
using LinearAlgebra
using Random
using Plots
using JLD2
using Printf
using TOML
using Optim
using Surrogates

# å¼•å…¥é¡¹ç›®æ ¸å¿ƒæ¨¡å—
include("surrogate_model.jl")

"""
    load_bayesian_config(config_path::String, section::String="single_objective")

ä»TOMLé…ç½®æ–‡ä»¶åŠ è½½è´å¶æ–¯ä¼˜åŒ–é…ç½®
"""
function load_bayesian_config(config_path::String="config/bayesian_optimization_config.toml", section::String="single_objective")
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if !isfile(config_path)
        println("âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: $config_path")
        println("ä½¿ç”¨é»˜è®¤é…ç½®...")
        return create_default_bayesian_config()
    end
    
    try
        # è¯»å–TOMLé…ç½®
        config_data = TOML.parsefile(config_path)
        
        # è·å–æŒ‡å®šéƒ¨åˆ†çš„é…ç½®
        if !haskey(config_data, section)
            println("âš ï¸  é…ç½®éƒ¨åˆ†ä¸å­˜åœ¨: $section")
            println("ä½¿ç”¨é»˜è®¤é…ç½®...")
            return create_default_bayesian_config()
        end
        
        section_data = config_data[section]
        
        # åˆ›å»ºé…ç½®ç»“æ„ä½“
        config = BayesianOptimizationConfig(
            objective_type = Symbol(get(section_data, "objective_type", "single_objective")),
            optimization_direction = Symbol(get(section_data, "optimization_direction", "maximize")),
            target_variable = Symbol(get(section_data, "target_variable", "C_final")),
            
            # å¤šç›®æ ‡é…ç½®
            multi_objectives = [Symbol(obj) for obj in get(section_data, "multi_objectives", ["C_final", "v1_mean"])],
            multi_weights = Vector{Float64}(get(section_data, "multi_weights", [0.7, 0.3])),
            
            # è´å¶æ–¯ä¼˜åŒ–å‚æ•°
            n_initial_points = get(section_data, "n_initial_points", 20),
            n_iterations = get(section_data, "n_iterations", 50),
            acquisition_function = Symbol(get(section_data, "acquisition_function", "ei")),
            
            # GPè¶…å‚æ•°
            gp_kernel = Symbol(get(get(config_data, "gaussian_process", Dict()), "kernel", "matern52")),
            gp_noise = Float64(get(get(config_data, "gaussian_process", Dict()), "noise_variance", 1e-6)),
            
            # çº¦æŸé…ç½®
            apply_constraints = get(section_data, "apply_constraints", true),
            constraint_penalty = Float64(get(section_data, "constraint_penalty", -1000.0)),
            
            # é‡‡é›†å‡½æ•°å‚æ•°
            exploration_weight = Float64(get(section_data, "exploration_weight", 2.0)),
            improvement_threshold = Float64(get(section_data, "improvement_threshold", 0.01)),
            
            # å¯è§†åŒ–é…ç½®
            plot_acquisition = get(section_data, "plot_acquisition", true),
            plot_convergence = get(section_data, "plot_convergence", true),
            save_intermediate = get(section_data, "save_intermediate", true)
        )
        
        println("âœ… å·²åŠ è½½é…ç½®: $config_path [$section]")
        return config
        
    catch e
        println("âŒ é…ç½®æ–‡ä»¶è§£æå¤±è´¥: $e")
        println("ä½¿ç”¨é»˜è®¤é…ç½®...")
        return create_default_bayesian_config()
    end
end

"""
    create_default_bayesian_config()

åˆ›å»ºé»˜è®¤çš„è´å¶æ–¯ä¼˜åŒ–é…ç½®ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
"""
function create_default_bayesian_config()
    return BayesianOptimizationConfig(
        objective_type = :single_objective,
        optimization_direction = :maximize,
        target_variable = :C_final,
        
        multi_objectives = [:C_final, :v1_mean],
        multi_weights = [0.7, 0.3],
        
        n_initial_points = 20,
        n_iterations = 50,
        acquisition_function = :ei,
        
        gp_kernel = :matern52,
        gp_noise = 1e-6,
        
        apply_constraints = true,
        constraint_penalty = -1000.0,
        
        exploration_weight = 2.0,
        improvement_threshold = 0.01,
        
        plot_acquisition = true,
        plot_convergence = true,
        save_intermediate = true
    )
end

"""
    load_parameter_space_from_config(config_path::String)

ä»TOMLé…ç½®æ–‡ä»¶åŠ è½½å‚æ•°ç©ºé—´é…ç½®
"""
function load_parameter_space_from_config(config_path::String="config/bayesian_optimization_config.toml")
    if !isfile(config_path)
        println("âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°ç©ºé—´")
        return create_default_parameter_space()
    end
    
    try
        config_data = TOML.parsefile(config_path)
        
        # æå–å‚æ•°ç©ºé—´é…ç½®
        param_config = get(config_data, "parameter_space", Dict())
        rates_config = get(param_config, "rates", Dict())
        init_config = get(param_config, "initial_conditions", Dict())
        time_config = get(param_config, "time", Dict())
        
        # åˆ›å»ºå‚æ•°ç©ºé—´
        # å®‰å…¨è¯»å–åŒºé—´çš„å¸®åŠ©å‡½æ•°
        get_range(d::Dict, key::AbstractString, dmin, dmax) = begin
            sub = get(d, key, Dict())
            (Float64(get(sub, "min", dmin)), Float64(get(sub, "max", dmax)))
        end

        param_space = ParameterSpace(
            # ååº”é€Ÿç‡å¸¸æ•°èŒƒå›´
            k1f_range = get_range(rates_config, "k1f", 0.1, 20.0),
            k1r_range = get_range(rates_config, "k1r", 0.1, 20.0),
            k2f_range = get_range(rates_config, "k2f", 0.1, 20.0),
            k2r_range = get_range(rates_config, "k2r", 0.1, 20.0),
            k3f_range = get_range(rates_config, "k3f", 0.1, 20.0),
            k3r_range = get_range(rates_config, "k3r", 0.1, 20.0),
            k4f_range = get_range(rates_config, "k4f", 0.1, 20.0),
            k4r_range = get_range(rates_config, "k4r", 0.1, 20.0),
            
            # åˆå§‹æ¡ä»¶èŒƒå›´
            A_range = get_range(init_config, "A", 0.1, 20.0),
            B_range = get_range(init_config, "B", 0.0, 5.0),
            C_range = get_range(init_config, "C", 0.0, 5.0),
            E1_range = get_range(init_config, "E1", 1.0, 20.0),
            E2_range = get_range(init_config, "E2", 1.0, 20.0),
            
            # æ—¶é—´èŒƒå›´
            tspan = (Float64(get(time_config, "t0", 0.0)), Float64(get(time_config, "t1", 5.0)))
        )
        
        println("âœ… å·²åŠ è½½å‚æ•°ç©ºé—´é…ç½®")
        return param_space
        
    catch e
        println("âŒ å‚æ•°ç©ºé—´é…ç½®åŠ è½½å¤±è´¥: $e")
        println("ä½¿ç”¨é»˜è®¤å‚æ•°ç©ºé—´")
        return create_default_parameter_space()
    end
end

"""
    BayesianOptimizationConfig

è´å¶æ–¯ä¼˜åŒ–é…ç½®ç»“æ„ä½“
"""
Base.@kwdef struct BayesianOptimizationConfig
    # ä¼˜åŒ–ç›®æ ‡é…ç½®
    objective_type::Symbol = :single_objective  # :single_objective, :multi_objective
    optimization_direction::Symbol = :maximize  # :maximize, :minimize
    target_variable::Symbol = :C_final          # å•ç›®æ ‡ä¼˜åŒ–çš„ç›®æ ‡å˜é‡
    
    # å¤šç›®æ ‡é…ç½®
    multi_objectives::Vector{Symbol} = [:C_final, :v1_mean]  # å¤šç›®æ ‡ä¼˜åŒ–å˜é‡
    multi_weights::Vector{Float64} = [0.7, 0.3]             # å¤šç›®æ ‡æƒé‡
    
    # è´å¶æ–¯ä¼˜åŒ–å‚æ•°
    n_initial_points::Int = 20        # åˆå§‹æ¢ç´¢ç‚¹æ•°
    n_iterations::Int = 50            # ä¼˜åŒ–è¿­ä»£æ¬¡æ•°
    acquisition_function::Symbol = :ei  # :ei (Expected Improvement), :ucb, :poi
    
    # GPè¶…å‚æ•°
    gp_kernel::Symbol = :matern52     # :matern52, :rbf, :matern32
    gp_noise::Float64 = 1e-6         # GPå™ªå£°æ–¹å·®
    
    # çº¦æŸé…ç½®
    apply_constraints::Bool = true    # æ˜¯å¦åº”ç”¨çº¦æŸ
    constraint_penalty::Float64 = -1000.0  # çº¦æŸè¿åæƒ©ç½š
    
    # é‡‡é›†å‡½æ•°å‚æ•°
    exploration_weight::Float64 = 2.0  # UCBæ¢ç´¢æƒé‡
    improvement_threshold::Float64 = 0.01  # POIæ”¹è¿›é˜ˆå€¼
    
    # å¯è§†åŒ–é…ç½®
    plot_acquisition::Bool = true     # æ˜¯å¦ç»˜åˆ¶é‡‡é›†å‡½æ•°
    plot_convergence::Bool = true     # æ˜¯å¦ç»˜åˆ¶æ”¶æ•›æ›²çº¿
    save_intermediate::Bool = true    # æ˜¯å¦ä¿å­˜ä¸­é—´ç»“æœ
end

"""
    BayesianOptimizer

è´å¶æ–¯ä¼˜åŒ–å™¨ä¸»ç»“æ„ä½“
"""
mutable struct BayesianOptimizer
    config::BayesianOptimizationConfig
    param_space::ParameterSpace
    surrogate_model::Union{Nothing, SurrogateModel}
    
    # ä¼˜åŒ–å†å²
    X_evaluated::Matrix{Float64}      # å·²è¯„ä¼°çš„å‚æ•°ç‚¹
    y_evaluated::Vector{Float64}      # å·²è¯„ä¼°çš„ç›®æ ‡å€¼
    y_multi_evaluated::Matrix{Float64} # å¤šç›®æ ‡è¯„ä¼°å€¼
    # çƒ­åŠ›å­¦é€šé‡ç»Ÿè®¡ï¼ˆæ¯æ¬¡è¯„ä¼°ç‚¹çš„å‡å€¼ï¼‰
    thermo_v1_mean_history::Vector{Float64}
    thermo_v2_mean_history::Vector{Float64}
    
    # GPæ¨¡å‹çŠ¶æ€
    gp_model::Any
    acquisition_history::Vector{Float64}
    
    # æœ€ä¼˜ç»“æœ
    best_x::Vector{Float64}
    best_y::Float64
    best_params::Dict{Symbol, Float64}
    
    # æ„é€ å‡½æ•°
    function BayesianOptimizer(config::BayesianOptimizationConfig, param_space::ParameterSpace)
        new(config, param_space, nothing,
            Matrix{Float64}(undef, 0, 0), Float64[], Matrix{Float64}(undef, 0, 0),
            Float64[], Float64[],
            nothing, Float64[],
            Float64[], 0.0, Dict{Symbol, Float64}())
    end
end

"""
    create_objective_function(optimizer::BayesianOptimizer)

åˆ›å»ºé»‘ç›’ç›®æ ‡å‡½æ•°ï¼ˆåŒ…è£…ä»¿çœŸï¼‰
"""
function create_objective_function(optimizer::BayesianOptimizer)
    config = optimizer.config
    param_space = optimizer.param_space
    
    function objective(x::Vector{Float64})
        try
            # æ£€æŸ¥çº¦æŸ
            if config.apply_constraints
                if !check_parameter_constraints(x, param_space, config)
                    # è®°å½•å ä½ä»¥ä¿æŒé•¿åº¦ä¸€è‡´
                    push!(optimizer.thermo_v1_mean_history, NaN)
                    push!(optimizer.thermo_v2_mean_history, NaN)
                    return config.constraint_penalty
                end
            end
            
            # å‚æ•°å‘é‡è½¬æ¢ä¸ºå­—å…¸
            params_dict = vector_to_params_dict(x, param_space)
            
            # æ„å»ºåˆå§‹æ¡ä»¶
            initial_conditions = [
                A   => params_dict[:A],
                B   => params_dict[:B], 
                C   => params_dict[:C],
                E1  => params_dict[:E1],
                E2  => params_dict[:E2],
                AE1 => 0.0,
                BE2 => 0.0
            ]
            
            # æå–ååº”é€Ÿç‡å¸¸æ•°
            rate_params = Dict(
                :k1f => params_dict[:k1f], :k1r => params_dict[:k1r],
                :k2f => params_dict[:k2f], :k2r => params_dict[:k2r], 
                :k3f => params_dict[:k3f], :k3r => params_dict[:k3r],
                :k4f => params_dict[:k4f], :k4r => params_dict[:k4r]
            )
            
            # è¿è¡Œä»¿çœŸ
            sol = simulate_system(rate_params, initial_conditions, param_space.tspan, saveat=0.1)
            
            # æå–ç›®æ ‡å˜é‡
            target_values = extract_target_variables(sol, rate_params, [config.target_variable])
            
            objective_value = target_values[1]

            # è®¡ç®—å¹¶è®°å½•çƒ­åŠ›å­¦é€šé‡å‡å€¼
            try
                thermo = calculate_thermo_fluxes(sol, rate_params)
                v1m = mean(thermo["v1_thermo"]) |> float
                v2m = mean(thermo["v2_thermo"]) |> float
                push!(optimizer.thermo_v1_mean_history, v1m)
                push!(optimizer.thermo_v2_mean_history, v2m)
            catch
                push!(optimizer.thermo_v1_mean_history, NaN)
                push!(optimizer.thermo_v2_mean_history, NaN)
            end
            
            # å¤„ç†ä¼˜åŒ–æ–¹å‘
            if config.optimization_direction == :minimize
                objective_value = -objective_value
            end
            
            return isfinite(objective_value) ? objective_value : config.constraint_penalty
            
        catch e
            println("âš ï¸  ç›®æ ‡å‡½æ•°è¯„ä¼°å¤±è´¥: $e")
            push!(optimizer.thermo_v1_mean_history, NaN)
            push!(optimizer.thermo_v2_mean_history, NaN)
            return config.constraint_penalty
        end
    end
    
    return objective
end

"""
    create_multi_objective_function(optimizer::BayesianOptimizer)

åˆ›å»ºå¤šç›®æ ‡ä¼˜åŒ–å‡½æ•°
"""
function create_multi_objective_function(optimizer::BayesianOptimizer)
    config = optimizer.config
    param_space = optimizer.param_space
    
    function multi_objective(x::Vector{Float64})
        try
            # æ£€æŸ¥çº¦æŸ
            if config.apply_constraints
                if !check_parameter_constraints(x, param_space, config)
                    return fill(config.constraint_penalty, length(config.multi_objectives))
                end
            end
            
            # å‚æ•°è½¬æ¢
            params_dict = vector_to_params_dict(x, param_space)
            
            # æ„å»ºåˆå§‹æ¡ä»¶ 
            initial_conditions = [
                A   => params_dict[:A],
                B   => params_dict[:B],
                C   => params_dict[:C], 
                E1  => params_dict[:E1],
                E2  => params_dict[:E2],
                AE1 => 0.0,
                BE2 => 0.0
            ]
            
            # æå–ååº”é€Ÿç‡å¸¸æ•°
            rate_params = Dict(
                :k1f => params_dict[:k1f], :k1r => params_dict[:k1r],
                :k2f => params_dict[:k2f], :k2r => params_dict[:k2r],
                :k3f => params_dict[:k3f], :k3r => params_dict[:k3r], 
                :k4f => params_dict[:k4f], :k4r => params_dict[:k4r]
            )
            
            # è¿è¡Œä»¿çœŸ
            sol = simulate_system(rate_params, initial_conditions, param_space.tspan, saveat=0.1)
            
            # æå–å¤šä¸ªç›®æ ‡å˜é‡
            target_values = extract_target_variables(sol, rate_params, config.multi_objectives)

            # è®°å½•çƒ­åŠ›å­¦é€šé‡å‡å€¼ï¼ˆä½œä¸ºè¾…åŠ©åˆ†æï¼Œä¸å‚ä¸ç›®æ ‡è®¡ç®—ï¼‰
            try
                thermo = calculate_thermo_fluxes(sol, rate_params)
                v1m = mean(thermo["v1_thermo"]) |> float
                v2m = mean(thermo["v2_thermo"]) |> float
                push!(optimizer.thermo_v1_mean_history, v1m)
                push!(optimizer.thermo_v2_mean_history, v2m)
            catch
                push!(optimizer.thermo_v1_mean_history, NaN)
                push!(optimizer.thermo_v2_mean_history, NaN)
            end
            
            # å¤„ç†ä¼˜åŒ–æ–¹å‘
            if config.optimization_direction == :minimize
                target_values = -target_values
            end
            
            # æ£€æŸ¥æœ‰æ•ˆæ€§
            if all(isfinite.(target_values))
                return target_values
            else
                return fill(config.constraint_penalty, length(config.multi_objectives))
            end
            
        catch e
            println("âš ï¸  å¤šç›®æ ‡å‡½æ•°è¯„ä¼°å¤±è´¥: $e")
            push!(optimizer.thermo_v1_mean_history, NaN)
            push!(optimizer.thermo_v2_mean_history, NaN)
            return fill(config.constraint_penalty, length(config.multi_objectives))
        end
    end
    
    return multi_objective
end

"""
    check_parameter_constraints(x::Vector{Float64}, param_space::ParameterSpace, config::BayesianOptimizationConfig)

æ£€æŸ¥å‚æ•°çº¦æŸï¼ˆçƒ­åŠ›å­¦çº¦æŸç­‰ï¼‰
"""
function check_parameter_constraints(x::Vector{Float64}, param_space::ParameterSpace, config::BayesianOptimizationConfig)
    # åŸºæœ¬è¾¹ç•Œçº¦æŸ
    ranges = get_parameter_ranges(param_space)
    
    for (i, val) in enumerate(x)
        range_min, range_max = minimum(ranges[i]), maximum(ranges[i])
        if val < range_min || val > range_max
            return false
        end
    end
    
    # çƒ­åŠ›å­¦çº¦æŸï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if config.apply_constraints
        params_dict = vector_to_params_dict(x, param_space)
        
        # æ£€æŸ¥å¹³è¡¡å¸¸æ•°èŒƒå›´
        Keq1 = (params_dict[:k1f] * params_dict[:k2f]) / (params_dict[:k1r] * params_dict[:k2r])
        Keq2 = (params_dict[:k3f] * params_dict[:k4f]) / (params_dict[:k3r] * params_dict[:k4r])
        
        if !(0.01 <= Keq1 <= 100.0) || !(0.01 <= Keq2 <= 100.0)
            return false
        end
    end
    
    return true
end

"""
    vector_to_params_dict(x::Vector{Float64}, param_space::ParameterSpace)

å°†å‚æ•°å‘é‡è½¬æ¢ä¸ºå‚æ•°å­—å…¸
"""
function vector_to_params_dict(x::Vector{Float64}, param_space::ParameterSpace)
    param_names = [:k1f, :k1r, :k2f, :k2r, :k3f, :k3r, :k4f, :k4r, :A, :B, :C, :E1, :E2]
    
    params_dict = Dict{Symbol, Float64}()
    for (i, name) in enumerate(param_names)
        params_dict[name] = x[i]
    end
    
    return params_dict
end

"""
    get_parameter_ranges(param_space::ParameterSpace)

è·å–å‚æ•°èŒƒå›´
"""
function get_parameter_ranges(param_space::ParameterSpace)
    return [
        param_space.k1f_range, param_space.k1r_range,
        param_space.k2f_range, param_space.k2r_range,
        param_space.k3f_range, param_space.k3r_range,
        param_space.k4f_range, param_space.k4r_range,
        param_space.A_range, param_space.B_range,
        param_space.C_range, param_space.E1_range, param_space.E2_range
    ]
end

"""
    initialize_optimizer!(optimizer::BayesianOptimizer)

åˆå§‹åŒ–è´å¶æ–¯ä¼˜åŒ–å™¨
"""
function initialize_optimizer!(optimizer::BayesianOptimizer)
    config = optimizer.config
    param_space = optimizer.param_space
    
    println("ğŸš€ åˆå§‹åŒ–è´å¶æ–¯ä¼˜åŒ–å™¨...")
    println("ğŸ“Š ç›®æ ‡ç±»å‹: $(config.objective_type)")
    println("ğŸ¯ ä¼˜åŒ–æ–¹å‘: $(config.optimization_direction)")
    
    if config.objective_type == :single_objective
        println("ğŸ“ˆ ç›®æ ‡å˜é‡: $(config.target_variable)")
    else
        println("ğŸ“ˆ å¤šç›®æ ‡å˜é‡: $(config.multi_objectives)")
        println("âš–ï¸  ç›®æ ‡æƒé‡: $(config.multi_weights)")
    end
    
    # ç”Ÿæˆåˆå§‹æ¢ç´¢ç‚¹
    println("ğŸ” ç”Ÿæˆ$(config.n_initial_points)ä¸ªåˆå§‹æ¢ç´¢ç‚¹...")
    
    ranges = get_parameter_ranges(param_space)
    n_dims = length(ranges)
    
    # ä½¿ç”¨LHSé‡‡æ ·ç”Ÿæˆåˆå§‹ç‚¹
    X_init = zeros(config.n_initial_points, n_dims)
    
    Random.seed!(42)  # å¯é‡ç°æ€§
    for i in 1:n_dims
        # LHSé‡‡æ ·
        lhs_samples = (randperm(config.n_initial_points) .- 1 .+ rand(config.n_initial_points)) ./ config.n_initial_points
        range_min, range_max = minimum(ranges[i]), maximum(ranges[i])
        X_init[:, i] = range_min .+ lhs_samples .* (range_max - range_min)
    end
    
    # è¿‡æ»¤æ»¡è¶³çº¦æŸçš„ç‚¹
    valid_indices = []
    for i in 1:size(X_init, 1)
        if check_parameter_constraints(X_init[i, :], param_space, config)
            push!(valid_indices, i)
        end
    end
    
    if length(valid_indices) < config.n_initial_points Ã· 2
        println("âš ï¸  çº¦æŸè¿‡äºä¸¥æ ¼ï¼Œæœ‰æ•ˆåˆå§‹ç‚¹æ•°: $(length(valid_indices))")
    end
    
    # ä¿ç•™æœ‰æ•ˆç‚¹
    X_valid = X_init[valid_indices, :]
    n_valid = size(X_valid, 1)
    
    # è¯„ä¼°åˆå§‹ç‚¹
    println("ğŸ§ª è¯„ä¼°åˆå§‹ç‚¹...")
    
    if config.objective_type == :single_objective
        objective_fn = create_objective_function(optimizer)
        y_init = zeros(n_valid)
        
        for i in 1:n_valid
            y_init[i] = objective_fn(X_valid[i, :])
            if i % 5 == 0
                println("  è¿›åº¦: $i/$n_valid")
            end
        end
        
        optimizer.y_evaluated = y_init
        
    else
        multi_objective_fn = create_multi_objective_function(optimizer)
        y_multi_init = zeros(n_valid, length(config.multi_objectives))
        
        for i in 1:n_valid
            y_multi_init[i, :] = multi_objective_fn(X_valid[i, :])
            if i % 5 == 0
                println("  è¿›åº¦: $i/$n_valid")
            end
        end
        
        optimizer.y_multi_evaluated = y_multi_init
        
        # è®¡ç®—åŠ æƒå•ç›®æ ‡å€¼
        y_weighted = y_multi_init * config.multi_weights
        optimizer.y_evaluated = y_weighted
    end
    
    optimizer.X_evaluated = X_valid
    
    # æ‰¾åˆ°å½“å‰æœ€ä¼˜ç‚¹
    best_idx = argmax(optimizer.y_evaluated)
    optimizer.best_x = X_valid[best_idx, :]
    optimizer.best_y = optimizer.y_evaluated[best_idx]
    optimizer.best_params = vector_to_params_dict(optimizer.best_x, param_space)
    
    println("âœ… åˆå§‹åŒ–å®Œæˆ")
    println("ğŸ“Š æœ‰æ•ˆåˆå§‹ç‚¹æ•°: $n_valid")
    println("ğŸ† åˆå§‹æœ€ä¼˜å€¼: $(round(optimizer.best_y, digits=4))")
    
    return optimizer
end

"""
    run_bayesian_optimization!(optimizer::BayesianOptimizer)

è¿è¡Œè´å¶æ–¯ä¼˜åŒ–ä¸»å¾ªç¯
"""
function run_bayesian_optimization!(optimizer::BayesianOptimizer)
    config = optimizer.config
    param_space = optimizer.param_space
    
    println("\nğŸ¯ å¼€å§‹è´å¶æ–¯ä¼˜åŒ–...")
    println("ğŸ”„ ä¼˜åŒ–è¿­ä»£æ•°: $(config.n_iterations)")
    println("ğŸ“ é‡‡é›†å‡½æ•°: $(config.acquisition_function)")
    
    # åˆ›å»ºç›®æ ‡å‡½æ•°
    if config.objective_type == :single_objective
        objective_fn = create_objective_function(optimizer)
    else
        multi_objective_fn = create_multi_objective_function(optimizer)
    end
    
    # ä¼˜åŒ–å¾ªç¯
    for iter in 1:config.n_iterations
        println("\n--- è¿­ä»£ $iter/$(config.n_iterations) ---")
        
        # 1. æ‹ŸåˆGPæ¨¡å‹
        gp_model = fit_gp_model(optimizer)
        optimizer.gp_model = gp_model
        
        # 2. ä¼˜åŒ–é‡‡é›†å‡½æ•°æ‰¾åˆ°ä¸‹ä¸€ä¸ªå€™é€‰ç‚¹
        next_x = optimize_acquisition_function(optimizer)
        
        if next_x === nothing
            println("âš ï¸  é‡‡é›†å‡½æ•°ä¼˜åŒ–å¤±è´¥ï¼Œè·³è¿‡æ­¤æ¬¡è¿­ä»£")
            continue
        end
        
        # 3. è¯„ä¼°æ–°ç‚¹
        if config.objective_type == :single_objective
            next_y = objective_fn(next_x)
            
            # æ›´æ–°å†å²è®°å½•
            optimizer.X_evaluated = vcat(optimizer.X_evaluated, next_x')
            optimizer.y_evaluated = vcat(optimizer.y_evaluated, next_y)
            
        else
            next_y_multi = multi_objective_fn(next_x)
            next_y_weighted = dot(next_y_multi, config.multi_weights)
            
            # æ›´æ–°å†å²è®°å½•
            optimizer.X_evaluated = vcat(optimizer.X_evaluated, next_x')
            optimizer.y_multi_evaluated = vcat(optimizer.y_multi_evaluated, next_y_multi')
            optimizer.y_evaluated = vcat(optimizer.y_evaluated, next_y_weighted)
            
            next_y = next_y_weighted
        end
        
        # 4. æ›´æ–°æœ€ä¼˜ç»“æœ
        if next_y > optimizer.best_y
            optimizer.best_x = next_x
            optimizer.best_y = next_y
            optimizer.best_params = vector_to_params_dict(next_x, param_space)
            println("ğŸ‰ å‘ç°æ–°çš„æœ€ä¼˜ç‚¹! ç›®æ ‡å€¼: $(round(next_y, digits=4))")
        else
            println("ğŸ“Š å½“å‰ç‚¹ç›®æ ‡å€¼: $(round(next_y, digits=4))")
        end
        
        # 5. è®°å½•é‡‡é›†å‡½æ•°å€¼
        acquisition_value = evaluate_acquisition_function(optimizer, next_x)
        optimizer.acquisition_history = vcat(optimizer.acquisition_history, acquisition_value)
        
        # 6. ä¸­é—´ç»“æœä¿å­˜
        if config.save_intermediate && iter % 10 == 0
            save_intermediate_results(optimizer, iter)
        end
        
        # 7. è¿›åº¦æŠ¥å‘Š
        improvement = optimizer.best_y - optimizer.y_evaluated[1]
        println("ğŸ“ˆ æœ€ä¼˜å€¼æ”¹å–„: $(round(improvement, digits=4))")
        println("ğŸ“Š å·²è¯„ä¼°ç‚¹æ•°: $(size(optimizer.X_evaluated, 1))")
    end
    
    println("\nğŸ‰ è´å¶æ–¯ä¼˜åŒ–å®Œæˆ!")
    println("ğŸ† æœ€ç»ˆæœ€ä¼˜å€¼: $(round(optimizer.best_y, digits=4))")
    println("ğŸ“Š æ€»è¯„ä¼°æ¬¡æ•°: $(size(optimizer.X_evaluated, 1))")
    
    return optimizer
end

"""
    fit_gp_model(optimizer::BayesianOptimizer)

æ‹ŸåˆGaussian Processæ¨¡å‹
"""
function fit_gp_model(optimizer::BayesianOptimizer)
    X = optimizer.X_evaluated
    y = optimizer.y_evaluated
    config = optimizer.config
    
    # ä½¿ç”¨Surrogates.jlçš„Krigingæ¨¡å‹ï¼ˆGPçš„å®ç°ï¼‰
    try
        # å‡†å¤‡æ•°æ®æ ¼å¼
        X_data = [X[i, :] for i in 1:size(X, 1)]
        
        # å®šä¹‰å‚æ•°è¾¹ç•Œ
        ranges = get_parameter_ranges(optimizer.param_space)
        lower_bounds = [minimum(range) for range in ranges]
        upper_bounds = [maximum(range) for range in ranges]
        
        # åˆ›å»ºGPæ¨¡å‹
        gp_model = Kriging(X_data, y, lower_bounds, upper_bounds)
        
        return gp_model
        
    catch e
        println("âš ï¸  GPæ¨¡å‹æ‹Ÿåˆå¤±è´¥: $e")
        return nothing
    end
end

"""
    optimize_acquisition_function(optimizer::BayesianOptimizer)

ä¼˜åŒ–é‡‡é›†å‡½æ•°å¯»æ‰¾ä¸‹ä¸€ä¸ªå€™é€‰ç‚¹
"""
function optimize_acquisition_function(optimizer::BayesianOptimizer)
    config = optimizer.config
    param_space = optimizer.param_space
    gp_model = optimizer.gp_model
    
    if gp_model === nothing
        return nothing
    end
    
    # å®šä¹‰é‡‡é›†å‡½æ•°
    function acquisition_function(x::Vector{Float64})
        # æ£€æŸ¥çº¦æŸ
        if !check_parameter_constraints(x, param_space, config)
            return -Inf
        end
        
        try
            # GPé¢„æµ‹
            Î¼ = gp_model(x)
            
            # è®¡ç®—ä¸ç¡®å®šæ€§ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…GPä¼šæä¾›æ–¹å·®ï¼‰
            # è¿™é‡Œä½¿ç”¨ä¸å·²æœ‰ç‚¹çš„è·ç¦»ä½œä¸ºä¸ç¡®å®šæ€§çš„ä»£ç†
            min_dist = minimum([norm(x - optimizer.X_evaluated[i, :]) for i in 1:size(optimizer.X_evaluated, 1)])
            Ïƒ = max(0.1, min_dist)  # æœ€å°ä¸ç¡®å®šæ€§
            
            if config.acquisition_function == :ei
                # Expected Improvement
                best_y = maximum(optimizer.y_evaluated)
                z = (Î¼ - best_y - config.improvement_threshold) / Ïƒ
                ei = Ïƒ * (z * cdf(Normal(), z) + pdf(Normal(), z))
                return ei
                
            elseif config.acquisition_function == :ucb
                # Upper Confidence Bound
                return Î¼ + config.exploration_weight * Ïƒ
                
            elseif config.acquisition_function == :poi
                # Probability of Improvement
                best_y = maximum(optimizer.y_evaluated)
                z = (Î¼ - best_y - config.improvement_threshold) / Ïƒ
                return cdf(Normal(), z)
                
            else
                return Î¼  # é»˜è®¤è¿”å›å‡å€¼
            end
            
        catch e
            return -Inf
        end
    end
    
    # å¤šèµ·ç‚¹ä¼˜åŒ–é‡‡é›†å‡½æ•°
    ranges = get_parameter_ranges(param_space)
    n_dims = length(ranges)
    lower_bounds = [minimum(range) for range in ranges]
    upper_bounds = [maximum(range) for range in ranges]
    
    best_x = nothing
    best_acq = -Inf
    
    # å°è¯•å¤šä¸ªéšæœºèµ·ç‚¹
    n_starts = 10
    Random.seed!(42)
    
    for start in 1:n_starts
        # éšæœºèµ·ç‚¹
        x0 = [lower_bounds[i] + rand() * (upper_bounds[i] - lower_bounds[i]) for i in 1:n_dims]
        
        # ç¡®ä¿èµ·ç‚¹æ»¡è¶³çº¦æŸ
        if !check_parameter_constraints(x0, param_space, config)
            continue
        end
        
        try
            # ä½¿ç”¨Optim.jlä¼˜åŒ–
            result = optimize(
                x -> -acquisition_function(x),  # æœ€å°åŒ–è´Ÿé‡‡é›†å‡½æ•°
                lower_bounds,
                upper_bounds, 
                x0,
                Fminbox(LBFGS()),
                Optim.Options(iterations=100)
            )
            
            if Optim.converged(result)
                candidate_x = Optim.minimizer(result)
                candidate_acq = acquisition_function(candidate_x)
                
                if candidate_acq > best_acq
                    best_x = candidate_x
                    best_acq = candidate_acq
                end
            end
            
        catch e
            continue
        end
    end
    
    if best_x === nothing
        println("âš ï¸  é‡‡é›†å‡½æ•°ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨éšæœºç‚¹")
        # éšæœºç”Ÿæˆä¸€ä¸ªæ»¡è¶³çº¦æŸçš„ç‚¹
        for _ in 1:100
            x_random = [lower_bounds[i] + rand() * (upper_bounds[i] - lower_bounds[i]) for i in 1:n_dims]
            if check_parameter_constraints(x_random, param_space, config)
                return x_random
            end
        end
        return nothing
    end
    
    println("ğŸ¯ é‡‡é›†å‡½æ•°å€¼: $(round(best_acq, digits=4))")
    return best_x
end

"""
    evaluate_acquisition_function(optimizer::BayesianOptimizer, x::Vector{Float64})

è¯„ä¼°ç»™å®šç‚¹çš„é‡‡é›†å‡½æ•°å€¼
"""
function evaluate_acquisition_function(optimizer::BayesianOptimizer, x::Vector{Float64})
    config = optimizer.config
    gp_model = optimizer.gp_model
    
    if gp_model === nothing
        return 0.0
    end
    
    try
        Î¼ = gp_model(x)
        
        # ç®€åŒ–çš„ä¸ç¡®å®šæ€§ä¼°è®¡
        min_dist = minimum([norm(x - optimizer.X_evaluated[i, :]) for i in 1:size(optimizer.X_evaluated, 1)])
        Ïƒ = max(0.1, min_dist)
        
        if config.acquisition_function == :ei
            best_y = maximum(optimizer.y_evaluated)
            z = (Î¼ - best_y - config.improvement_threshold) / Ïƒ
            return Ïƒ * (z * cdf(Normal(), z) + pdf(Normal(), z))
        elseif config.acquisition_function == :ucb
            return Î¼ + config.exploration_weight * Ïƒ
        else
            z = (Î¼ - maximum(optimizer.y_evaluated) - config.improvement_threshold) / Ïƒ
            return cdf(Normal(), z)
        end
        
    catch e
        return 0.0
    end
end

"""
    save_intermediate_results(optimizer::BayesianOptimizer, iteration::Int)

ä¿å­˜ä¸­é—´ç»“æœ
"""
function save_intermediate_results(optimizer::BayesianOptimizer, iteration::Int)
    results_dir = "/home/ryankwok/Documents/TwoEnzymeSim/ML/result"
    
    if !isdir(results_dir)
        mkpath(results_dir)
    end
    
    filename = joinpath(results_dir, "bayesian_opt_iter_$(iteration).jld2")
    
    try
        jldsave(filename;
                X_evaluated = optimizer.X_evaluated,
                y_evaluated = optimizer.y_evaluated,
                best_x = optimizer.best_x,
                best_y = optimizer.best_y,
                best_params = optimizer.best_params,
                acquisition_history = optimizer.acquisition_history,
                thermo_v1_mean_history = optimizer.thermo_v1_mean_history,
                thermo_v2_mean_history = optimizer.thermo_v2_mean_history,
                iteration = iteration)
        
        println("ğŸ’¾ ä¸­é—´ç»“æœå·²ä¿å­˜: $filename")
    catch e
        println("âš ï¸  ä¿å­˜ä¸­é—´ç»“æœå¤±è´¥: $e")
    end
end

# éœ€è¦å¯¼å…¥Distributionsç”¨äºæ­£æ€åˆ†å¸ƒ
using Distributions

"""
    create_bayesian_optimization_workflow(config_path::String="config/bayesian_optimization_config.toml", section::String="single_objective")

åˆ›å»ºå®Œæ•´çš„è´å¶æ–¯ä¼˜åŒ–å·¥ä½œæµç¨‹
"""
function create_bayesian_optimization_workflow(config_path::String="config/bayesian_optimization_config.toml", section::String="single_objective")
    println("ğŸš€ è´å¶æ–¯ä¼˜åŒ–å·¥ä½œæµç¨‹")
    println("="^60)
    
    # ç¬¬1æ­¥ï¼šåŠ è½½é…ç½®
    println("\nğŸ“‹ ç¬¬1æ­¥ï¼šåŠ è½½é…ç½®")
    
    # ä»é…ç½®æ–‡ä»¶åŠ è½½å‚æ•°
    config = load_bayesian_config(config_path, section)
    param_space = load_parameter_space_from_config(config_path)
    
    println("âœ… è´å¶æ–¯ä¼˜åŒ–é…ç½®å®Œæˆ")
    println("ğŸ¯ ä¼˜åŒ–ç›®æ ‡: æœ€å¤§åŒ– $(config.target_variable)")
    println("ğŸ” åˆå§‹ç‚¹æ•°: $(config.n_initial_points)")
    println("ğŸ”„ ä¼˜åŒ–è¿­ä»£: $(config.n_iterations)")
    println("ğŸ“ é‡‡é›†å‡½æ•°: $(config.acquisition_function)")
    
    # ç¬¬2æ­¥ï¼šåˆ›å»ºä¼˜åŒ–å™¨
    println("\nğŸ—ï¸  ç¬¬2æ­¥ï¼šåˆ›å»ºè´å¶æ–¯ä¼˜åŒ–å™¨")
    optimizer = BayesianOptimizer(config, param_space)
    
    # ç¬¬3æ­¥ï¼šåˆå§‹åŒ–ï¼ˆç”Ÿæˆå¹¶è¯„ä¼°åˆå§‹ç‚¹ï¼‰
    println("\nğŸ”¬ ç¬¬3æ­¥ï¼šåˆå§‹åŒ–æ¢ç´¢")
    initialize_optimizer!(optimizer)
    
    # ç¬¬4æ­¥ï¼šè¿è¡Œè´å¶æ–¯ä¼˜åŒ–
    println("\nğŸ¯ ç¬¬4æ­¥ï¼šæ™ºèƒ½å‚æ•°ä¼˜åŒ–")
    run_bayesian_optimization!(optimizer)
    
    # ç¬¬5æ­¥ï¼šç»“æœåˆ†æ
    println("\nğŸ“Š ç¬¬5æ­¥ï¼šç»“æœåˆ†æ")
    analyze_optimization_results(optimizer)
    
    # ç¬¬6æ­¥ï¼šå¯è§†åŒ–ç»“æœ
    println("\nğŸ“ˆ ç¬¬6æ­¥ï¼šç”Ÿæˆå¯è§†åŒ–")
    if config.plot_convergence
        plot_optimization_convergence(optimizer)
    end
    
    if config.plot_acquisition
        plot_acquisition_function_evolution(optimizer)
    end
    
    # ç¬¬7æ­¥ï¼šä¿å­˜æœ€ç»ˆç»“æœ
    println("\nğŸ’¾ ç¬¬7æ­¥ï¼šä¿å­˜ç»“æœ")
    save_optimization_results(optimizer)
    
    # ç¬¬8æ­¥ï¼šæ€§èƒ½å¯¹æ¯”
    println("\nâš¡ ç¬¬8æ­¥ï¼šæ•ˆç‡å¯¹æ¯”")
    compare_with_grid_search(optimizer)
    
    println("\nğŸ‰ è´å¶æ–¯ä¼˜åŒ–å·¥ä½œæµç¨‹å®Œæˆ!")
    
    return optimizer
end

"""
    analyze_optimization_results(optimizer::BayesianOptimizer)

åˆ†æä¼˜åŒ–ç»“æœ
"""
function analyze_optimization_results(optimizer::BayesianOptimizer)
    config = optimizer.config
    
    println("ğŸ” ä¼˜åŒ–ç»“æœåˆ†æ:")
    println("ğŸ“Š æ€»è¯„ä¼°æ¬¡æ•°: $(size(optimizer.X_evaluated, 1))")
    println("ğŸ† æœ€ä¼˜ç›®æ ‡å€¼: $(round(optimizer.best_y, digits=4))")
    
    # è®¡ç®—æ”¹å–„å¹…åº¦
    initial_best = maximum(optimizer.y_evaluated[1:config.n_initial_points])
    final_improvement = optimizer.best_y - initial_best
    improvement_percent = (final_improvement / abs(initial_best)) * 100
    
    println("ğŸ“ˆ æ”¹å–„å¹…åº¦: $(round(final_improvement, digits=4)) ($(round(improvement_percent, digits=1))%)")
    
    # æœ€ä¼˜å‚æ•°ç»„åˆ
    println("\nğŸ¯ æœ€ä¼˜å‚æ•°ç»„åˆ:")
    for (param, value) in optimizer.best_params
        println("  $param: $(round(value, digits=3))")
    end
    
    # çƒ­åŠ›å­¦çº¦æŸéªŒè¯
    best_params = optimizer.best_params
    Keq1 = (best_params[:k1f] * best_params[:k2f]) / (best_params[:k1r] * best_params[:k2r])
    Keq2 = (best_params[:k3f] * best_params[:k4f]) / (best_params[:k3r] * best_params[:k4r])
    
    println("\nğŸ§ª çƒ­åŠ›å­¦éªŒè¯:")
    println("  Keq1: $(round(Keq1, digits=3))")
    println("  Keq2: $(round(Keq2, digits=3))")
    println("  çº¦æŸæ»¡è¶³: $(0.01 <= Keq1 <= 100.0 && 0.01 <= Keq2 <= 100.0 ? "âœ…" : "âŒ")")
    
    # æ”¶æ•›æ€§åˆ†æ
    if length(optimizer.y_evaluated) > 10
        recent_improvement = maximum(optimizer.y_evaluated[end-9:end]) - maximum(optimizer.y_evaluated[end-19:end-10])
        println("\nğŸ“‰ æ”¶æ•›æ€§åˆ†æ:")
        println("  æœ€è¿‘10æ­¥æ”¹å–„: $(round(recent_improvement, digits=4))")
        println("  æ”¶æ•›çŠ¶æ€: $(abs(recent_improvement) < 0.001 ? "å·²æ”¶æ•›" : "ä»åœ¨æ”¹å–„")")
    end
end

"""
    plot_optimization_convergence(optimizer::BayesianOptimizer)

ç»˜åˆ¶ä¼˜åŒ–æ”¶æ•›æ›²çº¿
"""
function plot_optimization_convergence(optimizer::BayesianOptimizer)
    y_values = optimizer.y_evaluated
    n_points = length(y_values)
    
    # è®¡ç®—ç´¯ç§¯æœ€ä¼˜å€¼
    cumulative_best = zeros(n_points)
    cumulative_best[1] = y_values[1]
    
    for i in 2:n_points
        cumulative_best[i] = max(cumulative_best[i-1], y_values[i])
    end
    
    # ç»˜åˆ¶æ”¶æ•›æ›²çº¿
    p1 = plot(1:n_points, cumulative_best, 
              xlabel="è¯„ä¼°æ¬¡æ•°", ylabel="æœ€ä¼˜ç›®æ ‡å€¼", 
              title="è´å¶æ–¯ä¼˜åŒ–æ”¶æ•›æ›²çº¿", 
              lw=2, label="ç´¯ç§¯æœ€ä¼˜å€¼", color=:blue)
    
    # æ·»åŠ åˆå§‹æ¢ç´¢é˜¶æ®µæ ‡è®°
    vline!([optimizer.config.n_initial_points], 
           label="åˆå§‹æ¢ç´¢ç»“æŸ", color=:red, ls=:dash)
    
    # ä¿å­˜å›¾ç‰‡
    results_dir = "/home/ryankwok/Documents/TwoEnzymeSim/ML/result"
    if !isdir(results_dir)
        mkpath(results_dir)
    end
    
    savefig(p1, joinpath(results_dir, "bayesian_convergence.png"))
    println("ğŸ“ å·²ä¿å­˜æ”¶æ•›æ›²çº¿: $(joinpath(results_dir, "bayesian_convergence.png"))")
    
    # ç»˜åˆ¶ç›®æ ‡å€¼åˆ†å¸ƒ
    p2 = histogram(y_values, bins=20, 
                   xlabel="ç›®æ ‡å€¼", ylabel="é¢‘æ¬¡", 
                   title="ç›®æ ‡å€¼åˆ†å¸ƒ", 
                   alpha=0.7, color=:green)
    
    vline!([optimizer.best_y], label="æœ€ä¼˜å€¼", color=:red, lw=2)
    
    savefig(p2, joinpath(results_dir, "bayesian_objective_distribution.png"))
    println("ğŸ“ å·²ä¿å­˜ç›®æ ‡å€¼åˆ†å¸ƒ: $(joinpath(results_dir, "bayesian_objective_distribution.png"))")
end

"""
    plot_acquisition_function_evolution(optimizer::BayesianOptimizer)

ç»˜åˆ¶é‡‡é›†å‡½æ•°æ¼”åŒ–
"""
function plot_acquisition_function_evolution(optimizer::BayesianOptimizer)
    if isempty(optimizer.acquisition_history)
        println("âš ï¸  æ— é‡‡é›†å‡½æ•°å†å²ï¼Œè·³è¿‡ç»˜åˆ¶")
        return
    end
    
    acq_values = optimizer.acquisition_history
    n_acq = length(acq_values)
    
    p = plot(1:n_acq, acq_values,
             xlabel="ä¼˜åŒ–è¿­ä»£", ylabel="é‡‡é›†å‡½æ•°å€¼",
             title="é‡‡é›†å‡½æ•°æ¼”åŒ– ($(optimizer.config.acquisition_function))",
             lw=2, label="é‡‡é›†å‡½æ•°å€¼", color=:purple)
    
    # ä¿å­˜å›¾ç‰‡
    results_dir = "/home/ryankwok/Documents/TwoEnzymeSim/ML/result"
    if !isdir(results_dir)
        mkpath(results_dir)
    end
    
    savefig(p, joinpath(results_dir, "bayesian_acquisition_evolution.png"))
    println("ğŸ“ å·²ä¿å­˜é‡‡é›†å‡½æ•°æ¼”åŒ–: $(joinpath(results_dir, "bayesian_acquisition_evolution.png"))")
end

"""
    save_optimization_results(optimizer::BayesianOptimizer)

ä¿å­˜ä¼˜åŒ–ç»“æœ
"""
function save_optimization_results(optimizer::BayesianOptimizer)
    results_path = "/home/ryankwok/Documents/TwoEnzymeSim/ML/model/bayesian_optimization_results.jld2"
    
    try
        jldsave(results_path;
                config = optimizer.config,
                param_space = optimizer.param_space,
                X_evaluated = optimizer.X_evaluated,
                y_evaluated = optimizer.y_evaluated,
                y_multi_evaluated = optimizer.y_multi_evaluated,
                best_x = optimizer.best_x,
                best_y = optimizer.best_y,
                best_params = optimizer.best_params,
                acquisition_history = optimizer.acquisition_history,
                thermo_v1_mean_history = optimizer.thermo_v1_mean_history,
                thermo_v2_mean_history = optimizer.thermo_v2_mean_history)
        
        println("âœ… ä¼˜åŒ–ç»“æœå·²ä¿å­˜: $results_path")
        
        # ä¿å­˜æ–‡ä»¶å¤§å°ä¿¡æ¯
        file_size_mb = round(filesize(results_path) / 1024^2, digits=1)
        println("ğŸ“Š ç»“æœæ–‡ä»¶å¤§å°: $(file_size_mb) MB")
        
    catch e
        println("âŒ ä¿å­˜ç»“æœå¤±è´¥: $e")
    end
end

"""
    compare_with_grid_search(optimizer::BayesianOptimizer)

ä¸ç½‘æ ¼æœç´¢æ•ˆç‡å¯¹æ¯”
"""
function compare_with_grid_search(optimizer::BayesianOptimizer)
    n_evaluated = size(optimizer.X_evaluated, 1)
    
    # ä¼°ç®—ç­‰æ•ˆç½‘æ ¼æœç´¢çš„è®¡ç®—é‡
    param_space = optimizer.param_space
    ranges = get_parameter_ranges(param_space)
    
    # å‡è®¾æ¯ä¸ªç»´åº¦10ä¸ªç‚¹çš„ç²—ç½‘æ ¼
    grid_points_coarse = 10^length(ranges)
    
    # å‡è®¾æ¯ä¸ªç»´åº¦20ä¸ªç‚¹çš„ç»†ç½‘æ ¼
    grid_points_fine = 20^length(ranges)
    
    println("âš¡ æ•ˆç‡å¯¹æ¯”åˆ†æ:")
    println("ğŸ“Š è´å¶æ–¯ä¼˜åŒ–è¯„ä¼°æ¬¡æ•°: $n_evaluated")
    println("ğŸ”² ç­‰æ•ˆç²—ç½‘æ ¼ç‚¹æ•°: $(grid_points_coarse)")
    println("ğŸ”³ ç­‰æ•ˆç»†ç½‘æ ¼ç‚¹æ•°: $(grid_points_fine)")
    
    # è®¡ç®—æ•ˆç‡æå‡
    efficiency_coarse = grid_points_coarse / n_evaluated
    efficiency_fine = grid_points_fine / n_evaluated
    
    println("\nğŸš€ æ•ˆç‡æå‡:")
    println("  vs ç²—ç½‘æ ¼: $(round(efficiency_coarse, digits=1))x")
    println("  vs ç»†ç½‘æ ¼: $(round(efficiency_fine, digits=1))x")
    
    # è®¡ç®—èŠ‚çœçš„è®¡ç®—æ—¶é—´ï¼ˆå‡è®¾æ¯æ¬¡ä»¿çœŸ0.1ç§’ï¼‰
    time_saved_coarse = (grid_points_coarse - n_evaluated) * 0.1 / 3600  # å°æ—¶
    time_saved_fine = (grid_points_fine - n_evaluated) * 0.1 / 3600     # å°æ—¶
    
    println("\nâ° æ—¶é—´èŠ‚çœ:")
    println("  vs ç²—ç½‘æ ¼: $(round(time_saved_coarse, digits=1)) å°æ—¶")
    println("  vs ç»†ç½‘æ ¼: $(round(time_saved_fine, digits=1)) å°æ—¶")
    
    println("\nâœ… è´å¶æ–¯ä¼˜åŒ–æˆåŠŸå®ç°æ™ºèƒ½å‚æ•°æ¢ç´¢ï¼")
end

"""
    create_multi_objective_workflow(config_path::String="config/bayesian_optimization_config.toml")

åˆ›å»ºå¤šç›®æ ‡è´å¶æ–¯ä¼˜åŒ–å·¥ä½œæµç¨‹
"""
function create_multi_objective_workflow(config_path::String="config/bayesian_optimization_config.toml")
    println("ğŸ¯ å¤šç›®æ ‡è´å¶æ–¯ä¼˜åŒ–å·¥ä½œæµç¨‹")
    println("="^60)
    
    # ä»é…ç½®æ–‡ä»¶åŠ è½½å¤šç›®æ ‡å‚æ•°
    config = load_bayesian_config(config_path, "multi_objective")
    param_space = load_parameter_space_from_config(config_path)
    
    println("ğŸ¯ å¤šç›®æ ‡: $(config.multi_objectives)")
    println("âš–ï¸  æƒé‡: $(config.multi_weights)")
    
    # åˆ›å»ºå¹¶è¿è¡Œä¼˜åŒ–å™¨
    optimizer = BayesianOptimizer(config, param_space)
    initialize_optimizer!(optimizer)
    run_bayesian_optimization!(optimizer)
    
    # å¤šç›®æ ‡ç»“æœåˆ†æ
    analyze_multi_objective_results(optimizer)
    
    # ä¿å­˜å¤šç›®æ ‡ç»“æœ
    save_multi_objective_results(optimizer)
    
    return optimizer
end

"""
    analyze_multi_objective_results(optimizer::BayesianOptimizer)

åˆ†æå¤šç›®æ ‡ä¼˜åŒ–ç»“æœ
"""
function analyze_multi_objective_results(optimizer::BayesianOptimizer)
    config = optimizer.config
    
    if config.objective_type != :multi_objective
        return
    end
    
    println("ğŸ¯ å¤šç›®æ ‡ä¼˜åŒ–ç»“æœåˆ†æ:")
    
    # æœ€ä¼˜ç‚¹çš„å¤šç›®æ ‡å€¼
    best_idx = argmax(optimizer.y_evaluated)
    best_multi_values = optimizer.y_multi_evaluated[best_idx, :]
    
    println("ğŸ† æœ€ä¼˜ç‚¹çš„å¤šç›®æ ‡å€¼:")
    for (i, obj) in enumerate(config.multi_objectives)
        println("  $obj: $(round(best_multi_values[i], digits=4))")
    end
    
    println("âš–ï¸  åŠ æƒç»¼åˆå¾—åˆ†: $(round(optimizer.best_y, digits=4))")
    
    # Paretoå‰æ²¿åˆ†æ
    pareto_indices = find_pareto_front(optimizer.y_multi_evaluated)
    println("\nğŸ“Š Paretoå‰æ²¿åˆ†æ:")
    println("  Paretoæœ€ä¼˜è§£æ•°é‡: $(length(pareto_indices))")
    println("  Paretoæ•ˆç‡: $(round(length(pareto_indices)/size(optimizer.y_multi_evaluated,1)*100, digits=1))%")
end

"""
    find_pareto_front(Y::Matrix{Float64})

å¯»æ‰¾Paretoå‰æ²¿
"""
function find_pareto_front(Y::Matrix{Float64})
    n_points, n_objectives = size(Y)
    pareto_indices = Int[]
    
    for i in 1:n_points
        is_dominated = false
        
        for j in 1:n_points
            if i != j
                # æ£€æŸ¥ç‚¹iæ˜¯å¦è¢«ç‚¹jæ”¯é…
                if all(Y[j, :] .>= Y[i, :]) && any(Y[j, :] .> Y[i, :])
                    is_dominated = true
                    break
                end
            end
        end
        
        if !is_dominated
            push!(pareto_indices, i)
        end
    end
    
    return pareto_indices
end

"""
    save_multi_objective_results(optimizer::BayesianOptimizer)

ä¿å­˜å¤šç›®æ ‡ä¼˜åŒ–ç»“æœ
"""
function save_multi_objective_results(optimizer::BayesianOptimizer)
    if optimizer.config.objective_type != :multi_objective
        return
    end
    
    results_path = "/home/ryankwok/Documents/TwoEnzymeSim/ML/model/multi_objective_bayesian_results.jld2"
    
    # è®¡ç®—Paretoå‰æ²¿
    pareto_indices = find_pareto_front(optimizer.y_multi_evaluated)
    pareto_solutions = optimizer.X_evaluated[pareto_indices, :]
    pareto_objectives = optimizer.y_multi_evaluated[pareto_indices, :]
    
    try
        jldsave(results_path;
                config = optimizer.config,
                param_space = optimizer.param_space,
                X_evaluated = optimizer.X_evaluated,
                y_evaluated = optimizer.y_evaluated,
                y_multi_evaluated = optimizer.y_multi_evaluated,
                pareto_indices = pareto_indices,
                pareto_solutions = pareto_solutions,
                pareto_objectives = pareto_objectives,
                best_x = optimizer.best_x,
                best_y = optimizer.best_y,
                best_params = optimizer.best_params)
        
        println("âœ… å¤šç›®æ ‡ç»“æœå·²ä¿å­˜: $results_path")
        
    catch e
        println("âŒ ä¿å­˜å¤šç›®æ ‡ç»“æœå¤±è´¥: $e")
    end
end

# å¯¼å‡ºä¸»è¦å‡½æ•°
export BayesianOptimizationConfig, BayesianOptimizer
export create_bayesian_optimization_workflow, create_multi_objective_workflow
export initialize_optimizer!, run_bayesian_optimization!
export analyze_optimization_results, save_optimization_results
export load_bayesian_config, load_parameter_space_from_config

# ä¸»ç¨‹åºå…¥å£
if abspath(PROGRAM_FILE) == @__FILE__
    println("ğŸ¬ æ‰§è¡Œè´å¶æ–¯ä¼˜åŒ–å·¥ä½œæµç¨‹...")
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    config_path = "config/bayesian_optimization_config.toml"
    
    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°é€‰æ‹©å·¥ä½œæµç¨‹
    if length(ARGS) > 0
        if ARGS[1] == "--single" || ARGS[1] == "-s"
            section = length(ARGS) > 1 ? ARGS[2] : "single_objective"
            optimizer = create_bayesian_optimization_workflow(config_path, section)
            
        elseif ARGS[1] == "--multi" || ARGS[1] == "-m"
            optimizer = create_multi_objective_workflow(config_path)
            
        elseif ARGS[1] == "--config" || ARGS[1] == "-c"
            # æŒ‡å®šé…ç½®æ–‡ä»¶
            if length(ARGS) > 1
                config_path = ARGS[2]
            end
            section = length(ARGS) > 2 ? ARGS[3] : "single_objective"
            optimizer = create_bayesian_optimization_workflow(config_path, section)
            
        elseif ARGS[1] == "--help" || ARGS[1] == "-h"
            println("ğŸ“š è´å¶æ–¯ä¼˜åŒ–ä½¿ç”¨è¯´æ˜:")
            println("  julia bayesian_optimization.jl                    # é»˜è®¤å•ç›®æ ‡ä¼˜åŒ–")
            println("  julia bayesian_optimization.jl --single           # å•ç›®æ ‡ä¼˜åŒ–")
            println("  julia bayesian_optimization.jl --multi            # å¤šç›®æ ‡ä¼˜åŒ–")
            println("  julia bayesian_optimization.jl --config <path>    # æŒ‡å®šé…ç½®æ–‡ä»¶")
            println("  julia bayesian_optimization.jl --help             # æ˜¾ç¤ºå¸®åŠ©")
            println("\nğŸ“ é…ç½®æ–‡ä»¶éƒ¨åˆ†:")
            println("  single_objective       # å•ç›®æ ‡ä¼˜åŒ–é…ç½®")
            println("  multi_objective        # å¤šç›®æ ‡ä¼˜åŒ–é…ç½®")
            println("  constraint_optimization # çº¦æŸä¼˜åŒ–é…ç½®")
            println("  acquisition_comparison  # é‡‡é›†å‡½æ•°æ¯”è¾ƒé…ç½®")
            
        else
            # é»˜è®¤å•ç›®æ ‡ä¼˜åŒ–
            optimizer = create_bayesian_optimization_workflow(config_path, "single_objective")
        end
    else
        # é»˜è®¤å•ç›®æ ‡ä¼˜åŒ–
        optimizer = create_bayesian_optimization_workflow(config_path, "single_objective")
    end
    
    println("\nğŸ‰ è´å¶æ–¯ä¼˜åŒ–æ¼”ç¤ºå®Œæˆï¼")
    println("ğŸ’¡ ç°åœ¨å¯ä»¥ç”¨æ™ºèƒ½ç®—æ³•æ›¿ä»£ç½‘æ ¼æ‰«æï¼Œåªéœ€100-500æ¬¡æ¨¡æ‹Ÿï¼")
end

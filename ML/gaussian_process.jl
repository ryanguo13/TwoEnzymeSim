"""
Gaussian Process ä»£ç†æ¨¡å‹å®ç°

ä½¿ç”¨Surrogates.jlå®ç°é«˜çº§ä»£ç†æ¨¡å‹ï¼Œç‰¹åˆ«é€‚åˆä¸ç¡®å®šæ€§é‡åŒ–
"""

using Surrogates
using Plots
using Statistics
using LinearAlgebra

"""
    train_gaussian_process!(surrogate_model::SurrogateModel)

è®­ç»ƒGaussian Processä»£ç†æ¨¡å‹
"""
function train_gaussian_process!(surrogate_model::SurrogateModel)
    println("ğŸ”® è®­ç»ƒGaussian Processä»£ç†æ¨¡å‹...")
    
    X_train = surrogate_model.X_train
    y_train = surrogate_model.y_train
    
    # ä¸ºæ¯ä¸ªè¾“å‡ºå˜é‡è®­ç»ƒç‹¬ç«‹çš„GPæ¨¡å‹
    n_outputs = size(y_train, 2)
    gp_models = []
    
    for i in 1:n_outputs
        println("ğŸ“Š è®­ç»ƒè¾“å‡ºå˜é‡ $i/$(n_outputs)...")
        
        # å‡†å¤‡æ•°æ® - Surrogates.jléœ€è¦ç‰¹å®šæ ¼å¼
        X_data = [X_train[j, :] for j in 1:size(X_train, 1)]
        y_data = y_train[:, i]
        
        # å®šä¹‰è¾¹ç•Œ
        n_dims = size(X_train, 2)
        lower_bounds = [minimum(X_train[:, j]) for j in 1:n_dims]
        upper_bounds = [maximum(X_train[:, j]) for j in 1:n_dims]
        
        try
            # åˆ›å»ºKrigingä»£ç†æ¨¡å‹ï¼ˆGaussian Processçš„ä¸€ç§å®ç°ï¼‰
            gp_model = Kriging(X_data, y_data, lower_bounds, upper_bounds)
            push!(gp_models, gp_model)
            println("âœ… GPæ¨¡å‹ $i è®­ç»ƒå®Œæˆ")
        catch e
            println("âš ï¸  GPæ¨¡å‹ $i è®­ç»ƒå¤±è´¥: $e")
            # å›é€€åˆ°RadialBasis
            rb_model = RadialBasis(X_data, y_data, lower_bounds, upper_bounds)
            push!(gp_models, rb_model)
            println("ğŸ”„ ä½¿ç”¨RadialBasisä½œä¸ºå¤‡é€‰")
        end
    end
    
    surrogate_model.model = gp_models
    println("âœ… Gaussian Processè®­ç»ƒå®Œæˆ")
end

"""
    predict_gaussian_process(surrogate_model::SurrogateModel, X_new::Matrix{Float64})

ä½¿ç”¨Gaussian Processè¿›è¡Œé¢„æµ‹
"""
function predict_gaussian_process(surrogate_model::SurrogateModel, X_new::Matrix{Float64})
    gp_models = surrogate_model.model
    n_samples, n_dims = size(X_new)
    n_outputs = length(gp_models)
    
    y_pred = zeros(n_samples, n_outputs)
    
    for i in 1:n_samples
        x_point = X_new[i, :]
        
        for j in 1:n_outputs
            try
                # Surrogates.jlçš„é¢„æµ‹æ¥å£
                y_pred[i, j] = gp_models[j](x_point)
            catch e
                println("âš ï¸  é¢„æµ‹å¤±è´¥ (æ ·æœ¬$i, è¾“å‡º$j): $e")
                y_pred[i, j] = NaN
            end
        end
    end
    
    return y_pred
end

"""
    create_adaptive_surrogate(param_space::ParameterSpace, config::SurrogateModelConfig)

åˆ›å»ºè‡ªé€‚åº”ä»£ç†æ¨¡å‹ï¼Œä½¿ç”¨ä¸»åŠ¨å­¦ä¹ ç­–ç•¥
"""
function create_adaptive_surrogate(param_space::ParameterSpace, config::SurrogateModelConfig)
    println("ğŸ§  åˆ›å»ºè‡ªé€‚åº”ä»£ç†æ¨¡å‹...")
    
    # åˆå§‹é‡‡æ ·
    n_initial = max(100, Int(config.max_samples * 0.1))
    X_initial = generate_lhs_samples(param_space, n_initial)
    y_initial = simulate_parameter_batch(X_initial, param_space.tspan, config.target_variables)
    
    # è¿‡æ»¤æœ‰æ•ˆæ ·æœ¬
    valid_indices = findall(x -> !any(isnan.(x)), eachrow(y_initial))
    X_train = X_initial[valid_indices, :]
    y_train = y_initial[valid_indices, :]
    
    println("ğŸ“Š åˆå§‹è®­ç»ƒæ ·æœ¬: $(size(X_train, 1))")
    
    # åˆ›å»ºä»£ç†æ¨¡å‹
    surrogate_model = SurrogateModel(config, param_space)
    preprocess_data!(surrogate_model, X_train, y_train)
    
    # ä¸»åŠ¨å­¦ä¹ å¾ªç¯
    max_iterations = 5
    samples_per_iteration = Int(config.max_samples / max_iterations)
    
    for iter in 1:max_iterations
        println("\nğŸ”„ ä¸»åŠ¨å­¦ä¹ è¿­ä»£ $iter/$max_iterations")
        
        # è®­ç»ƒå½“å‰æ¨¡å‹
        if config.model_type == :gaussian_process
            train_gaussian_process!(surrogate_model)
        else
            train_surrogate_model!(surrogate_model)
        end
        
        if iter < max_iterations
            # ç”Ÿæˆå€™é€‰ç‚¹
            X_candidates = generate_lhs_samples(param_space, samples_per_iteration * 5)
            
            # é€‰æ‹©æœ€æœ‰ä»·å€¼çš„ç‚¹ï¼ˆåŸºäºé¢„æµ‹ä¸ç¡®å®šæ€§ï¼‰
            X_new = select_most_informative_points(surrogate_model, X_candidates, samples_per_iteration)
            
            # è¿è¡Œæ–°ä»¿çœŸ
            println("ğŸ§ª è¿è¡Œ $(size(X_new, 1)) ä¸ªæ–°ä»¿çœŸ...")
            y_new = simulate_parameter_batch(X_new, param_space.tspan, config.target_variables)
            
            # è¿‡æ»¤å¹¶æ·»åŠ åˆ°è®­ç»ƒé›†
            valid_new = findall(x -> !any(isnan.(x)), eachrow(y_new))
            if length(valid_new) > 0
                X_train = vcat(X_train, X_new[valid_new, :])
                y_train = vcat(y_train, y_new[valid_new, :])
                
                # é‡æ–°é¢„å¤„ç†æ•°æ®
                preprocess_data!(surrogate_model, X_train, y_train)
                println("âœ… æ·»åŠ  $(length(valid_new)) ä¸ªæ–°æ ·æœ¬ï¼Œæ€»è®¡: $(size(X_train, 1))")
            end
        end
    end
    
    println("ğŸ¯ è‡ªé€‚åº”ä»£ç†æ¨¡å‹è®­ç»ƒå®Œæˆ")
    return surrogate_model
end

"""
    select_most_informative_points(surrogate_model::SurrogateModel, X_candidates::Matrix{Float64}, n_select::Int)

é€‰æ‹©æœ€æœ‰ä¿¡æ¯é‡çš„ç‚¹è¿›è¡Œä¸»åŠ¨å­¦ä¹ 
"""
function select_most_informative_points(surrogate_model::SurrogateModel, X_candidates::Matrix{Float64}, n_select::Int)
    config = surrogate_model.config
    
    if config.model_type == :neural_network && config.uncertainty_estimation
        # ä½¿ç”¨ç¥ç»ç½‘ç»œçš„ä¸ç¡®å®šæ€§
        _, y_std = predict_with_uncertainty(surrogate_model, X_candidates, n_samples=20)
        
        # é€‰æ‹©ä¸ç¡®å®šæ€§æœ€é«˜çš„ç‚¹
        uncertainty_scores = mean(y_std, dims=2)[:, 1]
        
    elseif config.model_type == :gaussian_process
        # å¯¹äºGPï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„é‡‡é›†å‡½æ•°
        # è¿™é‡Œç®€åŒ–ä¸ºéšæœºé€‰æ‹©ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥å®ç°EIã€UCBç­‰ï¼‰
        uncertainty_scores = rand(size(X_candidates, 1))
        
    else
        # éšæœºé€‰æ‹©ä½œä¸ºå¤‡é€‰
        uncertainty_scores = rand(size(X_candidates, 1))
    end
    
    # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ç‚¹
    selected_indices = sortperm(uncertainty_scores, rev=true)[1:min(n_select, length(uncertainty_scores))]
    
    return X_candidates[selected_indices, :]
end

"""
    create_ensemble_surrogate(param_space::ParameterSpace, config::SurrogateModelConfig; n_models::Int=5)

åˆ›å»ºé›†æˆä»£ç†æ¨¡å‹ï¼Œç»“åˆå¤šä¸ªä¸åŒçš„ä»£ç†æ¨¡å‹
"""
function create_ensemble_surrogate(param_space::ParameterSpace, config::SurrogateModelConfig; n_models::Int=5)
    println("ğŸ­ åˆ›å»ºé›†æˆä»£ç†æ¨¡å‹...")
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    X_data, y_data = generate_small_scale_data(SurrogateModel(config, param_space))
    
    ensemble_models = []
    model_types = [:neural_network, :gaussian_process, :radial_basis]
    
    for i in 1:n_models
        println("ğŸ”§ è®­ç»ƒé›†æˆæ¨¡å‹ $i/$n_models...")
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹ä½¿ç”¨ä¸åŒçš„é…ç½®å’Œæ•°æ®å­é›†
        model_config = deepcopy(config)
        model_config.model_type = model_types[mod(i-1, length(model_types)) + 1]
        
        # ä½¿ç”¨Bootstrapé‡‡æ ·åˆ›å»ºä¸åŒçš„è®­ç»ƒé›†
        n_samples = size(X_data, 1)
        bootstrap_indices = rand(1:n_samples, n_samples)
        X_bootstrap = X_data[bootstrap_indices, :]
        y_bootstrap = y_data[bootstrap_indices, :]
        
        # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
        surrogate_model = SurrogateModel(model_config, param_space)
        preprocess_data!(surrogate_model, X_bootstrap, y_bootstrap)
        
        if model_config.model_type == :gaussian_process
            train_gaussian_process!(surrogate_model)
        else
            train_surrogate_model!(surrogate_model)
        end
        
        push!(ensemble_models, surrogate_model)
        println("âœ… é›†æˆæ¨¡å‹ $i å®Œæˆ (ç±»å‹: $(model_config.model_type))")
    end
    
    println("ğŸ¯ é›†æˆä»£ç†æ¨¡å‹åˆ›å»ºå®Œæˆ")
    return ensemble_models
end

"""
    predict_ensemble(ensemble_models::Vector, X_new::Matrix{Float64})

ä½¿ç”¨é›†æˆæ¨¡å‹è¿›è¡Œé¢„æµ‹
"""
function predict_ensemble(ensemble_models::Vector, X_new::Matrix{Float64})
    n_models = length(ensemble_models)
    n_samples = size(X_new, 1)
    
    # æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹
    all_predictions = []
    
    for (i, model) in enumerate(ensemble_models)
        try
            if model.config.model_type == :gaussian_process
                y_pred = predict_gaussian_process(model, X_new)
                y_std = zeros(size(y_pred))  # GPçš„ä¸ç¡®å®šæ€§éœ€è¦å•ç‹¬è®¡ç®—
            else
                y_pred, y_std = predict_with_uncertainty(model, X_new, n_samples=20)
            end
            
            push!(all_predictions, y_pred)
        catch e
            println("âš ï¸  é›†æˆæ¨¡å‹ $i é¢„æµ‹å¤±è´¥: $e")
        end
    end
    
    if isempty(all_predictions)
        error("æ‰€æœ‰é›†æˆæ¨¡å‹é¢„æµ‹éƒ½å¤±è´¥äº†")
    end
    
    # è®¡ç®—é›†æˆé¢„æµ‹
    predictions_array = cat(all_predictions..., dims=3)  # [n_samples, n_outputs, n_models]
    
    y_ensemble_mean = mean(predictions_array, dims=3)[:, :, 1]
    y_ensemble_std = std(predictions_array, dims=3)[:, :, 1]
    
    return y_ensemble_mean, y_ensemble_std
end

"""
    plot_surrogate_performance(surrogate_model::SurrogateModel, X_test::Matrix{Float64}, y_test::Matrix{Float64})

ç»˜åˆ¶ä»£ç†æ¨¡å‹æ€§èƒ½å›¾è¡¨
"""
function plot_surrogate_performance(surrogate_model::SurrogateModel, X_test::Matrix{Float64}, y_test::Matrix{Float64})
    println("ğŸ“Š ç»˜åˆ¶ä»£ç†æ¨¡å‹æ€§èƒ½å›¾è¡¨...")
    
    # é¢„æµ‹
    if surrogate_model.config.model_type == :gaussian_process
        y_pred = predict_gaussian_process(surrogate_model, X_test)
        y_std = zeros(size(y_pred))
    else
        y_pred, y_std = predict_with_uncertainty(surrogate_model, X_test, n_samples=50)
    end
    
    target_vars = surrogate_model.config.target_variables
    plots_array = []
    
    for (i, var) in enumerate(target_vars)
        # é¢„æµ‹ vs çœŸå®å€¼æ•£ç‚¹å›¾
        p = scatter(y_test[:, i], y_pred[:, i], 
                   xlabel="çœŸå®å€¼", ylabel="é¢„æµ‹å€¼", 
                   title="$var: é¢„æµ‹ vs çœŸå®",
                   alpha=0.6, markersize=3)
        
        # æ·»åŠ ç†æƒ³çº¿
        min_val = min(minimum(y_test[:, i]), minimum(y_pred[:, i]))
        max_val = max(maximum(y_test[:, i]), maximum(y_pred[:, i]))
        plot!(p, [min_val, max_val], [min_val, max_val], 
              color=:red, linestyle=:dash, label="ç†æƒ³çº¿")
        
        # æ·»åŠ ä¸ç¡®å®šæ€§ï¼ˆå¦‚æœæœ‰ï¼‰
        if surrogate_model.config.uncertainty_estimation && any(y_std[:, i] .> 0)
            scatter!(p, y_test[:, i], y_pred[:, i], 
                    yerror=y_std[:, i], alpha=0.3, label="ä¸ç¡®å®šæ€§")
        end
        
        push!(plots_array, p)
    end
    
    # ç»„åˆå›¾è¡¨
    combined_plot = plot(plots_array..., layout=(2, 3), size=(1200, 800))
    
    # ä¿å­˜å›¾è¡¨
    plot_path = "/home/ryankwok/Documents/TwoEnzymeSim/ML/model/surrogate_performance.png"
    savefig(combined_plot, plot_path)
    println("ğŸ’¾ æ€§èƒ½å›¾è¡¨ä¿å­˜åˆ°: $plot_path")
    
    return combined_plot
end

"""
    optimize_hyperparameters(param_space::ParameterSpace, config::SurrogateModelConfig)

è¶…å‚æ•°ä¼˜åŒ–ï¼ˆç®€åŒ–ç‰ˆï¼‰
"""
function optimize_hyperparameters(param_space::ParameterSpace, base_config::SurrogateModelConfig)
    println("ğŸ” è¶…å‚æ•°ä¼˜åŒ–...")
    
    # ç”ŸæˆéªŒè¯æ•°æ®
    X_val_data, y_val_data = generate_small_scale_data(SurrogateModel(base_config, param_space))
    
    # è¶…å‚æ•°å€™é€‰
    learning_rates = [1e-4, 1e-3, 1e-2]
    hidden_dims_options = [[32, 16], [64, 32, 16], [128, 64, 32]]
    dropout_rates = [0.05, 0.1, 0.2]
    
    best_config = base_config
    best_score = Inf
    
    for lr in learning_rates
        for hidden_dims in hidden_dims_options
            for dropout in dropout_rates
                config = deepcopy(base_config)
                config.learning_rate = lr
                config.hidden_dims = hidden_dims
                config.dropout_rate = dropout
                config.epochs = 50  # å‡å°‘è®­ç»ƒæ—¶é—´
                
                try
                    # è®­ç»ƒæ¨¡å‹
                    surrogate_model = SurrogateModel(config, param_space)
                    preprocess_data!(surrogate_model, X_val_data, y_val_data)
                    train_surrogate_model!(surrogate_model)
                    
                    # è¯„ä¼°æ€§èƒ½
                    y_pred, _ = predict_with_uncertainty(surrogate_model, surrogate_model.X_val)
                    mse = mean((y_pred - surrogate_model.y_val).^2)
                    
                    if mse < best_score
                        best_score = mse
                        best_config = config
                        println("ğŸ¯ æ–°æœ€ä½³é…ç½®: MSE=$(round(mse, digits=6))")
                    end
                    
                catch e
                    println("âš ï¸  é…ç½®å¤±è´¥: lr=$lr, hidden=$hidden_dims, dropout=$dropout")
                end
            end
        end
    end
    
    println("âœ… è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ")
    println("ğŸ† æœ€ä½³é…ç½®: lr=$(best_config.learning_rate), hidden=$(best_config.hidden_dims)")
    
    return best_config
end

export train_gaussian_process!, predict_gaussian_process
export create_adaptive_surrogate, create_ensemble_surrogate, predict_ensemble
export plot_surrogate_performance, optimize_hyperparameters

# Note: Surrogate configuration can be provided via TOML using
# `load_surrogate_from_toml` defined in `surrogate_model.jl`.

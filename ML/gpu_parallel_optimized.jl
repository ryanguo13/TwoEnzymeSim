"""
ä¼˜åŒ–çš„GPUå¹¶è¡Œæ±‚è§£å™¨

å®ç°çœŸæ­£çš„å¤šGPUå¹¶è¡Œå¤„ç†ï¼Œè§£å†³ç°æœ‰å®ç°ä¸­çš„åºåˆ—åŒ–å’ŒCPUå›é€€é—®é¢˜

ä¸»è¦æ”¹è¿›ï¼š
1. çœŸæ­£çš„å¹¶è¡ŒGPUè®¡ç®—ï¼ˆåŒæ—¶ä½¿ç”¨å¤šä¸ªGPUï¼‰
2. GPUå†…å­˜ä¼˜åŒ–å’Œæ‰¹å¤„ç†
3. CUDAå†…æ ¸çº§åˆ«çš„ODEæ±‚è§£
4. æœ€å°åŒ–CPU-GPUæ•°æ®ä¼ è¾“
5. æ™ºèƒ½è´Ÿè½½å‡è¡¡å’Œé”™è¯¯æ¢å¤
"""

using CUDA
using DifferentialEquations
using DiffEqGPU
using Distributed
using Printf
using LinearAlgebra
using Statistics
using ProgressMeter
using StaticArrays

"""
    GPUParallelConfig

GPUå¹¶è¡Œè®¡ç®—é…ç½®
"""
struct GPUParallelConfig
    # GPUè®¾å¤‡é…ç½®
    use_multi_gpu::Bool
    gpu_batch_size::Int
    max_memory_usage::Float64  # æ¯ä¸ªGPUæœ€å¤§å†…å­˜ä½¿ç”¨ç‡ï¼ˆ0-1ï¼‰

    # è®¡ç®—é…ç½®
    ode_solver::Symbol  # :Tsit5, :RK4, :Euler
    abstol::Float64
    reltol::Float64
    maxiters::Int

    # å¹¶è¡Œé…ç½®
    async_processing::Bool  # å¼‚æ­¥å¤„ç†
    overlap_transfers::Bool  # é‡å æ•°æ®ä¼ è¾“å’Œè®¡ç®—

    # è°ƒè¯•é…ç½®
    verbose::Bool
    profile_gpu::Bool
end

"""
    default_gpu_config()

åˆ›å»ºé»˜è®¤GPUé…ç½®
"""
function default_gpu_config()
    return GPUParallelConfig(
        false,                # use_multi_gpu (å…ˆç”¨å•GPUç¨³å®šè·¯å¾„)
        2000,                 # gpu_batch_size
        0.8,                  # max_memory_usage
        :GPUTsit5,            # ode_solver
        1e-6,                 # abstol
        1e-3,                 # reltol
        10000,                # maxiters
        false,                # async_processing
        true,                 # overlap_transfers
        false,                # verbose
        false                 # profile_gpu
    )
end

"""
    OptimizedGPUSolver

ä¼˜åŒ–çš„GPUå¹¶è¡Œæ±‚è§£å™¨
"""
mutable struct OptimizedGPUSolver
    config::GPUParallelConfig
    gpu_devices::Vector{Int}
    gpu_streams::Vector{Any}  # CUDA streams for async processing
    memory_pools::Vector{Any}  # GPU memory pools

    # æ€§èƒ½ç›‘æ§
    solve_times::Vector{Float64}
    memory_usage::Vector{Float64}
    throughput::Vector{Float64}

    function OptimizedGPUSolver(config::GPUParallelConfig)
        solver = new()
        solver.config = config
        solver.solve_times = Float64[]
        solver.memory_usage = Float64[]
        solver.throughput = Float64[]

        initialize_gpu_resources!(solver)
        return solver
    end
end
# GPU-friendly parameter struct
struct GPUParams
    k1f::Float64; k1r::Float64; k2f::Float64; k2r::Float64
    k3f::Float64; k3r::Float64; k4f::Float64; k4r::Float64
end

@inline function to_su0(u::AbstractVector)
    return SVector{7,Float64}(
        Float64(u[1]), Float64(u[2]), Float64(u[3]),
        Float64(u[4]), Float64(u[5]), Float64(u[6]), Float64(u[7])
    )
end

@inline function to_pp(p::AbstractVector)
    return GPUParams(Float64(p[1]), Float64(p[2]), Float64(p[3]), Float64(p[4]),
                     Float64(p[5]), Float64(p[6]), Float64(p[7]), Float64(p[8]))
end


"""
    initialize_gpu_resources!(solver::OptimizedGPUSolver)

åˆå§‹åŒ–GPUèµ„æº
"""
function initialize_gpu_resources!(solver::OptimizedGPUSolver)
    if !CUDA.functional()
        error("CUDA is not functional")
    end

    n_devices = CUDA.ndevices()
    if n_devices == 0
        error("No CUDA devices found")
    end

    # é€‰æ‹©è¦ä½¿ç”¨çš„GPUè®¾å¤‡
    if solver.config.use_multi_gpu && n_devices > 1
        solver.gpu_devices = collect(0:min(n_devices-1, 3))  # æœ€å¤šä½¿ç”¨4ä¸ªGPU
        println("ğŸš€ åˆå§‹åŒ–å¤šGPUå¹¶è¡Œï¼šä½¿ç”¨ $(length(solver.gpu_devices)) ä¸ªGPU")
    else
        solver.gpu_devices = [0]
        println("ğŸš€ åˆå§‹åŒ–å•GPUæ¨¡å¼")
    end

    # ä¸ºæ¯ä¸ªGPUåˆ›å»ºCUDA streamå’Œå†…å­˜æ± 
    solver.gpu_streams = []
    solver.memory_pools = []

    for gpu_id in solver.gpu_devices
        CUDA.device!(gpu_id)

        # åˆ›å»ºä¸“ç”¨streamç”¨äºå¼‚æ­¥è®¡ç®—
        stream = CUDA.stream()
        push!(solver.gpu_streams, stream)

        # é¢„åˆ†é…å†…å­˜æ± 
        device_memory = CUDA.totalmem(CUDA.device())
        allocated_memory = device_memory * solver.config.max_memory_usage

        # é¢„çƒ­GPUå’Œåˆ†é…å†…å­˜æ± 
        dummy_array = CUDA.zeros(Float32, 1000, 1000)
        CUDA.unsafe_free!(dummy_array)

        push!(solver.memory_pools, nothing)  # å ä½ç¬¦ï¼Œå®é™…ä½¿ç”¨CUDAå†…å­˜ç®¡ç†

        if solver.config.verbose
            println("  GPU $gpu_id: $(round(device_memory/1e9, digits=2))GB æ€»å†…å­˜, " *
                   "$(round(allocated_memory/1e9, digits=2))GB å¯ç”¨")
        end
    end

    # åˆ‡å›ä¸»GPU
    CUDA.device!(solver.gpu_devices[1])

    println("âœ… GPUèµ„æºåˆå§‹åŒ–å®Œæˆ")
end

"""
    reaction_ode_gpu!(du, u, p, t)

GPUä¼˜åŒ–çš„ODEå‡½æ•°ï¼ˆæ”¯æŒCUDAæ•°ç»„ï¼‰
"""
function reaction_ode_gpu!(du, u, p, t)
    # è§£æ„å‚æ•°
    k1f = p.k1f; k1r = p.k1r; k2f = p.k2f; k2r = p.k2r
    k3f = p.k3f; k3r = p.k3r; k4f = p.k4f; k4r = p.k4r

    # çŠ¶æ€å˜é‡: A, B, C, E1, E2, AE1, BE2
    A, B, C, E1, E2, AE1, BE2 = u

    # æ•°å€¼ç¨³å®šæ€§ï¼šå¯¹çŠ¶æ€åšåŒºé—´è£å‰ªï¼Œé¿å…çˆ†ç‚¸æˆ–è´Ÿå€¼
    @inbounds begin
        A   = clamp(A,   0.0, 1.0e9)
        B   = clamp(B,   0.0, 1.0e9)
        C   = clamp(C,   0.0, 1.0e9)
        E1  = clamp(E1,  0.0, 1.0e9)
        E2  = clamp(E2,  0.0, 1.0e9)
        AE1 = clamp(AE1, 0.0, 1.0e9)
        BE2 = clamp(BE2, 0.0, 1.0e9)
    end

    # æ•°å€¼ç¨³å®šçš„ä¹˜ç§¯ï¼ˆé¿å…æº¢å‡ºï¼‰
    AE1_f = clamp(A * E1, -1.0e12, 1.0e12)
    BE2_f = clamp(B * E2, -1.0e12, 1.0e12)

    # ååº”é€Ÿç‡æ–¹ç¨‹ï¼ˆä½¿ç”¨å®‰å…¨ä¹˜ç§¯ï¼‰
    du[1] = -k1f*AE1_f + k1r*AE1                        # dA/dt
    du[2] = k2f*AE1 - k2r*clamp(B * E1, -1.0e12, 1.0e12) - k3f*BE2_f + k3r*BE2   # dB/dt
    du[3] = k4f*BE2 - k4r*clamp(C * E2, -1.0e12, 1.0e12)                         # dC/dt
    du[4] = -k1f*AE1_f + k1r*AE1 + k2f*AE1 - k2r*clamp(B * E1, -1.0e12, 1.0e12)  # dE1/dt
    du[5] = -k3f*BE2_f + k3r*BE2 + k4f*BE2 - k4r*clamp(C * E2, -1.0e12, 1.0e12)  # dE2/dt
    du[6] = k1f*AE1_f - k1r*AE1 - k2f*AE1 + k2r*clamp(B * E1, -1.0e12, 1.0e12)   # dAE1/dt
    du[7] = k3f*BE2_f - k3r*BE2 - k4f*BE2 + k4r*clamp(C * E2, -1.0e12, 1.0e12)   # dBE2/dt

    # ç¡®ä¿å¯¼æ•°æœ‰é™
    @inbounds for i in 1:7
        val = du[i]
        if !isfinite(val)
            du[i] = 0.0
        else
            du[i] = clamp(val, -1.0e12, 1.0e12)
        end
    end

    return nothing
end

"""
    reaction_ode_gpu_oop(u, p, t) -> SVector{7,Float32}

Out-of-place GPU ODE for kernel execution
"""
function reaction_ode_gpu_oop(u, p, t)
    # parameters
    k1f, k1r, k2f, k2r = p.k1f, p.k1r, p.k2f, p.k2r
    k3f, k3r, k4f, k4r = p.k3f, p.k3r, p.k4f, p.k4r

    # state with non-negativity
    A   = ifelse(u[1] > 0.0, u[1], 0.0)
    B   = ifelse(u[2] > 0.0, u[2], 0.0)
    C   = ifelse(u[3] > 0.0, u[3], 0.0)
    E1  = ifelse(u[4] > 0.0, u[4], 0.0)
    E2  = ifelse(u[5] > 0.0, u[5], 0.0)
    AE1 = ifelse(u[6] > 0.0, u[6], 0.0)
    BE2 = ifelse(u[7] > 0.0, u[7], 0.0)

    du1 = -k1f*A*E1 + k1r*AE1
    du2 =  k2f*AE1 - k2r*B*E1 - k3f*B*E2 + k3r*BE2
    du3 =  k4f*BE2 - k4r*C*E2
    du4 = -k1f*A*E1 + k1r*AE1 + k2f*AE1 - k2r*B*E1
    du5 = -k3f*B*E2 + k3r*BE2 + k4f*BE2 - k4r*C*E2
    du6 =  k1f*A*E1 - k1r*AE1 - k2f*AE1 + k2r*B*E1
    du7 =  k3f*B*E2 - k3r*BE2 - k4f*BE2 + k4r*C*E2

    return SVector{7,Float64}(du1, du2, du3, du4, du5, du6, du7)
end

"""
    solve_batch_gpu_optimized(solver, X_samples, tspan, target_vars)

ä¼˜åŒ–çš„GPUæ‰¹å¤„ç†æ±‚è§£
"""
function solve_batch_gpu_optimized(solver::OptimizedGPUSolver, X_samples::Matrix{Float64},
                                  tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol})
    n_samples = size(X_samples, 1)
    n_outputs = length(target_vars)
    n_gpus = length(solver.gpu_devices)

    if solver.config.verbose
        println("ğŸš€ å¼€å§‹GPUä¼˜åŒ–æ‰¹å¤„ç†: $(n_samples) æ ·æœ¬, $(n_gpus) GPU")
    end

    start_time = time()
    results = zeros(Float64, n_samples, n_outputs)

    if n_gpus > 1 && solver.config.async_processing
        # å¤šGPUå¼‚æ­¥å¹¶è¡Œå¤„ç†
        results = solve_multi_gpu_async(solver, X_samples, tspan, target_vars)
    else
        # å•GPUæˆ–åŒæ­¥å¤„ç†
        results = solve_single_gpu_optimized(solver, X_samples, tspan, target_vars)
    end

    # è®°å½•æ€§èƒ½æŒ‡æ ‡
    solve_time = time() - start_time
    push!(solver.solve_times, solve_time)
    push!(solver.throughput, n_samples / solve_time)

    if solver.config.verbose
        println("âœ… GPUæ±‚è§£å®Œæˆ: $(n_samples) æ ·æœ¬ç”¨æ—¶ $(round(solve_time, digits=2))s")
        println("   ååé‡: $(round(n_samples/solve_time, digits=1)) æ ·æœ¬/ç§’")
    end

    return results
end

"""
    solve_multi_gpu_async(solver, X_samples, tspan, target_vars)

çœŸæ­£çš„å¤šGPUå¼‚æ­¥å¹¶è¡Œå¤„ç†
"""
function solve_multi_gpu_async(solver::OptimizedGPUSolver, X_samples::Matrix{Float64},
                              tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol})
    n_samples = size(X_samples, 1)
    n_outputs = length(target_vars)
    n_gpus = length(solver.gpu_devices)

    # æ™ºèƒ½è´Ÿè½½å‡è¡¡ï¼šæ ¹æ®GPUèƒ½åŠ›åˆ†é…ä»»åŠ¡
    gpu_capabilities = get_gpu_capabilities(solver)
    sample_allocation = allocate_samples_smart(n_samples, gpu_capabilities)

    if solver.config.verbose
        println("ğŸ“Š æ™ºèƒ½ä»»åŠ¡åˆ†é…:")
        for (i, (gpu_id, n_allocated)) in enumerate(zip(solver.gpu_devices, sample_allocation))
            percentage = round(n_allocated/n_samples*100, digits=1)
            println("  GPU $gpu_id: $(n_allocated) æ ·æœ¬ ($(percentage)%)")
        end
    end

    # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
    tasks = []
    results_futures = []

    start_idx = 1
    for (gpu_idx, n_allocated) in enumerate(sample_allocation)
        if n_allocated == 0
            continue
        end

        end_idx = start_idx + n_allocated - 1
        X_chunk = X_samples[start_idx:end_idx, :]
        gpu_id = solver.gpu_devices[gpu_idx]
        stream = solver.gpu_streams[gpu_idx]

        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
        task = @async solve_gpu_chunk_async(solver, X_chunk, tspan, target_vars, gpu_id, stream)
        push!(tasks, task)
        push!(results_futures, (start_idx, end_idx, task))

        start_idx = end_idx + 1
    end

    # æ”¶é›†æ‰€æœ‰å¼‚æ­¥ç»“æœ
    final_results = zeros(Float64, n_samples, n_outputs)

    for (start_idx, end_idx, task) in results_futures
        try
            chunk_results = fetch(task)
            final_results[start_idx:end_idx, :] = chunk_results
        catch e
            println("âš ï¸  GPUä»»åŠ¡å¤±è´¥ï¼Œæ ‡è®°ä¸ºNaNå¹¶ç»§ç»­: $(typeof(e))")
            final_results[start_idx:end_idx, :] .= NaN
        end
    end

    return final_results
end

"""
    solve_gpu_chunk_async(solver, X_chunk, tspan, target_vars, gpu_id, stream)

å¼‚æ­¥GPUå—å¤„ç†
"""
function solve_gpu_chunk_async(solver::OptimizedGPUSolver, X_chunk::Matrix{Float64},
                              tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol},
                              gpu_id::Int, stream)
    # åˆ‡æ¢åˆ°æŒ‡å®šGPU
    CUDA.device!(gpu_id)

    n_chunk = size(X_chunk, 1)
    n_outputs = length(target_vars)
    chunk_results = zeros(Float64, n_chunk, n_outputs)

    try
        # æ•°æ®ä¼ è¾“åˆ°GPUï¼ˆå¼‚æ­¥ï¼‰
        X_gpu = CuArray{Float64}(X_chunk)

        # å‡†å¤‡åˆå§‹æ¡ä»¶å’Œå‚æ•°
        u0_array = prepare_initial_conditions_gpu(X_gpu)
        p_array = prepare_parameters_gpu(X_gpu)

        # ä½¿ç”¨EnsembleGPUArrayè¿›è¡ŒçœŸæ­£çš„GPUå¹¶è¡Œæ±‚è§£
        prob_func = (prob, i, repeat) -> remake(prob,
            u0 = u0_array[:, i],
            p = p_array[:, i]
        )

        # åŸºç¡€ODEé—®é¢˜
        u0_base = u0_array[:, 1]
        p_base = p_array[:, 1]
        prob_base = ODEProblem(reaction_ode_gpu!, u0_base, tspan, p_base)

        # é›†æˆé—®é¢˜
        ensemble_prob = EnsembleProblem(prob_base, prob_func=prob_func)

        # GPUå¹¶è¡Œæ±‚è§£
        sol = solve(ensemble_prob,
            get_gpu_solver(solver.config.ode_solver),
            EnsembleGPUArray(),
            trajectories = n_chunk,
            abstol = solver.config.abstol,
            reltol = solver.config.reltol,
            maxiters = solver.config.maxiters,
            saveat = tspan[2]  # åªä¿å­˜ç»ˆç‚¹
        )

        # æå–ç›®æ ‡å˜é‡ï¼ˆåœ¨CPUä¸Šä»æ¯æ¡è½¨è¿¹çš„prob.pè¯»å–å‚æ•°ï¼‰
        chunk_results = extract_and_transfer_results(sol, target_vars)

    catch e
        bt = catch_backtrace()
        println("âš ï¸  GPU $gpu_id æ±‚è§£å¤±è´¥ï¼Œæ ‡è®°ä¸ºNaNå¹¶ç»§ç»­: $(typeof(e))")
        println(sprint(showerror, e, bt))
        chunk_results .= NaN
    end

    return chunk_results
end

"""
    solve_single_gpu_optimized(solver, X_samples, tspan, target_vars)

ä¼˜åŒ–çš„å•GPUå¤„ç†
"""
function solve_single_gpu_optimized(solver::OptimizedGPUSolver, X_samples::Matrix{Float64},
                                   tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol})
    n_samples = size(X_samples, 1)
    n_outputs = length(target_vars)
    gpu_id = solver.gpu_devices[1]

    CUDA.device!(gpu_id)

    # è®¡ç®—æœ€ä¼˜æ‰¹å¤§å°
    optimal_batch_size = calculate_optimal_batch_size(solver, n_samples, size(X_samples, 2))

    if solver.config.verbose
        println("ğŸ“Š ä¼˜åŒ–æ‰¹å¤„ç†: æ‰¹å¤§å° = $optimal_batch_size")
    end

    results = zeros(Float64, n_samples, n_outputs)

    # åˆ†æ‰¹å¤„ç†
    @showprogress "GPUå¤„ç†è¿›åº¦: " for start_idx in 1:optimal_batch_size:n_samples
        end_idx = min(start_idx + optimal_batch_size - 1, n_samples)
        batch_size = end_idx - start_idx + 1

        X_batch = X_samples[start_idx:end_idx, :]

        try
            batch_results = process_gpu_batch(solver, X_batch, tspan, target_vars)
            results[start_idx:end_idx, :] = batch_results
        catch e
            bt = catch_backtrace()
            println("âš ï¸  æ‰¹å¤„ç†å¤±è´¥ï¼Œæ ‡è®°ä¸ºNaNå¹¶ç»§ç»­: $(typeof(e))")
            println(sprint(showerror, e, bt))
            results[start_idx:end_idx, :] .= NaN
        end

        # å†…å­˜æ¸…ç†
        if start_idx % (optimal_batch_size * 5) == 1
            CUDA.reclaim()
        end
    end

    return results
end

"""
    process_gpu_batch(solver, X_batch, tspan, target_vars)

å¤„ç†å•ä¸ªGPUæ‰¹æ¬¡
"""
function process_gpu_batch(solver::OptimizedGPUSolver, X_batch::Matrix{Float64},
                          tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol})
    n_batch = size(X_batch, 1)
    n_outputs = length(target_vars)

    # è½¬æ¢ä¸ºGPUæ•°ç»„
    X_gpu = CuArray{Float64}(X_batch)

    # å‡†å¤‡åˆå§‹æ¡ä»¶å’Œå‚æ•°ï¼ˆæ‰¹é‡å¤„ç†ï¼‰
    u0_array = prepare_initial_conditions_gpu(X_gpu)
    p_array = prepare_parameters_gpu(X_gpu)

    # GPUå¹¶è¡ŒODEæ±‚è§£
    results_gpu = solve_ode_batch_gpu(solver, u0_array, p_array, tspan, n_batch)

    # æå–ç›®æ ‡å˜é‡å¹¶è½¬å›CPU
    batch_results = extract_and_transfer_results(results_gpu, target_vars)

    return batch_results
end

"""
    prepare_initial_conditions_gpu(X_gpu::CuArray)

åœ¨GPUä¸Šå‡†å¤‡åˆå§‹æ¡ä»¶
"""
function prepare_initial_conditions_gpu(X_gpu::CuArray)
    n_samples = size(X_gpu, 1)
    u0_array = CuArray{Float64}(undef, 7, n_samples)  # 7ä¸ªçŠ¶æ€å˜é‡

    # GPU kernelä¼šæ›´é«˜æ•ˆï¼Œè¿™é‡Œç®€åŒ–å®ç°
    u0_array[1, :] = X_gpu[:, 9]   # A
    u0_array[2, :] = X_gpu[:, 10]  # B
    u0_array[3, :] = X_gpu[:, 11]  # C
    u0_array[4, :] = X_gpu[:, 12]  # E1
    u0_array[5, :] = X_gpu[:, 13]  # E2
    u0_array[6, :] .= 0.0          # AE1
    u0_array[7, :] .= 0.0          # BE2

    return u0_array
end

"""
    prepare_parameters_gpu(X_gpu::CuArray)

åœ¨GPUä¸Šå‡†å¤‡å‚æ•°
"""
function prepare_parameters_gpu(X_gpu::CuArray)
    n_samples = size(X_gpu, 1)
    p_array = CuArray{Float64}(undef, 8, n_samples)  # 8ä¸ªååº”å¸¸æ•°

    p_array[1, :] = X_gpu[:, 1]  # k1f
    p_array[2, :] = X_gpu[:, 2]  # k1r
    p_array[3, :] = X_gpu[:, 3]  # k2f
    p_array[4, :] = X_gpu[:, 4]  # k2r
    p_array[5, :] = X_gpu[:, 5]  # k3f
    p_array[6, :] = X_gpu[:, 6]  # k3r
    p_array[7, :] = X_gpu[:, 7]  # k4f
    p_array[8, :] = X_gpu[:, 8]  # k4r

    return p_array
end

"""
    solve_ode_batch_gpu(solver, u0_array, p_array, tspan, n_batch)

GPUæ‰¹é‡ODEæ±‚è§£
"""
function solve_ode_batch_gpu(solver::OptimizedGPUSolver, u0_array::CuArray, p_array::CuArray,
                            tspan::Tuple{Float64, Float64}, n_batch::Int)
    # ä½¿ç”¨EnsembleGPUArray + in-place Float64 ODEï¼ˆæ›´ç¨³å®šï¼‰
    u0_mat = Array{Float64}(undef, 7, n_batch)
    p_vec = Vector{GPUParams}(undef, n_batch)
    @inbounds for i in 1:n_batch
        u0_mat[:, i] = Array(u0_array[:, i])
        pi = Array(p_array[:, i])
        p_vec[i] = GPUParams(pi[1], pi[2], pi[3], pi[4], pi[5], pi[6], pi[7], pi[8])
    end

    prob_func = (prob, i, repeat) -> remake(prob, u0=u0_mat[:, i], p=p_vec[i])

    prob_base = ODEProblem(reaction_ode_gpu!, u0_mat[:, 1], tspan, p_vec[1]; isoutofdomain = (u,p,t)->any(!isfinite, u))
    ensemble_prob = EnsembleProblem(prob_base, prob_func=prob_func)

    sol = solve(ensemble_prob,
        get_gpu_solver(solver.config.ode_solver),
        EnsembleGPUArray(CUDA.CUDABackend());
        trajectories = n_batch,
        abstol = min(solver.config.abstol, 1e-8),
        reltol = min(solver.config.reltol, 1e-6),
        maxiters = solver.config.maxiters,
        saveat = [tspan[2]],
        dt = (tspan[2]-tspan[1]) / 10000.0,
        dtmax = (tspan[2]-tspan[1]) / 100.0,
        adaptive = false
    )

    # è°ƒè¯•ï¼šæ‰“å°éƒ¨åˆ†è½¨è¿¹retcodeä¸ç»ˆæ€æ˜¯å¦æœ‰é™
    try
        total = length(sol)
        ok = 0
        limit = min(10, total)
        println("ğŸ” GPUè°ƒè¯•: é‡‡æ · $limit/$total æ¡è½¨è¿¹")
        for i in 1:limit
            r = sol[i].retcode
            print("  traj ", i, " retcode=", r)
            if r == :Success && length(sol[i].u) > 0
                uend = sol[i].u[end]
                finite = all(isfinite, uend)
                println(", uend_finite=", finite)
                if finite
                    ok += 1
                end
            else
                println()
            end
        end
        println("âœ… æœ‰é™ç»ˆæ€æ ·æœ¬: ", ok, "/", limit)
        if limit > 0
            try
                uend = sol[1].u[end]
                println("ğŸ”¬ ç¤ºä¾‹ç»ˆæ€[1]: ", uend)
            catch e
                println("âš ï¸  æ— æ³•æ‰“å°ç¤ºä¾‹ç»ˆæ€: ", typeof(e))
            end
        end
    catch e
        println("âš ï¸  è°ƒè¯•ä¿¡æ¯æ‰“å°å¤±è´¥: ", typeof(e))
    end

    return sol
end

"""
    extract_and_transfer_results(sol, target_vars, X_gpu)

æå–ç»“æœå¹¶ä¼ è¾“å›CPU
"""
function extract_and_transfer_results(sol, target_vars::Vector{Symbol})
    n_batch = length(sol)
    n_outputs = length(target_vars)

    results = zeros(Float64, n_batch, n_outputs)

    # ä»è§£ä¸­æå–ç›®æ ‡å˜é‡
    for i in 1:n_batch
        sol_i = sol[i]
        if sol_i.retcode == :Success && length(sol_i.u) > 0
            final_state = Array(sol_i.u[end])  # è½¬å›CPUè¿›è¡Œæå–

            # è®¡ç®—ç›®æ ‡å˜é‡ï¼ˆå‚æ•°ä»prob.pè¯»å–ï¼Œå…¼å®¹isbitsï¼‰
            for (j, var) in enumerate(target_vars)
                results[i, j] = extract_single_target_variable(final_state, var, sol_i)
            end
        else
            # æ±‚è§£å¤±è´¥ï¼Œå¡«å…¥NaN
            results[i, :] .= NaN32
        end
    end

    return results
end

"""
    extract_single_target_variable(final_state, var, sol, params)

æå–å•ä¸ªç›®æ ‡å˜é‡
"""
function extract_single_target_variable(final_state::Vector{Float64}, var::Symbol, sol)
    # final_state: [A, B, C, E1, E2, AE1, BE2]
    if var == :A_final
        return final_state[1]
    elseif var == :B_final
        return final_state[2]
    elseif var == :C_final
        return final_state[3]
    elseif var == :v1_mean
        # è®¡ç®—å¹³å‡ååº”é€Ÿç‡ v1 = k1f*A*E1 - k1r*AE1
        p = sol.prob.p
        k1f = Base.hasproperty(p, :k1f) ? p.k1f : p[1]
        k1r = Base.hasproperty(p, :k1r) ? p.k1r : p[2]
        A_mean = mean([sol.u[i][1] for i in 1:length(sol.u)])
        E1_mean = mean([sol.u[i][4] for i in 1:length(sol.u)])
        AE1_mean = mean([sol.u[i][6] for i in 1:length(sol.u)])
        return k1f * A_mean * E1_mean - k1r * AE1_mean
    elseif var == :v2_mean
        # è®¡ç®—å¹³å‡ååº”é€Ÿç‡ v2 = k3f*B*E2 - k3r*BE2
        p = sol.prob.p
        k3f = Base.hasproperty(p, :k3f) ? p.k3f : p[5]
        k3r = Base.hasproperty(p, :k3r) ? p.k3r : p[6]
        B_mean = mean([sol.u[i][2] for i in 1:length(sol.u)])
        E2_mean = mean([sol.u[i][5] for i in 1:length(sol.u)])
        BE2_mean = mean([sol.u[i][7] for i in 1:length(sol.u)])
        return k3f * B_mean * E2_mean - k3r * BE2_mean
    else
        return NaN
    end
end

"""
    get_gpu_capabilities(solver)

è·å–GPUè®¡ç®—èƒ½åŠ›
"""
function get_gpu_capabilities(solver::OptimizedGPUSolver)
    capabilities = Float64[]

    for gpu_id in solver.gpu_devices
        CUDA.device!(gpu_id)
        device = CUDA.device()

        # åŸºäºå†…å­˜å’Œè®¡ç®—èƒ½åŠ›è¯„åˆ†
        memory_gb = CUDA.totalmem(device) / 1e9
        compute_capability = CUDA.capability(device)

        # ç®€å•çš„èƒ½åŠ›è¯„åˆ†
        score = memory_gb * (compute_capability.major * 10 + compute_capability.minor)
        push!(capabilities, score)
    end

    return capabilities
end

"""
    allocate_samples_smart(n_samples, capabilities)

æ™ºèƒ½æ ·æœ¬åˆ†é…
"""
function allocate_samples_smart(n_samples::Int, capabilities::Vector{Float64})
    total_capability = sum(capabilities)
    allocation = Int[]

    remaining_samples = n_samples
    for i in 1:length(capabilities)-1
        proportion = capabilities[i] / total_capability
        allocated = round(Int, n_samples * proportion)
        push!(allocation, allocated)
        remaining_samples -= allocated
    end

    # å‰©ä½™æ ·æœ¬åˆ†é…ç»™æœ€åä¸€ä¸ªGPU
    push!(allocation, remaining_samples)

    return allocation
end

"""
    calculate_optimal_batch_size(solver, n_samples, n_features)

è®¡ç®—æœ€ä¼˜æ‰¹å¤§å°
"""
function calculate_optimal_batch_size(solver::OptimizedGPUSolver, n_samples::Int, n_features::Int)
    gpu_id = solver.gpu_devices[1]
    CUDA.device!(gpu_id)

    available_memory = CUDA.totalmem(CUDA.device()) * solver.config.max_memory_usage

    # ä¼°ç®—æ¯ä¸ªæ ·æœ¬çš„å†…å­˜éœ€æ±‚
    memory_per_sample = n_features * 8 * 10  # Float64, çº¦10å€æ”¾å¤§ç³»æ•°

    theoretical_batch_size = floor(Int, available_memory / memory_per_sample)

    # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
    optimal_batch_size = min(
        theoretical_batch_size,
        solver.config.gpu_batch_size,
        n_samples
    )

    return max(optimal_batch_size, 1)
end

"""
    get_gpu_solver(solver_type::Symbol)

è·å–GPUæ±‚è§£å™¨ - ä½¿ç”¨Tsit5()é…åˆEnsembleGPUArray(0)
"""
function get_gpu_solver(solver_type::Symbol)
    # Use Rosenbrock23 with finite-difference Jacobian on GPU (Float64)
    return Rosenbrock23(autodiff = AutoFiniteDiff())
end

"""
    solve_cpu_fallback(X_batch, tspan, target_vars)

CPUå›é€€æ±‚è§£
"""
# å·²ç§»é™¤CPUå›é€€ï¼šçº¯GPUæ‰§è¡Œï¼Œå¤±è´¥æ ·æœ¬å°†æ ‡è®°ä¸ºNaN

"""
    cleanup_gpu_resources!(solver::OptimizedGPUSolver)

æ¸…ç†GPUèµ„æº
"""
function cleanup_gpu_resources!(solver::OptimizedGPUSolver)
    println("ğŸ§¹ æ¸…ç†GPUèµ„æº...")

    for gpu_id in solver.gpu_devices
        CUDA.device!(gpu_id)
        CUDA.reclaim()
    end

    println("âœ… GPUèµ„æºæ¸…ç†å®Œæˆ")
end

"""
    benchmark_gpu_solver(solver, test_samples, tspan, target_vars)

GPUæ±‚è§£å™¨æ€§èƒ½æµ‹è¯•
"""
function benchmark_gpu_solver(solver::OptimizedGPUSolver, test_samples::Matrix{Float64},
                             tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol})
    println("ğŸƒ GPUæ€§èƒ½æµ‹è¯•...")

    # é¢„çƒ­
    warmup_samples = test_samples[1:min(100, size(test_samples, 1)), :]
    solve_batch_gpu_optimized(solver, warmup_samples, tspan, target_vars)

    # æ­£å¼æµ‹è¯•
    start_time = time()
    results = solve_batch_gpu_optimized(solver, test_samples, tspan, target_vars)
    end_time = time()

    solve_time = end_time - start_time
    throughput = size(test_samples, 1) / solve_time

    println("ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ:")
    println("  æ ·æœ¬æ•°é‡: $(size(test_samples, 1))")
    println("  æ±‚è§£æ—¶é—´: $(round(solve_time, digits=3))s")
    println("  ååé‡: $(round(throughput, digits=1)) æ ·æœ¬/ç§’")

    # è®¡ç®—GPUåˆ©ç”¨ç‡
    if solver.config.profile_gpu
        # è¿™é‡Œå¯ä»¥æ·»åŠ GPU profilingä»£ç 
        println("  GPUåˆ©ç”¨ç‡åˆ†æéœ€è¦ä¸“ä¸šprofilingå·¥å…·")
    end

    return results, solve_time, throughput
end



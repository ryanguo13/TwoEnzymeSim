"""
ä¼˜åŒ–çš„GPUå¹¶è¡Œæ±‚è§£å™¨

å®ç°çœŸæ­£çš„å¤šGPUå¹¶è¡Œå¤„ç†ï¼Œè§£å†³ç°æœ‰å®ç°ä¸­çš„åºåˆ—åŒ–å’ŒCPUå›é€€é—®é¢˜

ä¸»è¦æ”¹è¿›ï¼š
1. çœŸæ­£çš„å¹¶è¡ŒGPUè®¡ç®—ï¼ˆåŒæ—¶ä½¿ç”¨å¤šä¸ªGPUï¼‰
2. GPUå†…å­˜ä¼˜åŒ–å’Œæ‰¹å¤„ç†
3. CUDAå†…æ ¸çº§åˆ«çš„ODEæ±‚è§£
4. æœ€å°åŒ–CPU-GPUæ•°æ®ä¼ è¾“
5. æ™ºèƒ½è´Ÿè½½å‡è¡¡å’Œé”™è¯¯æ¢å¤
"""

using CUDA
using DifferentialEquations
using DiffEqGPU
using Distributed
using Printf
using LinearAlgebra
using Statistics
using ProgressMeter

"""
    GPUParallelConfig

GPUå¹¶è¡Œè®¡ç®—é…ç½®
"""
struct GPUParallelConfig
    # GPUè®¾å¤‡é…ç½®
    use_multi_gpu::Bool
    gpu_batch_size::Int
    max_memory_usage::Float64  # æ¯ä¸ªGPUæœ€å¤§å†…å­˜ä½¿ç”¨ç‡ï¼ˆ0-1ï¼‰

    # è®¡ç®—é…ç½®
    ode_solver::Symbol  # :Tsit5, :RK4, :Euler
    abstol::Float64
    reltol::Float64
    maxiters::Int

    # å¹¶è¡Œé…ç½®
    async_processing::Bool  # å¼‚æ­¥å¤„ç†
    overlap_transfers::Bool  # é‡å æ•°æ®ä¼ è¾“å’Œè®¡ç®—

    # è°ƒè¯•é…ç½®
    verbose::Bool
    profile_gpu::Bool
end

"""
    default_gpu_config()

åˆ›å»ºé»˜è®¤GPUé…ç½®
"""
function default_gpu_config()
    return GPUParallelConfig(
        CUDA.ndevices() > 1,  # use_multi_gpu
        1000,                 # gpu_batch_size
        0.8,                  # max_memory_usage
        :Tsit5,               # ode_solver
        1e-6,                 # abstol
        1e-3,                 # reltol
        10000,                # maxiters
        true,                 # async_processing
        true,                 # overlap_transfers
        false,                # verbose
        false                 # profile_gpu
    )
end

"""
    OptimizedGPUSolver

ä¼˜åŒ–çš„GPUå¹¶è¡Œæ±‚è§£å™¨
"""
mutable struct OptimizedGPUSolver
    config::GPUParallelConfig
    gpu_devices::Vector{Int}
    gpu_streams::Vector{Any}  # CUDA streams for async processing
    memory_pools::Vector{Any}  # GPU memory pools

    # æ€§èƒ½ç›‘æ§
    solve_times::Vector{Float64}
    memory_usage::Vector{Float64}
    throughput::Vector{Float64}

    function OptimizedGPUSolver(config::GPUParallelConfig)
        solver = new()
        solver.config = config
        solver.solve_times = Float64[]
        solver.memory_usage = Float64[]
        solver.throughput = Float64[]

        initialize_gpu_resources!(solver)
        return solver
    end
end

"""
    initialize_gpu_resources!(solver::OptimizedGPUSolver)

åˆå§‹åŒ–GPUèµ„æº
"""
function initialize_gpu_resources!(solver::OptimizedGPUSolver)
    if !CUDA.functional()
        error("CUDA is not functional")
    end

    n_devices = CUDA.ndevices()
    if n_devices == 0
        error("No CUDA devices found")
    end

    # é€‰æ‹©è¦ä½¿ç”¨çš„GPUè®¾å¤‡
    if solver.config.use_multi_gpu && n_devices > 1
        solver.gpu_devices = collect(0:min(n_devices-1, 3))  # æœ€å¤šä½¿ç”¨4ä¸ªGPU
        println("ğŸš€ åˆå§‹åŒ–å¤šGPUå¹¶è¡Œï¼šä½¿ç”¨ $(length(solver.gpu_devices)) ä¸ªGPU")
    else
        solver.gpu_devices = [0]
        println("ğŸš€ åˆå§‹åŒ–å•GPUæ¨¡å¼")
    end

    # ä¸ºæ¯ä¸ªGPUåˆ›å»ºCUDA streamå’Œå†…å­˜æ± 
    solver.gpu_streams = []
    solver.memory_pools = []

    for gpu_id in solver.gpu_devices
        CUDA.device!(gpu_id)

        # åˆ›å»ºä¸“ç”¨streamç”¨äºå¼‚æ­¥è®¡ç®—
        stream = CUDA.stream()
        push!(solver.gpu_streams, stream)

        # é¢„åˆ†é…å†…å­˜æ± 
        device_memory = CUDA.totalmem(CUDA.device())
        allocated_memory = device_memory * solver.config.max_memory_usage

        # é¢„çƒ­GPUå’Œåˆ†é…å†…å­˜æ± 
        dummy_array = CUDA.zeros(Float32, 1000, 1000)
        CUDA.unsafe_free!(dummy_array)

        push!(solver.memory_pools, nothing)  # å ä½ç¬¦ï¼Œå®é™…ä½¿ç”¨CUDAå†…å­˜ç®¡ç†

        if solver.config.verbose
            println("  GPU $gpu_id: $(round(device_memory/1e9, digits=2))GB æ€»å†…å­˜, " *
                   "$(round(allocated_memory/1e9, digits=2))GB å¯ç”¨")
        end
    end

    # åˆ‡å›ä¸»GPU
    CUDA.device!(solver.gpu_devices[1])

    println("âœ… GPUèµ„æºåˆå§‹åŒ–å®Œæˆ")
end

"""
    reaction_ode_gpu!(du, u, p, t)

GPUä¼˜åŒ–çš„ODEå‡½æ•°ï¼ˆæ”¯æŒCUDAæ•°ç»„ï¼‰
"""
function reaction_ode_gpu!(du, u, p, t)
    # è§£æ„å‚æ•°
    k1f, k1r, k2f, k2r, k3f, k3r, k4f, k4r = p

    # çŠ¶æ€å˜é‡: A, B, C, E1, E2, AE1, BE2
    A, B, C, E1, E2, AE1, BE2 = u

    # ç¡®ä¿éè´Ÿï¼ˆä½¿ç”¨max.()è¿›è¡Œå‘é‡åŒ–æ“ä½œï¼‰
    A = max.(A, 0.0)
    B = max.(B, 0.0)
    C = max.(C, 0.0)
    E1 = max.(E1, 0.0)
    E2 = max.(E2, 0.0)
    AE1 = max.(AE1, 0.0)
    BE2 = max.(BE2, 0.0)

    # ååº”é€Ÿç‡æ–¹ç¨‹
    du[1] = -k1f*A*E1 + k1r*AE1                        # dA/dt
    du[2] = k2f*AE1 - k2r*B*E1 - k3f*B*E2 + k3r*BE2   # dB/dt
    du[3] = k4f*BE2 - k4r*C*E2                         # dC/dt
    du[4] = -k1f*A*E1 + k1r*AE1 + k2f*AE1 - k2r*B*E1  # dE1/dt
    du[5] = -k3f*B*E2 + k3r*BE2 + k4f*BE2 - k4r*C*E2  # dE2/dt
    du[6] = k1f*A*E1 - k1r*AE1 - k2f*AE1 + k2r*B*E1   # dAE1/dt
    du[7] = k3f*B*E2 - k3r*BE2 - k4f*BE2 + k4r*C*E2   # dBE2/dt

    return nothing
end

"""
    solve_batch_gpu_optimized(solver, X_samples, tspan, target_vars)

ä¼˜åŒ–çš„GPUæ‰¹å¤„ç†æ±‚è§£
"""
function solve_batch_gpu_optimized(solver::OptimizedGPUSolver, X_samples::Matrix{Float64},
                                  tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol})
    n_samples = size(X_samples, 1)
    n_outputs = length(target_vars)
    n_gpus = length(solver.gpu_devices)

    if solver.config.verbose
        println("ğŸš€ å¼€å§‹GPUä¼˜åŒ–æ‰¹å¤„ç†: $(n_samples) æ ·æœ¬, $(n_gpus) GPU")
    end

    start_time = time()
    results = zeros(Float32, n_samples, n_outputs)

    if n_gpus > 1 && solver.config.async_processing
        # å¤šGPUå¼‚æ­¥å¹¶è¡Œå¤„ç†
        results = solve_multi_gpu_async(solver, X_samples, tspan, target_vars)
    else
        # å•GPUæˆ–åŒæ­¥å¤„ç†
        results = solve_single_gpu_optimized(solver, X_samples, tspan, target_vars)
    end

    # è®°å½•æ€§èƒ½æŒ‡æ ‡
    solve_time = time() - start_time
    push!(solver.solve_times, solve_time)
    push!(solver.throughput, n_samples / solve_time)

    if solver.config.verbose
        println("âœ… GPUæ±‚è§£å®Œæˆ: $(n_samples) æ ·æœ¬ç”¨æ—¶ $(round(solve_time, digits=2))s")
        println("   ååé‡: $(round(n_samples/solve_time, digits=1)) æ ·æœ¬/ç§’")
    end

    return results
end

"""
    solve_multi_gpu_async(solver, X_samples, tspan, target_vars)

çœŸæ­£çš„å¤šGPUå¼‚æ­¥å¹¶è¡Œå¤„ç†
"""
function solve_multi_gpu_async(solver::OptimizedGPUSolver, X_samples::Matrix{Float64},
                              tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol})
    n_samples = size(X_samples, 1)
    n_outputs = length(target_vars)
    n_gpus = length(solver.gpu_devices)

    # æ™ºèƒ½è´Ÿè½½å‡è¡¡ï¼šæ ¹æ®GPUèƒ½åŠ›åˆ†é…ä»»åŠ¡
    gpu_capabilities = get_gpu_capabilities(solver)
    sample_allocation = allocate_samples_smart(n_samples, gpu_capabilities)

    if solver.config.verbose
        println("ğŸ“Š æ™ºèƒ½ä»»åŠ¡åˆ†é…:")
        for (i, (gpu_id, n_allocated)) in enumerate(zip(solver.gpu_devices, sample_allocation))
            percentage = round(n_allocated/n_samples*100, digits=1)
            println("  GPU $gpu_id: $(n_allocated) æ ·æœ¬ ($(percentage)%)")
        end
    end

    # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
    tasks = []
    results_futures = []

    start_idx = 1
    for (gpu_idx, n_allocated) in enumerate(sample_allocation)
        if n_allocated == 0
            continue
        end

        end_idx = start_idx + n_allocated - 1
        X_chunk = X_samples[start_idx:end_idx, :]
        gpu_id = solver.gpu_devices[gpu_idx]
        stream = solver.gpu_streams[gpu_idx]

        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
        task = @async solve_gpu_chunk_async(solver, X_chunk, tspan, target_vars, gpu_id, stream)
        push!(tasks, task)
        push!(results_futures, (start_idx, end_idx, task))

        start_idx = end_idx + 1
    end

    # æ”¶é›†æ‰€æœ‰å¼‚æ­¥ç»“æœ
    final_results = zeros(Float32, n_samples, n_outputs)

    for (start_idx, end_idx, task) in results_futures
        try
            chunk_results = fetch(task)
            final_results[start_idx:end_idx, :] = chunk_results
        catch e
            println("âš ï¸  GPUä»»åŠ¡å¤±è´¥ï¼Œä½¿ç”¨CPUå›é€€: $(typeof(e))")
            # CPUå›é€€å¤„ç†
            X_chunk = X_samples[start_idx:end_idx, :]
            fallback_results = solve_cpu_fallback(X_chunk, tspan, target_vars)
            final_results[start_idx:end_idx, :] = fallback_results
        end
    end

    return final_results
end

"""
    solve_gpu_chunk_async(solver, X_chunk, tspan, target_vars, gpu_id, stream)

å¼‚æ­¥GPUå—å¤„ç†
"""
function solve_gpu_chunk_async(solver::OptimizedGPUSolver, X_chunk::Matrix{Float64},
                              tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol},
                              gpu_id::Int, stream)
    # åˆ‡æ¢åˆ°æŒ‡å®šGPU
    CUDA.device!(gpu_id)

    n_chunk = size(X_chunk, 1)
    n_outputs = length(target_vars)
    chunk_results = zeros(Float32, n_chunk, n_outputs)

    try
        # æ•°æ®ä¼ è¾“åˆ°GPUï¼ˆå¼‚æ­¥ï¼‰
        X_gpu = CuArray{Float32}(X_chunk)

        # å‡†å¤‡åˆå§‹æ¡ä»¶å’Œå‚æ•°
        u0_array = prepare_initial_conditions_gpu(X_gpu)
        p_array = prepare_parameters_gpu(X_gpu)

        # ä½¿ç”¨EnsembleGPUArrayè¿›è¡ŒçœŸæ­£çš„GPUå¹¶è¡Œæ±‚è§£
        prob_func = (prob, i, repeat) -> remake(prob,
            u0 = u0_array[:, i],
            p = p_array[:, i]
        )

        # åŸºç¡€ODEé—®é¢˜
        u0_base = u0_array[:, 1]
        p_base = p_array[:, 1]
        prob_base = ODEProblem(reaction_ode_gpu!, u0_base, tspan, p_base)

        # é›†æˆé—®é¢˜
        ensemble_prob = EnsembleProblem(prob_base, prob_func=prob_func)

        # GPUå¹¶è¡Œæ±‚è§£
        sol = solve(ensemble_prob,
            get_gpu_solver(solver.config.ode_solver),
            EnsembleGPUArray(0),
            trajectories = n_chunk,
            abstol = solver.config.abstol,
            reltol = solver.config.reltol,
            maxiters = solver.config.maxiters,
            saveat = tspan[2]  # åªä¿å­˜ç»ˆç‚¹
        )

        # æå–ç›®æ ‡å˜é‡ï¼ˆåœ¨GPUä¸Šå®Œæˆï¼‰
        chunk_results = extract_target_variables_gpu(sol, target_vars, X_gpu)

    catch e
        println("âš ï¸  GPU $gpu_id æ±‚è§£å¤±è´¥ï¼Œä½¿ç”¨CPUå›é€€: $(typeof(e))")
        # å›é€€åˆ°CPU
        chunk_results = solve_cpu_fallback(X_chunk, tspan, target_vars)
    end

    return chunk_results
end

"""
    solve_single_gpu_optimized(solver, X_samples, tspan, target_vars)

ä¼˜åŒ–çš„å•GPUå¤„ç†
"""
function solve_single_gpu_optimized(solver::OptimizedGPUSolver, X_samples::Matrix{Float64},
                                   tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol})
    n_samples = size(X_samples, 1)
    n_outputs = length(target_vars)
    gpu_id = solver.gpu_devices[1]

    CUDA.device!(gpu_id)

    # è®¡ç®—æœ€ä¼˜æ‰¹å¤§å°
    optimal_batch_size = calculate_optimal_batch_size(solver, n_samples, size(X_samples, 2))

    if solver.config.verbose
        println("ğŸ“Š ä¼˜åŒ–æ‰¹å¤„ç†: æ‰¹å¤§å° = $optimal_batch_size")
    end

    results = zeros(Float32, n_samples, n_outputs)

    # åˆ†æ‰¹å¤„ç†
    @showprogress "GPUå¤„ç†è¿›åº¦: " for start_idx in 1:optimal_batch_size:n_samples
        end_idx = min(start_idx + optimal_batch_size - 1, n_samples)
        batch_size = end_idx - start_idx + 1

        X_batch = X_samples[start_idx:end_idx, :]

        try
            batch_results = process_gpu_batch(solver, X_batch, tspan, target_vars)
            results[start_idx:end_idx, :] = batch_results
        catch e
            println("âš ï¸  æ‰¹å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨CPUå›é€€: $(typeof(e))")
            batch_results = solve_cpu_fallback(X_batch, tspan, target_vars)
            results[start_idx:end_idx, :] = batch_results
        end

        # å†…å­˜æ¸…ç†
        if start_idx % (optimal_batch_size * 5) == 1
            CUDA.reclaim()
        end
    end

    return results
end

"""
    process_gpu_batch(solver, X_batch, tspan, target_vars)

å¤„ç†å•ä¸ªGPUæ‰¹æ¬¡
"""
function process_gpu_batch(solver::OptimizedGPUSolver, X_batch::Matrix{Float64},
                          tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol})
    n_batch = size(X_batch, 1)
    n_outputs = length(target_vars)

    # è½¬æ¢ä¸ºGPUæ•°ç»„
    X_gpu = CuArray{Float32}(X_batch)

    # å‡†å¤‡åˆå§‹æ¡ä»¶å’Œå‚æ•°ï¼ˆæ‰¹é‡å¤„ç†ï¼‰
    u0_array = prepare_initial_conditions_gpu(X_gpu)
    p_array = prepare_parameters_gpu(X_gpu)

    # GPUå¹¶è¡ŒODEæ±‚è§£
    results_gpu = solve_ode_batch_gpu(solver, u0_array, p_array, tspan, n_batch)

    # æå–ç›®æ ‡å˜é‡å¹¶è½¬å›CPU
    batch_results = extract_and_transfer_results(results_gpu, target_vars, X_gpu)

    return batch_results
end

"""
    prepare_initial_conditions_gpu(X_gpu::CuArray)

åœ¨GPUä¸Šå‡†å¤‡åˆå§‹æ¡ä»¶
"""
function prepare_initial_conditions_gpu(X_gpu::CuArray)
    n_samples = size(X_gpu, 1)
    u0_array = CuArray{Float32}(undef, 7, n_samples)  # 7ä¸ªçŠ¶æ€å˜é‡

    # GPU kernelä¼šæ›´é«˜æ•ˆï¼Œè¿™é‡Œç®€åŒ–å®ç°
    u0_array[1, :] = X_gpu[:, 9]   # A
    u0_array[2, :] = X_gpu[:, 10]  # B
    u0_array[3, :] = X_gpu[:, 11]  # C
    u0_array[4, :] = X_gpu[:, 12]  # E1
    u0_array[5, :] = X_gpu[:, 13]  # E2
    u0_array[6, :] .= 0.0f0        # AE1
    u0_array[7, :] .= 0.0f0        # BE2

    return u0_array
end

"""
    prepare_parameters_gpu(X_gpu::CuArray)

åœ¨GPUä¸Šå‡†å¤‡å‚æ•°
"""
function prepare_parameters_gpu(X_gpu::CuArray)
    n_samples = size(X_gpu, 1)
    p_array = CuArray{Float32}(undef, 8, n_samples)  # 8ä¸ªååº”å¸¸æ•°

    p_array[1, :] = X_gpu[:, 1]  # k1f
    p_array[2, :] = X_gpu[:, 2]  # k1r
    p_array[3, :] = X_gpu[:, 3]  # k2f
    p_array[4, :] = X_gpu[:, 4]  # k2r
    p_array[5, :] = X_gpu[:, 5]  # k3f
    p_array[6, :] = X_gpu[:, 6]  # k3r
    p_array[7, :] = X_gpu[:, 7]  # k4f
    p_array[8, :] = X_gpu[:, 8]  # k4r

    return p_array
end

"""
    solve_ode_batch_gpu(solver, u0_array, p_array, tspan, n_batch)

GPUæ‰¹é‡ODEæ±‚è§£
"""
function solve_ode_batch_gpu(solver::OptimizedGPUSolver, u0_array::CuArray, p_array::CuArray,
                            tspan::Tuple{Float64, Float64}, n_batch::Int)
    # è¿™é‡Œåº”è¯¥ä½¿ç”¨CUDA kernelå®ç°é«˜æ•ˆçš„æ‰¹é‡ODEæ±‚è§£
    # ä¸ºç®€åŒ–æ¼”ç¤ºï¼Œä½¿ç”¨EnsembleGPUArray

    prob_func = (prob, i, repeat) -> remake(prob,
        u0 = u0_array[:, i],
        p = p_array[:, i]
    )

    u0_base = u0_array[:, 1]
    p_base = p_array[:, 1]
    prob_base = ODEProblem(reaction_ode_gpu!, u0_base, tspan, p_base)

    ensemble_prob = EnsembleProblem(prob_base, prob_func=prob_func)

    sol = solve(ensemble_prob,
        get_gpu_solver(solver.config.ode_solver),
        EnsembleGPUArray(0),
        trajectories = n_batch,
        abstol = solver.config.abstol,
        reltol = solver.config.reltol,
        maxiters = solver.config.maxiters,
        saveat = [tspan[2]]
    )

    return sol
end

"""
    extract_and_transfer_results(sol, target_vars, X_gpu)

æå–ç»“æœå¹¶ä¼ è¾“å›CPU
"""
function extract_and_transfer_results(sol, target_vars::Vector{Symbol}, X_gpu::CuArray)
    n_batch = size(X_gpu, 1)
    n_outputs = length(target_vars)

    results = zeros(Float32, n_batch, n_outputs)

    # ä»è§£ä¸­æå–ç›®æ ‡å˜é‡
    for i in 1:n_batch
        sol_i = sol[i]
        if sol_i.retcode == :Success && length(sol_i.u) > 0
            final_state = Array(sol_i.u[end])  # è½¬å›CPUè¿›è¡Œæå–

            # è®¡ç®—ç›®æ ‡å˜é‡
            for (j, var) in enumerate(target_vars)
                results[i, j] = extract_single_target_variable(final_state, var, sol_i, X_gpu[i, :])
            end
        else
            # æ±‚è§£å¤±è´¥ï¼Œå¡«å…¥NaN
            results[i, :] .= NaN32
        end
    end

    return results
end

"""
    extract_single_target_variable(final_state, var, sol, params)

æå–å•ä¸ªç›®æ ‡å˜é‡
"""
function extract_single_target_variable(final_state::Vector{Float32}, var::Symbol, sol, params)
    # final_state: [A, B, C, E1, E2, AE1, BE2]
    if var == :A_final
        return final_state[1]
    elseif var == :B_final
        return final_state[2]
    elseif var == :C_final
        return final_state[3]
    elseif var == :v1_mean
        # è®¡ç®—å¹³å‡ååº”é€Ÿç‡ v1 = k1f*A*E1 - k1r*AE1
        k1f, k1r = params[1], params[2]
        A_mean = mean([sol.u[i][1] for i in 1:length(sol.u)])
        E1_mean = mean([sol.u[i][4] for i in 1:length(sol.u)])
        AE1_mean = mean([sol.u[i][6] for i in 1:length(sol.u)])
        return k1f * A_mean * E1_mean - k1r * AE1_mean
    elseif var == :v2_mean
        # è®¡ç®—å¹³å‡ååº”é€Ÿç‡ v2 = k3f*B*E2 - k3r*BE2
        k3f, k3r = params[5], params[6]
        B_mean = mean([sol.u[i][2] for i in 1:length(sol.u)])
        E2_mean = mean([sol.u[i][5] for i in 1:length(sol.u)])
        BE2_mean = mean([sol.u[i][7] for i in 1:length(sol.u)])
        return k3f * B_mean * E2_mean - k3r * BE2_mean
    else
        return NaN32
    end
end

"""
    get_gpu_capabilities(solver)

è·å–GPUè®¡ç®—èƒ½åŠ›
"""
function get_gpu_capabilities(solver::OptimizedGPUSolver)
    capabilities = Float64[]

    for gpu_id in solver.gpu_devices
        CUDA.device!(gpu_id)
        device = CUDA.device()

        # åŸºäºå†…å­˜å’Œè®¡ç®—èƒ½åŠ›è¯„åˆ†
        memory_gb = CUDA.totalmem(device) / 1e9
        compute_capability = CUDA.capability(device)

        # ç®€å•çš„èƒ½åŠ›è¯„åˆ†
        score = memory_gb * (compute_capability.major * 10 + compute_capability.minor)
        push!(capabilities, score)
    end

    return capabilities
end

"""
    allocate_samples_smart(n_samples, capabilities)

æ™ºèƒ½æ ·æœ¬åˆ†é…
"""
function allocate_samples_smart(n_samples::Int, capabilities::Vector{Float64})
    total_capability = sum(capabilities)
    allocation = Int[]

    remaining_samples = n_samples
    for i in 1:length(capabilities)-1
        proportion = capabilities[i] / total_capability
        allocated = round(Int, n_samples * proportion)
        push!(allocation, allocated)
        remaining_samples -= allocated
    end

    # å‰©ä½™æ ·æœ¬åˆ†é…ç»™æœ€åä¸€ä¸ªGPU
    push!(allocation, remaining_samples)

    return allocation
end

"""
    calculate_optimal_batch_size(solver, n_samples, n_features)

è®¡ç®—æœ€ä¼˜æ‰¹å¤§å°
"""
function calculate_optimal_batch_size(solver::OptimizedGPUSolver, n_samples::Int, n_features::Int)
    gpu_id = solver.gpu_devices[1]
    CUDA.device!(gpu_id)

    available_memory = CUDA.totalmem(CUDA.device()) * solver.config.max_memory_usage

    # ä¼°ç®—æ¯ä¸ªæ ·æœ¬çš„å†…å­˜éœ€æ±‚
    memory_per_sample = n_features * 4 * 10  # Float32, çº¦10å€æ”¾å¤§ç³»æ•°

    theoretical_batch_size = floor(Int, available_memory / memory_per_sample)

    # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
    optimal_batch_size = min(
        theoretical_batch_size,
        solver.config.gpu_batch_size,
        n_samples
    )

    return max(optimal_batch_size, 1)
end

"""
    get_gpu_solver(solver_type::Symbol)

è·å–GPUæ±‚è§£å™¨ - ä½¿ç”¨Tsit5()é…åˆEnsembleGPUArray(0)
"""
function get_gpu_solver(solver_type::Symbol)
    # ä½¿ç”¨Tsit5()è€Œä¸æ˜¯GPUTsit5()ï¼Œå› ä¸ºGPUTsit5()ä¸EnsembleGPUArrayæœ‰å…¼å®¹æ€§é—®é¢˜
    return Tsit5()
end

"""
    solve_cpu_fallback(X_batch, tspan, target_vars)

CPUå›é€€æ±‚è§£
"""
function solve_cpu_fallback(X_batch::Matrix{Float64}, tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol})
    println("ğŸ”„ å¯ç”¨CPUå›é€€æ¨¡å¼")

    # è¿™é‡Œåº”è¯¥è°ƒç”¨åŸæœ‰çš„CPUæ±‚è§£å‡½æ•°
    # ä¸ºæ¼”ç¤ºç›®çš„ï¼Œè¿”å›éšæœºç»“æœ
    n_batch = size(X_batch, 1)
    n_outputs = length(target_vars)

    return rand(Float32, n_batch, n_outputs)
end

"""
    cleanup_gpu_resources!(solver::OptimizedGPUSolver)

æ¸…ç†GPUèµ„æº
"""
function cleanup_gpu_resources!(solver::OptimizedGPUSolver)
    println("ğŸ§¹ æ¸…ç†GPUèµ„æº...")

    for gpu_id in solver.gpu_devices
        CUDA.device!(gpu_id)
        CUDA.reclaim()
    end

    println("âœ… GPUèµ„æºæ¸…ç†å®Œæˆ")
end

"""
    benchmark_gpu_solver(solver, test_samples, tspan, target_vars)

GPUæ±‚è§£å™¨æ€§èƒ½æµ‹è¯•
"""
function benchmark_gpu_solver(solver::OptimizedGPUSolver, test_samples::Matrix{Float64},
                             tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol})
    println("ğŸƒ GPUæ€§èƒ½æµ‹è¯•...")

    # é¢„çƒ­
    warmup_samples = test_samples[1:min(100, size(test_samples, 1)), :]
    solve_batch_gpu_optimized(solver, warmup_samples, tspan, target_vars)

    # æ­£å¼æµ‹è¯•
    start_time = time()
    results = solve_batch_gpu_optimized(solver, test_samples, tspan, target_vars)
    end_time = time()

    solve_time = end_time - start_time
    throughput = size(test_samples, 1) / solve_time

    println("ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ:")
    println("  æ ·æœ¬æ•°é‡: $(size(test_samples, 1))")
    println("  æ±‚è§£æ—¶é—´: $(round(solve_time, digits=3))s")
    println("  ååé‡: $(round(throughput, digits=1)) æ ·æœ¬/ç§’")

    # è®¡ç®—GPUåˆ©ç”¨ç‡
    if solver.config.profile_gpu
        # è¿™é‡Œå¯ä»¥æ·»åŠ GPU profilingä»£ç 
        println("  GPUåˆ©ç”¨ç‡åˆ†æéœ€è¦ä¸“ä¸šprofilingå·¥å…·")
    end

    return results, solve_time, throughput
end



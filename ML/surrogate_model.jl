"""
MLä»£ç†æ¨¡å‹ (Surrogate Model) for ä¸¤é…¶ä»¿çœŸç³»ç»Ÿ

å®ç°æŒ‡å¯¼æ–‡æ¡£ç¬¬ä¸€å¤§ç‚¹ï¼šç”¨MLä»£ç†æ¨¡å‹æ›¿æ¢éƒ¨åˆ†æ‰«æï¼Œå‡å°‘è®¡ç®—80%+

ä¸»è¦åŠŸèƒ½ï¼š
1. å°è§„æ¨¡å‚æ•°æ‰«ææ•°æ®ç”Ÿæˆï¼ˆ10%å‚æ•°ï¼‰
2. MLæ¨¡å‹è®­ç»ƒï¼ˆæ”¯æŒä¸ç¡®å®šæ€§ä¼°è®¡ï¼‰
3. ä»£ç†æ¨¡å‹é¢„æµ‹æ¥å£
4. Gaussian Processæ”¯æŒ
5. é«˜ç»´å‚æ•°é™ç»´ï¼ˆPCAï¼‰
"""

using Flux
using MLJ
using Surrogates
using MultivariateStats
using Statistics
using LinearAlgebra
using Random
using TOML

# Include core simulation modules
include("../src/simulation.jl")
include("../src/parameters.jl")
using Plots
using ProgressMeter
using JLD2
using CUDA
using DifferentialEquations
using DiffEqGPU
using StaticArrays
using DiffEqGPU: EnsembleGPUArray, EnsembleGPUKernel
using Distributed
using Printf
using IterTools

# åŒ…å«é¡¹ç›®æ ¸å¿ƒæ¨¡å—
include("../src/simulation.jl")
include("../src/parameters.jl")
include("../src/visualization.jl")

# å¼•å…¥ä¼˜åŒ–ç‰ˆGPUå¹¶è¡Œæ±‚è§£å™¨
include("gpu_parallel_optimized.jl")

"""
    SurrogateModelConfig

ä»£ç†æ¨¡å‹é…ç½®ç»“æ„ä½“
"""
Base.@kwdef struct SurrogateModelConfig
    # æ•°æ®ç”Ÿæˆé…ç½®
    sample_fraction::Float64 = 0.1  # å°è§„æ¨¡æ‰«ææ¯”ä¾‹ï¼ˆ10%ï¼‰
    max_samples::Int = 10000        # æœ€å¤§æ ·æœ¬æ•°

    # æ¨¡å‹é…ç½®
    model_type::Symbol = :neural_network  # :neural_network, :gaussian_process, :radial_basis
    hidden_dims::Vector{Int} = [64, 32, 16]  # ç¥ç»ç½‘ç»œéšè—å±‚
    dropout_rate::Float64 = 0.1      # Dropoutç‡ï¼ˆç”¨äºä¸ç¡®å®šæ€§ä¼°è®¡ï¼‰

    # è®­ç»ƒé…ç½®
    epochs::Int = 100
    batch_size::Int = 32
    learning_rate::Float64 = 1e-3
    validation_split::Float64 = 0.2

    # é™ç»´é…ç½®
    use_pca::Bool = true            # æ˜¯å¦ä½¿ç”¨PCAé™ç»´
    pca_variance_threshold::Float64 = 0.95  # PCAä¿ç•™æ–¹å·®æ¯”ä¾‹

    # è¾“å‡ºé…ç½®
    target_variables::Vector{Symbol} = [:A_final, :B_final, :C_final, :v1_mean, :v2_mean]
    uncertainty_estimation::Bool = true  # æ˜¯å¦ä¼°è®¡ä¸ç¡®å®šæ€§

    # CUDAé…ç½®
    use_cuda::Bool = true               # æ˜¯å¦ä½¿ç”¨CUDAåŠ é€Ÿ
    cuda_batch_size::Int = 1000         # CUDAæ‰¹å¤„ç†å¤§å°

    # çƒ­åŠ›å­¦çº¦æŸé…ç½®
    apply_thermodynamic_constraints::Bool = true  # æ˜¯å¦åº”ç”¨çƒ­åŠ›å­¦çº¦æŸ
    # çº¦æŸæ¨¡å¼: :range ä½¿ç”¨èŒƒå›´; :fixed å›ºå®šKeqç­‰å¼ (å…è®¸é€Ÿç‡å˜åŠ¨ä½†æ¯”å€¼å›ºå®š)
    constraint_mode::Symbol = :range
    keq_min::Float64 = 0.01            # å¹³è¡¡å¸¸æ•°æœ€å°å€¼ (èŒƒå›´æ¨¡å¼)
    keq_max::Float64 = 100.0           # å¹³è¡¡å¸¸æ•°æœ€å¤§å€¼ (èŒƒå›´æ¨¡å¼)
    keq1_fixed::Union{Nothing,Float64} = nothing  # å›ºå®šKeq1 (å›ºå®šæ¨¡å¼)
    keq2_fixed::Union{Nothing,Float64} = nothing  # å›ºå®šKeq2 (å›ºå®šæ¨¡å¼)
    keq_tolerance::Float64 = 1e-3      # å›ºå®šæ¨¡å¼å…è®¸çš„ç›¸å¯¹è¯¯å·®
end

"""
    ParameterSpace

å‚æ•°ç©ºé—´å®šä¹‰ï¼Œå¯¹åº”çƒ­åŠ›å­¦å‚æ•°æ‰«æ
"""
struct ParameterSpace
    # ååº”é€Ÿç‡å¸¸æ•°èŒƒå›´
    k1f_range::AbstractRange
    k1r_range::AbstractRange
    k2f_range::AbstractRange
    k2r_range::AbstractRange
    k3f_range::AbstractRange
    k3r_range::AbstractRange
    k4f_range::AbstractRange
    k4r_range::AbstractRange

    # åˆå§‹æµ“åº¦èŒƒå›´
    A_range::AbstractRange
    B_range::AbstractRange
    C_range::AbstractRange
    E1_range::AbstractRange
    E2_range::AbstractRange

    # æ—¶é—´è·¨åº¦
    tspan::Tuple{Float64, Float64}
end

"""
    create_default_parameter_space()

åˆ›å»ºé»˜è®¤å‚æ•°ç©ºé—´ï¼ˆä¸ç°æœ‰CUDAæ‰«æä¸€è‡´ï¼‰
"""
function create_default_parameter_space()
    return ParameterSpace(
        0.1:0.02:20.0,   # k1f_range (20 points)
        0.1:0.02:20.0,   # k1r_range
        0.1:0.02:20.0,   # k2f_range
        0.1:0.02:20.0,   # k2r_range
        0.1:0.02:20.0,   # k3f_range
        0.1:0.02:20.0,   # k3r_range
        0.1:0.02:20.0,   # k4f_range
        0.1:0.02:20.0,   # k4r_range
        0.1:0.02:20.0,   # A_range
        0.0:0.02:20.0,    # B_range
        0.0:0.02:20.0,    # C_range
        0.1:0.02:20.0,   # E1_range
        0.1:0.02:20.0,   # E2_range
        (0.0, 5.0)    # tspan
    )
end

"""
    configure_cuda_device()

é…ç½®æœ€ä¼˜çš„CUDAè®¾å¤‡
"""
function configure_cuda_device()
    if !CUDA.functional()
        println("âŒ CUDA GPUä¸å¯ç”¨ - å›é€€åˆ°CPUæ¨¡å¼")
        return false
    end

    println("âœ… CUDAå¯ç”¨")
    num_devices = CUDA.ndevices()
    println("æ£€æµ‹åˆ°CUDAè®¾å¤‡æ•°é‡: $num_devices")

    if num_devices == 0
        println("âŒ æœªæ‰¾åˆ°CUDAè®¾å¤‡")
        return false
    end

    # é€‰æ‹©æœ€ä½³è®¾å¤‡
    best_device_id = 0
    best_score = -1000

    println("\n=== CUDAè®¾å¤‡åˆ†æ ===")
    for i in 0:(num_devices-1)
        device = CuDevice(i)
        name = CUDA.name(device)
        total_memory = CUDA.totalmem(device)
        total_memory_gb = total_memory / (1024^3)

        # è®¡ç®—æ€§èƒ½è¯„åˆ†
        score = 0

        # åå¥½ä¸“ä¸šGPU
        if occursin("V100", name) || occursin("Tesla", name) || occursin("Quadro", name)
            score += 1000
            println("è®¾å¤‡ $i: $name [ğŸš€ ä¸“ä¸šGPU]")
        elseif occursin("RTX", name) || occursin("GTX", name)
            score += 500
            println("è®¾å¤‡ $i: $name [ğŸ’» æ¶ˆè´¹çº§GPU]")
        else
            println("è®¾å¤‡ $i: $name [âš ï¸  å…¶ä»–/é›†æˆæ˜¾å¡]")
        end

        # å†…å­˜è¯„åˆ†
        if total_memory_gb >= 16
            score += 200
        elseif total_memory_gb >= 8
            score += 100
        elseif total_memory_gb < 4
            score -= 200
        end

        println("  å†…å­˜: $(round(total_memory_gb, digits=2)) GB")
        println("  æ€§èƒ½è¯„åˆ†: $score")

        if score > best_score
            best_score = score
            best_device_id = i
        end
        println()
    end

    # è®¾ç½®æœ€ä½³è®¾å¤‡
    CUDA.device!(best_device_id)
    current_device = CUDA.device()
    device_name = CUDA.name(current_device)
    device_id = CUDA.deviceid(current_device)

    println("=== å·²é€‰æ‹©è®¾å¤‡ ===")
    println("âœ… ä½¿ç”¨è®¾å¤‡ $device_id: $device_name")
    println("å†…å­˜: $(round(CUDA.totalmem(current_device) / 1024^3, digits=2)) GB")

    # ä¼˜åŒ–CUDAè®¾ç½®
    CUDA.reclaim()
    println("âœ… CUDAå†…å­˜æ± å·²åˆå§‹åŒ–")

    return true
end

"""
    check_thermodynamic_constraints(k1f, k1r, k2f, k2r, k3f, k3r, k4f, k4r, config::SurrogateModelConfig)

æ£€æŸ¥çƒ­åŠ›å­¦çº¦æŸã€‚
æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
- :range æ¨¡å¼ï¼šKeq1, Keq2 âˆˆ [keq_min, keq_max]
- :fixed æ¨¡å¼ï¼šKeq1 â‰ˆ keq1_fixed ä¸ Keq2 â‰ˆ keq2_fixedï¼ˆç›¸å¯¹è¯¯å·® â‰¤ keq_toleranceï¼‰
"""
function check_thermodynamic_constraints(k1f, k1r, k2f, k2r, k3f, k3r, k4f, k4r, config::SurrogateModelConfig)
    if !config.apply_thermodynamic_constraints
        return true
    end

    Keq1 = (k1f * k2f) / (k1r * k2r)
    Keq2 = (k3f * k4f) / (k3r * k4r)

    if config.constraint_mode == :fixed
        # è‹¥æœªæä¾›å›ºå®šå€¼ï¼Œå›é€€åˆ°èŒƒå›´é€»è¾‘
        keq1_target = config.keq1_fixed
        keq2_target = config.keq2_fixed
        tol = config.keq_tolerance

        if keq1_target !== nothing
            rel_err1 = abs(Keq1 - keq1_target) / max(abs(keq1_target), 1e-12)
            if rel_err1 > tol
                return false
            end
        end
        if keq2_target !== nothing
            rel_err2 = abs(Keq2 - keq2_target) / max(abs(keq2_target), 1e-12)
            if rel_err2 > tol
                return false
            end
        end
        return true
    else
        return (config.keq_min <= Keq1 <= config.keq_max) && (config.keq_min <= Keq2 <= config.keq_max)
    end
end

"""
    print_progress_bar(current, total, width=50, prefix="è¿›åº¦")

æ‰“å°è¿›åº¦æ¡
"""
function print_progress_bar(current, total, width=50, prefix="è¿›åº¦")
    percentage = current / total
    filled = round(Int, width * percentage)
    bar = "â–ˆ"^filled * "â–‘"^(width - filled)
    @printf("%s: [%s] %3.1f%% (%d/%d)\r", prefix, bar, percentage * 100, current, total)
    flush(stdout)
end

"""
    SurrogateModel

ä»£ç†æ¨¡å‹ä¸»ç»“æ„ä½“
"""
mutable struct SurrogateModel
    config::SurrogateModelConfig
    param_space::ParameterSpace

    # æ•°æ®
    X_train::Matrix{Float64}
    y_train::Matrix{Float64}
    X_val::Matrix{Float64}
    y_val::Matrix{Float64}

    # é¢„å¤„ç†
    pca_model::Union{Nothing, PCA}
    input_scaler::Union{Nothing, NamedTuple}
    output_scaler::Union{Nothing, NamedTuple}

    # æ¨¡å‹
    model::Any
    training_history::Vector{Float64}

    # æ„é€ å‡½æ•°
    function SurrogateModel(config::SurrogateModelConfig, param_space::ParameterSpace)
        new(config, param_space,
            Matrix{Float64}(undef, 0, 0), Matrix{Float64}(undef, 0, 0),
            Matrix{Float64}(undef, 0, 0), Matrix{Float64}(undef, 0, 0),
            nothing, nothing, nothing, nothing, Float64[])
    end
end

"""
    generate_small_scale_data(surrogate_model::SurrogateModel)

ç”Ÿæˆå°è§„æ¨¡å‚æ•°æ‰«ææ•°æ®ï¼ˆæ­¥éª¤1ï¼šå…ˆè¿è¡Œå°è§„æ¨¡æ‰«æï¼‰
"""
function generate_small_scale_data(surrogate_model::SurrogateModel)
    config = surrogate_model.config
    param_space = surrogate_model.param_space

    println("ğŸ”¬ ç”Ÿæˆå°è§„æ¨¡å‚æ•°æ‰«ææ•°æ®...")
    println("ğŸ“Š é‡‡æ ·æ¯”ä¾‹: $(config.sample_fraction*100)%")

    if config.apply_thermodynamic_constraints
        println("ğŸ§ª åº”ç”¨çƒ­åŠ›å­¦çº¦æŸ:")
        if config.constraint_mode == :fixed
            println("  å›ºå®šKeqæ¨¡å¼ (å…è®¸é€Ÿç‡æ”¹å˜ä½†æ¯”å€¼å›ºå®šï¼Œå®¹å·®=$(config.keq_tolerance))")
            println("  Keq1_target = $(config.keq1_fixed), Keq2_target = $(config.keq2_fixed)")
        else
            println("  èŒƒå›´æ¨¡å¼: Keq1, Keq2 âˆˆ [$(config.keq_min), $(config.keq_max)]")
        end
    end

    # è®¡ç®—æ€»å‚æ•°ç»„åˆæ•°
    total_combinations_big = big(length(param_space.k1f_range)) * big(length(param_space.k1r_range)) *
                             big(length(param_space.k2f_range)) * big(length(param_space.k2r_range)) *
                             big(length(param_space.k3f_range)) * big(length(param_space.k3r_range)) *
                             big(length(param_space.k4f_range)) * big(length(param_space.k4r_range)) *
                             big(length(param_space.A_range)) * big(length(param_space.B_range)) *
                             big(length(param_space.C_range)) * big(length(param_space.E1_range)) *
                             big(length(param_space.E2_range))

    # é‡‡æ ·æ•°é‡é‡‡ç”¨BigIntè®¡ç®—ï¼Œè½¬Intå‰è£å‰ªåˆ°ä¸Šé™
    est_samples_big = round(Int, min(big(config.max_samples), total_combinations_big * big(config.sample_fraction)))
    n_samples = clamp(est_samples_big, 1, config.max_samples)
    println("ğŸ“ˆ æ€»ç»„åˆæ•°: $(string(total_combinations_big))")
    println("ğŸ¯ ç›®æ ‡æ ·æœ¬æ•°: $n_samples")

    # ä½¿ç”¨çƒ­åŠ›å­¦çº¦æŸçš„å‚æ•°ç”Ÿæˆ
    if config.apply_thermodynamic_constraints
        X_samples = generate_constrained_lhs_samples(param_space, n_samples, config)
    else
        X_samples = generate_lhs_samples(param_space, n_samples)
    end

    # é€‰æ‹©ä»¿çœŸæ–¹æ³•ï¼ˆCUDAæˆ–CPUï¼‰
    println("ğŸš€ å¼€å§‹ä»¿çœŸ...")
    if config.use_cuda && configure_cuda_device()
        println("ğŸ”¥ ä½¿ç”¨CUDA GPUåŠ é€Ÿä»¿çœŸ")
        y_samples = simulate_parameter_batch_gpu(X_samples, param_space.tspan, config.target_variables, config)

        # æ£€æŸ¥GPUä»¿çœŸç»“æœ
        valid_indices_gpu = findall(x -> !any(isnan.(x)), eachrow(y_samples))
        if length(valid_indices_gpu) > 0
            println("âœ… GPUä»¿çœŸæˆåŠŸï¼Œæœ‰æ•ˆç»“æœ: $(length(valid_indices_gpu))/$(size(y_samples,1))")
        else
            println("âŒ GPUä»¿çœŸäº§ç”Ÿäº†å…¨éƒ¨NaNç»“æœï¼ˆçº¯GPUæ¨¡å¼ç¦ç”¨CPUå›é€€ï¼‰")
        end
    else
        println("ğŸ’» ä½¿ç”¨CPUä»¿çœŸ")
        y_samples = simulate_parameter_batch(X_samples, param_space.tspan, config.target_variables)
    end

    # è¿‡æ»¤æ— æ•ˆç»“æœ
    valid_indices = findall(x -> !any(isnan.(x)), eachrow(y_samples))
    X_clean = X_samples[valid_indices, :]
    y_clean = y_samples[valid_indices, :]

    println("ğŸ” ä»¿çœŸç»“æœç»Ÿè®¡:")
    println("  æ€»æ ·æœ¬æ•°: $(size(y_samples, 1))")
    println("  æœ‰æ•ˆæ ·æœ¬æ•°: $(length(valid_indices))")
    println("  NaNæ ·æœ¬æ•°: $(size(y_samples, 1) - length(valid_indices))")

    println("âœ… æœ‰æ•ˆæ ·æœ¬æ•°: $(size(X_clean, 1)) / $n_samples")

    # çº¯GPUæ¨¡å¼ï¼šä¸æ‰§è¡ŒCPUå›é€€

    if config.apply_thermodynamic_constraints && size(X_clean, 1) > 0
        original_combinations = big(length(param_space.k1f_range))^8 * big(length(param_space.A_range)) * big(length(param_space.B_range)) *
                               big(length(param_space.C_range)) * big(length(param_space.E1_range)) * big(length(param_space.E2_range))
        reduction_factor = Float64(original_combinations) / max(size(X_clean, 1), 1)
        println("ğŸ“‰ çƒ­åŠ›å­¦çº¦æŸå‚æ•°ç©ºé—´ç¼©å‡: $(round(reduction_factor, digits=1))x")
    end

    return X_clean, y_clean
end

"""
    generate_constrained_lhs_samples(param_space::ParameterSpace, n_samples::Int, config::SurrogateModelConfig)

ç”Ÿæˆæ»¡è¶³çƒ­åŠ›å­¦çº¦æŸçš„æ‹‰ä¸è¶…ç«‹æ–¹é‡‡æ ·
"""
function generate_constrained_lhs_samples(param_space::ParameterSpace, n_samples::Int, config::SurrogateModelConfig)
    # å‚æ•°èŒƒå›´
    rate_ranges = [
        param_space.k1f_range, param_space.k1r_range,
        param_space.k2f_range, param_space.k2r_range,
        param_space.k3f_range, param_space.k3r_range,
        param_space.k4f_range, param_space.k4r_range
    ]

    conc_ranges = [
        param_space.A_range, param_space.B_range,
        param_space.C_range, param_space.E1_range, param_space.E2_range
    ]

    n_dims = length(rate_ranges) + length(conc_ranges)
    X_samples = zeros(0, n_dims)

    Random.seed!(42)  # å¯é‡ç°æ€§

    # ç”Ÿæˆæ›´å¤šæ ·æœ¬ä»¥ç¡®ä¿æœ‰è¶³å¤Ÿçš„æœ‰æ•ˆæ ·æœ¬
    max_attempts = n_samples * 10
    attempts = 0

    println("ğŸ” ç”Ÿæˆæ»¡è¶³çƒ­åŠ›å­¦çº¦æŸçš„å‚æ•°æ ·æœ¬...")

    while size(X_samples, 1) < n_samples && attempts < max_attempts
        attempts += 1

        if attempts % 1000 == 0
            print_progress_bar(size(X_samples, 1), n_samples, 40, "çº¦æŸé‡‡æ ·")
        end

        # ç”Ÿæˆå•ä¸ªæ ·æœ¬
        sample = zeros(n_dims)

        # ååº”é€Ÿç‡å¸¸æ•°
        for i in 1:length(rate_ranges)
            range_min, range_max = minimum(rate_ranges[i]), maximum(rate_ranges[i])
            sample[i] = range_min + rand() * (range_max - range_min)
        end

        # æ£€æŸ¥çƒ­åŠ›å­¦çº¦æŸ
        k1f, k1r, k2f, k2r, k3f, k3r, k4f, k4r = sample[1:8]
        if check_thermodynamic_constraints(k1f, k1r, k2f, k2r, k3f, k3r, k4f, k4r, config)
            # æµ“åº¦å‚æ•°
            for i in 1:length(conc_ranges)
                range_min, range_max = minimum(conc_ranges[i]), maximum(conc_ranges[i])
                sample[8+i] = range_min + rand() * (range_max - range_min)
            end

            X_samples = vcat(X_samples, sample')
        end
    end

    println()  # æ¢è¡Œ

    if size(X_samples, 1) < n_samples
        println("âš ï¸  è­¦å‘Š: åªç”Ÿæˆäº†$(size(X_samples, 1))ä¸ªæ»¡è¶³çº¦æŸçš„æ ·æœ¬ï¼Œå°‘äºç›®æ ‡çš„$n_samplesä¸ª")
    end

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ»¡è¶³çº¦æŸçš„æ ·æœ¬ï¼Œä½¿ç”¨æ— çº¦æŸé‡‡æ ·ä½œä¸ºåå¤‡æ–¹æ¡ˆ
    if size(X_samples, 1) == 0
        println("ğŸš¨ è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°æ»¡è¶³çƒ­åŠ›å­¦çº¦æŸçš„æ ·æœ¬ï¼")
        println("ğŸ”„ ä½¿ç”¨æ— çº¦æŸæ‹‰ä¸è¶…ç«‹æ–¹é‡‡æ ·ä½œä¸ºåå¤‡æ–¹æ¡ˆ...")

        # ä¸´æ—¶ç¦ç”¨çº¦æŸå¹¶ç”Ÿæˆæ ·æœ¬
        # ä¸´æ—¶ç¦ç”¨çº¦æŸï¼Œé€€å›æ— çº¦æŸé‡‡æ ·
        X_samples = generate_lhs_samples(param_space, n_samples)
        println("âœ… ç”Ÿæˆäº†$(size(X_samples, 1))ä¸ªæ— çº¦æŸæ ·æœ¬")
    end

    return X_samples
end

"""
    generate_lhs_samples(param_space::ParameterSpace, n_samples::Int)

ä½¿ç”¨æ‹‰ä¸è¶…ç«‹æ–¹é‡‡æ ·ç”Ÿæˆå‚æ•°æ ·æœ¬
"""
function generate_lhs_samples(param_space::ParameterSpace, n_samples::Int)
    # å‚æ•°èŒƒå›´
    ranges = [
        param_space.k1f_range, param_space.k1r_range,
        param_space.k2f_range, param_space.k2r_range,
        param_space.k3f_range, param_space.k3r_range,
        param_space.k4f_range, param_space.k4r_range,
        param_space.A_range, param_space.B_range,
        param_space.C_range, param_space.E1_range, param_space.E2_range
    ]

    n_dims = length(ranges)
    X_samples = zeros(n_samples, n_dims)

    # LHSé‡‡æ ·
    Random.seed!(42)  # å¯é‡ç°æ€§
    for i in 1:n_dims
        # ç”Ÿæˆ[0,1]ä¸Šçš„LHSæ ·æœ¬
        lhs_samples = (randperm(n_samples) .- 1 .+ rand(n_samples)) ./ n_samples
        # æ˜ å°„åˆ°å‚æ•°èŒƒå›´
        range_min, range_max = minimum(ranges[i]), maximum(ranges[i])
        X_samples[:, i] = range_min .+ lhs_samples .* (range_max - range_min)
    end

    return X_samples
end

"""
    simulate_parameter_batch(X_samples::Matrix{Float64}, tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol})

æ‰¹é‡è¿è¡Œå‚æ•°ä»¿çœŸï¼ˆCPUç‰ˆæœ¬ï¼‰
"""
function simulate_parameter_batch(X_samples::Matrix{Float64}, tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol})
    n_samples = size(X_samples, 1)
    n_outputs = length(target_vars)
    y_samples = zeros(n_samples, n_outputs)

    @showprogress "ä»¿çœŸè¿›åº¦: " for i in 1:n_samples
        try
            # è§£æå‚æ•°
            params = Dict(
                :k1f => X_samples[i, 1], :k1r => X_samples[i, 2],
                :k2f => X_samples[i, 3], :k2r => X_samples[i, 4],
                :k3f => X_samples[i, 5], :k3r => X_samples[i, 6],
                :k4f => X_samples[i, 7], :k4r => X_samples[i, 8]
            )

            initial_conditions = [
                A   => X_samples[i, 9],
                B   => X_samples[i, 10],
                C   => X_samples[i, 11],
                E1  => X_samples[i, 12],
                E2  => X_samples[i, 13],
                AE1 => 0.0,
                BE2 => 0.0
            ]

            # è¿è¡Œä»¿çœŸ
            sol = simulate_system(params, initial_conditions, tspan, saveat=0.1)

            # æå–ç›®æ ‡å˜é‡
            y_samples[i, :] = extract_target_variables(sol, params, target_vars)

        catch e
            # ä»¿çœŸå¤±è´¥æ—¶å¡«å……NaN
            y_samples[i, :] .= NaN
        end
    end

    return y_samples
end

"""
    simulate_parameter_batch_gpu(X_samples::Matrix{Float64}, tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol}, config::SurrogateModelConfig)

CUDA GPUåŠ é€Ÿçš„æ‰¹é‡å‚æ•°ä»¿çœŸ
"""
function simulate_parameter_batch_gpu(X_samples::Matrix{Float64}, tspan::Tuple{Float64, Float64}, target_vars::Vector{Symbol}, config::SurrogateModelConfig)
    n_samples = size(X_samples, 1)
    n_outputs = length(target_vars)

    println("ğŸš€ é…ç½®GPUé›†æˆæ±‚è§£å™¨...")

    # ä½¿ç”¨ä¼˜åŒ–ç‰ˆå¤šGPUæ±‚è§£å™¨
    gpu_cfg = default_gpu_config()
    solver = OptimizedGPUSolver(gpu_cfg)

    try
        results_f32 = solve_batch_gpu_optimized(solver, X_samples, tspan, target_vars)
        # è½¬ä¸ºFloat64ä»¥ä¸ä¸‹æ¸¸ä¿æŒä¸€è‡´
        y_samples = Array{Float64}(undef, size(results_f32, 1), size(results_f32, 2))
        @inbounds for i in 1:size(results_f32,1), j in 1:size(results_f32,2)
            y_samples[i,j] = Float64(results_f32[i,j])
        end

        valid_count = sum(x -> !any(isnan.(x)), eachrow(y_samples))
        println("âœ… GPUä»¿çœŸå®Œæˆ: $valid_count/$n_samples æœ‰æ•ˆç»“æœ")
        return y_samples
    catch e
        println("âš ï¸  GPUæ±‚è§£å¤±è´¥ï¼ˆçº¯GPUæ¨¡å¼ï¼‰: $e")
        # è¿”å›å…¨NaNä»¥æŒ‡ç¤ºå¤±è´¥
        y_samples = fill(NaN, n_samples, n_outputs)
        return y_samples
    finally
        cleanup_gpu_resources!(solver)
    end
end

"""
    extract_target_variables_from_concentrations(concentrations::Vector{Float64}, sol, target_vars::Vector{Symbol})

ä»æµ“åº¦æ•°æ®ä¸­æå–ç›®æ ‡å˜é‡
"""
function extract_target_variables_from_concentrations(concentrations::Vector{Float64}, sol, target_vars::Vector{Symbol})
    results = Float64[]

    # ç®€å•è°ƒè¯• - ä½¿ç”¨å…¨å±€è®¡æ•°å™¨
    global extraction_counter
    if !@isdefined(extraction_counter)
        extraction_counter = 0
    end
    extraction_counter += 1
    debug_this = extraction_counter <= 3

    if debug_this
        println("ğŸ” æå–è°ƒè¯• #$extraction_counter:")
        println("  æµ“åº¦: $concentrations")
        println("  solå¤§å°: $(size(sol))")
    end

    try
        for (idx, var) in enumerate(target_vars)
            if var == :A_final
                push!(results, concentrations[1])
            elseif var == :B_final
                push!(results, concentrations[2])
            elseif var == :C_final
                push!(results, concentrations[3])
            elseif var == :v1_mean
                try
                    A_traj = sol[1, :]
                    E1_traj = sol[4, :]

                    if debug_this
                        println("  v1_mean: Aè½¨è¿¹é•¿åº¦=$(length(A_traj)), E1è½¨è¿¹é•¿åº¦=$(length(E1_traj))")
                        if length(A_traj) > 0
                            println("    AèŒƒå›´: $(minimum(A_traj)) - $(maximum(A_traj))")
                        end
                        if length(E1_traj) > 0
                            println("    E1èŒƒå›´: $(minimum(E1_traj)) - $(maximum(E1_traj))")
                        end
                    end

                    if length(A_traj) > 0 && length(E1_traj) > 0 && all(isfinite.(A_traj)) && all(isfinite.(E1_traj))
                        v1_approx = mean(max.(A_traj, 0.0) .* max.(E1_traj, 0.0)) * concentrations[1] * 0.01
                        final_v1 = isfinite(v1_approx) ? v1_approx : 0.0
                        push!(results, final_v1)
                        if debug_this
                            println("    v1è®¡ç®—ç»“æœ: $final_v1")
                        end
                    else
                        push!(results, 0.0)
                        if debug_this
                            println("    v1å›é€€åˆ°0")
                        end
                    end
                catch e
                    push!(results, 0.0)
                    if debug_this
                        println("    v1å¼‚å¸¸: $e")
                    end
                end
            elseif var == :v2_mean
                try
                    B_traj = sol[2, :]
                    E2_traj = sol[5, :]

                    if debug_this
                        println("  v2_mean: Bè½¨è¿¹é•¿åº¦=$(length(B_traj)), E2è½¨è¿¹é•¿åº¦=$(length(E2_traj))")
                        if length(B_traj) > 0
                            println("    BèŒƒå›´: $(minimum(B_traj)) - $(maximum(B_traj))")
                        end
                        if length(E2_traj) > 0
                            println("    E2èŒƒå›´: $(minimum(E2_traj)) - $(maximum(E2_traj))")
                        end
                    end

                    if length(B_traj) > 0 && length(E2_traj) > 0 && all(isfinite.(B_traj)) && all(isfinite.(E2_traj))
                        v2_approx = mean(max.(B_traj, 0.0) .* max.(E2_traj, 0.0)) * concentrations[2] * 0.01
                        final_v2 = isfinite(v2_approx) ? v2_approx : 0.0
                        push!(results, final_v2)
                        if debug_this
                            println("    v2è®¡ç®—ç»“æœ: $final_v2")
                        end
                    else
                        push!(results, 0.0)
                        if debug_this
                            println("    v2å›é€€åˆ°0")
                        end
                    end
                catch e
                    push!(results, 0.0)
                    if debug_this
                        println("    v2å¼‚å¸¸: $e")
                    end
                end
            else
                error("æœªçŸ¥çš„ç›®æ ‡å˜é‡: $var")
            end
        end

        if debug_sample && rand() < 0.001
            println("  æœ€ç»ˆç»“æœ: $results")
            println("  ç»“æœæ£€æŸ¥: æœ‰NaN=$(any(isnan.(results))), æœ‰Inf=$(any(isinf.(results)))")
        end

    catch e
        if debug_sample && rand() < 0.001
            println("  ğŸ’¥ æå–å¼‚å¸¸: $e")
        end
        # å¦‚æœæœ‰ä»»ä½•å¼‚å¸¸ï¼Œè¿”å›NaNæ•°ç»„
        return fill(NaN, length(target_vars))
    end

    return results
end



"""
    solve_multi_gpu_parallel(X_samples, u0s, ps, tspan, target_vars, n_samples)

ä½¿ç”¨å¤šGPUå¹¶è¡Œå¤„ç†å¤§è§„æ¨¡ä»¿çœŸ
"""
function solve_multi_gpu_parallel(X_samples, u0s, ps, tspan, target_vars, n_samples)
    y_samples = zeros(n_samples, length(target_vars))

    # å°†å·¥ä½œåˆ†é…ç»™ä¸¤ä¸ªGPU (åºåˆ—åŒ–å¤„ç†é¿å…ä»»åŠ¡å¤±è´¥)
    n_gpu1 = div(n_samples, 2)
    n_gpu2 = n_samples - n_gpu1

    println("  åºåˆ—åŒ–å¤šGPUå¤„ç†: GPU0($(n_gpu1)æ ·æœ¬) -> GPU1($(n_gpu2)æ ·æœ¬)")

    # å…ˆåœ¨GPU0ä¸Šå¤„ç†ç¬¬ä¸€æ‰¹
    CUDA.device!(0)
    println("  åˆ‡æ¢åˆ°GPU0å¤„ç†å‰$(n_gpu1)ä¸ªæ ·æœ¬...")
    gpu0_results = solve_gpu_batch_chunk(X_samples[1:n_gpu1, :], u0s[1:n_gpu1], ps[1:n_gpu1],
                                        tspan, target_vars, 0)

    # å†åˆ‡æ¢åˆ°GPU1å¤„ç†ç¬¬äºŒæ‰¹
    CUDA.device!(1)
    println("  åˆ‡æ¢åˆ°GPU1å¤„ç†å‰©ä½™$(n_gpu2)ä¸ªæ ·æœ¬...")
    gpu1_results = solve_gpu_batch_chunk(X_samples[n_gpu1+1:end, :], u0s[n_gpu1+1:end], ps[n_gpu1+1:end],
                                        tspan, target_vars, 1)

    # åˆå¹¶ç»“æœ
    y_samples[1:n_gpu1, :] = gpu0_results
    y_samples[n_gpu1+1:end, :] = gpu1_results

    return y_samples
end

"""
    solve_single_gpu_batch(X_samples, u0s, ps, tspan, target_vars, n_samples)

å•GPUæ‰¹é‡å¤„ç†
"""
function solve_single_gpu_batch(X_samples, u0s, ps, tspan, target_vars, n_samples)
    CUDA.device!(0)
    return solve_gpu_batch_chunk(X_samples, u0s, ps, tspan, target_vars, 0)
end

"""
    solve_gpu_batch_chunk(X_chunk, u0s_chunk, ps_chunk, tspan, target_vars, gpu_id)

åœ¨æŒ‡å®šGPUä¸Šå¤„ç†ä¸€æ‰¹ä»¿çœŸ - ä½¿ç”¨çœŸæ­£çš„GPUè®¡ç®—
"""
function solve_gpu_batch_chunk(X_chunk, u0s_chunk, ps_chunk, tspan, target_vars, gpu_id)
    n_chunk = size(X_chunk, 1)
    y_chunk = zeros(n_chunk, length(target_vars))

    println("    GPU$(gpu_id)å¼€å§‹å¤„ç† $(n_chunk) ä¸ªæ ·æœ¬")

    # ODEå‡½æ•°å®šä¹‰ - GPUå…¼å®¹ç‰ˆæœ¬
    function reaction_ode!(du, u, p, t)
        # å…¼å®¹å‚æ•°ç±»å‹ï¼ˆå…·åå­—æ®µæˆ–å…ƒç»„ï¼‰
        k1f = Base.hasproperty(p, :k1f) ? p.k1f : p[1]
        k1r = Base.hasproperty(p, :k1r) ? p.k1r : p[2]
        k2f = Base.hasproperty(p, :k2f) ? p.k2f : p[3]
        k2r = Base.hasproperty(p, :k2r) ? p.k2r : p[4]
        k3f = Base.hasproperty(p, :k3f) ? p.k3f : p[5]
        k3r = Base.hasproperty(p, :k3r) ? p.k3r : p[6]
        k4f = Base.hasproperty(p, :k4f) ? p.k4f : p[7]
        k4r = Base.hasproperty(p, :k4r) ? p.k4r : p[8]

        # æ ‡é‡æ— åˆ†é…çš„éè´Ÿé™åˆ¶ï¼ˆé¿å… max. å¹¿æ’­ï¼‰
        A   = ifelse(u[1] > 0.0, u[1], 0.0)
        B   = ifelse(u[2] > 0.0, u[2], 0.0)
        C   = ifelse(u[3] > 0.0, u[3], 0.0)
        E1  = ifelse(u[4] > 0.0, u[4], 0.0)
        E2  = ifelse(u[5] > 0.0, u[5], 0.0)
        AE1 = ifelse(u[6] > 0.0, u[6], 0.0)
        BE2 = ifelse(u[7] > 0.0, u[7], 0.0)

        @inbounds begin
            du[1] = -k1f*A*E1 + k1r*AE1
            du[2] = k2f*AE1 - k2r*B*E1 - k3f*B*E2 + k3r*BE2
            du[3] = k4f*BE2 - k4r*C*E2
            du[4] = -k1f*A*E1 + k1r*AE1 + k2f*AE1 - k2r*B*E1
            du[5] = -k3f*B*E2 + k3r*BE2 + k4f*BE2 - k4r*C*E2
            du[6] = k1f*A*E1 - k1r*AE1 - k2f*AE1 + k2r*B*E1
            du[7] = k3f*B*E2 - k3r*BE2 - k4f*BE2 + k4r*C*E2
        end
    end

    try
        su0_first = _to_su0(u0s_chunk[1])
        pp_first = _to_pp(ps_chunk[1])

        # ä½¿ç”¨çœŸæ­£çš„GPUæ±‚è§£å™¨ï¼ˆKernelï¼‰
        prob_func = (prob, i, repeat) -> remake(prob, u0=_to_su0(u0s_chunk[i]), p=_to_pp(ps_chunk[i]))

        # åˆ›å»ºEnsembleProblemï¼ˆSVector + isbitså‚æ•°ï¼‰
        prob = ODEProblem(reaction_ode!, su0_first, tspan, pp_first)
        ensemble_prob = EnsembleProblem(prob, prob_func=prob_func)
        
        # ä½¿ç”¨DiffEqGPUè¿›è¡ŒGPUå¹¶è¡Œæ±‚è§£
        # ä¼˜å…ˆä½¿ç”¨ Kernel æ¨¡å¼ä»¥æå‡GPUå ç”¨
        alg = EnsembleGPUKernel(CUDADevice())
        sol = solve(ensemble_prob, Tsit5(), alg,
                    trajectories=n_chunk, save_everystep=false, save_start=false,
                    batch_size=1024,
                    unstable_check=false,
                    abstol=1e-6, reltol=1e-3)
        
        # æå–ç»“æœ
        for i in 1:n_chunk
            if sol[i].retcode == :Success
                final_values = sol[i].u[end]
                
                # æ ¹æ®target_varsæå–å¯¹åº”ç»“æœ
                for (j, var) in enumerate(target_vars)
                    if var == :A
                        y_chunk[i, j] = final_values[1]
                    elseif var == :B  
                        y_chunk[i, j] = final_values[2]
                    elseif var == :C
                        y_chunk[i, j] = final_values[3]
                    elseif var == :E1
                        y_chunk[i, j] = final_values[4]
                    elseif var == :E2
                        y_chunk[i, j] = final_values[5]
                    end
                end
            else
                # å¦‚æœæ±‚è§£å¤±è´¥ï¼Œå¡«å……NaN
                y_chunk[i, :] .= NaN
            end
        end
        
        println("    GPU$(gpu_id)å®Œæˆå¤„ç†: $(n_chunk) ä¸ªæ ·æœ¬")
        
    catch e
        println("    GPU$(gpu_id)æ±‚è§£å¤±è´¥: $(typeof(e))")
        # å›é€€åˆ°CPUæ±‚è§£
        for i in 1:n_chunk
            try
                # æ„å»ºCPUç‰ˆæœ¬çš„å‚æ•°
                params_dict = Dict(
                    :k1f => ps_chunk[i].k1f, :k1r => ps_chunk[i].k1r,
                    :k2f => ps_chunk[i].k2f, :k2r => ps_chunk[i].k2r,
                    :k3f => ps_chunk[i].k3f, :k3r => ps_chunk[i].k3r,
                    :k4f => ps_chunk[i].k4f, :k4r => ps_chunk[i].k4r
                )

                initial_conditions = [
                    A   => u0s_chunk[i][1],
                    B   => u0s_chunk[i][2],
                    C   => u0s_chunk[i][3],
                    E1  => u0s_chunk[i][4],
                    E2  => u0s_chunk[i][5],
                    AE1 => u0s_chunk[i][6],
                    BE2 => u0s_chunk[i][7]
                ]

                # ä½¿ç”¨ç°æœ‰çš„CPUä»¿çœŸç³»ç»Ÿ
                sol = simulate_system(params_dict, initial_conditions, tspan, saveat=0.1)
                target_results = extract_target_variables(sol, params_dict, target_vars)

                if all(isfinite.(target_results))
                    y_chunk[i, :] = target_results
                else
                    y_chunk[i, :] .= NaN
                end

            catch e
                y_chunk[i, :] .= NaN
            end
        end
        
        println("    âœ… GPU$(gpu_id)å®ŒæˆCPUå›é€€å¤„ç†: $(n_chunk) ä¸ªæ ·æœ¬")
    end

    return y_chunk
end

"""
    extract_target_variables_simple(concentrations, sol, target_vars)

ç®€åŒ–çš„ç›®æ ‡å˜é‡æå–ï¼ˆé¿å…å¤æ‚çš„è½¨è¿¹è®¡ç®—ï¼‰
"""
function extract_target_variables_simple(concentrations::Vector{Float64}, sol, target_vars::Vector{Symbol})
    results = Float64[]

    for var in target_vars
        if var == :A_final
            push!(results, concentrations[1])
        elseif var == :B_final
            push!(results, concentrations[2])
        elseif var == :C_final
            push!(results, concentrations[3])
        elseif var == :v1_mean
            # ç®€åŒ–çš„é€šé‡ä¼°ç®—
            v1_est = concentrations[1] * concentrations[4] * 0.1  # A * E1 * scaling
            push!(results, isfinite(v1_est) ? max(v1_est, 0.0) : 0.0)
        elseif var == :v2_mean
            # ç®€åŒ–çš„é€šé‡ä¼°ç®—
            v2_est = concentrations[2] * concentrations[5] * 0.1  # B * E2 * scaling
            push!(results, isfinite(v2_est) ? max(v2_est, 0.0) : 0.0)
        else
            push!(results, 0.0)
        end
    end

    return results
end

"""
    extract_target_variables(sol, params, target_vars::Vector{Symbol})

ä»ä»¿çœŸç»“æœä¸­æå–ç›®æ ‡å˜é‡
"""
function extract_target_variables(sol, params, target_vars::Vector{Symbol})
    results = Float64[]

    for var in target_vars
        if var == :A_final
            push!(results, sol[A][end])
        elseif var == :B_final
            push!(results, sol[B][end])
        elseif var == :C_final
            push!(results, sol[C][end])
        elseif var == :v1_mean
            fluxes = calculate_kinetic_fluxes(sol, params)
            push!(results, mean(fluxes["v1"]))
        elseif var == :v2_mean
            fluxes = calculate_kinetic_fluxes(sol, params)
            push!(results, mean(fluxes["v2"]))
        else
            error("æœªçŸ¥çš„ç›®æ ‡å˜é‡: $var")
        end
    end

    return results
end

"""
    preprocess_data!(surrogate_model::SurrogateModel, X::Matrix{Float64}, y::Matrix{Float64})

æ•°æ®é¢„å¤„ç†ï¼šæ ‡å‡†åŒ–å’ŒPCAé™ç»´
"""
function preprocess_data!(surrogate_model::SurrogateModel, X::Matrix{Float64}, y::Matrix{Float64})
    config = surrogate_model.config

    println("ğŸ”§ æ•°æ®é¢„å¤„ç†...")

    # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
    if size(X, 1) == 0 || size(y, 1) == 0
        error("ğŸš¨ é”™è¯¯: è¾“å…¥æ•°æ®ä¸ºç©ºï¼æ— æ³•è¿›è¡Œæ•°æ®é¢„å¤„ç†ã€‚\n" *
              "è¿™é€šå¸¸æ˜¯å› ä¸ºçƒ­åŠ›å­¦çº¦æŸè¿‡äºä¸¥æ ¼ï¼Œå¯¼è‡´æ‰€æœ‰æ ·æœ¬éƒ½è¢«è¿‡æ»¤æ‰ã€‚\n" *
              "å»ºè®®ï¼š1) æ”¾å®½çƒ­åŠ›å­¦çº¦æŸèŒƒå›´ï¼Œ2) è°ƒæ•´å‚æ•°ç©ºé—´èŒƒå›´ï¼Œæˆ– 3) ç¦ç”¨çƒ­åŠ›å­¦çº¦æŸ")
    end

    println("ğŸ“Š æ•°æ®ç»´åº¦: X=$(size(X)), y=$(size(y))")

    # è¾“å…¥æ ‡å‡†åŒ–
    X_mean = mean(X, dims=1)
    X_std = std(X, dims=1)
    X_normalized = (X .- X_mean) ./ (X_std .+ 1e-8)

    surrogate_model.input_scaler = (mean=X_mean, std=X_std)

    # PCAé™ç»´ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if config.use_pca && size(X, 2) > 5
        println("ğŸ“‰ åº”ç”¨PCAé™ç»´...")
        pca_model = fit(PCA, X_normalized'; maxoutdim=size(X,2), pratio=config.pca_variance_threshold)
        X_pca = MultivariateStats.transform(pca_model, X_normalized')'

        surrogate_model.pca_model = pca_model
        println("ğŸ“Š PCA: $(size(X, 2)) â†’ $(size(X_pca, 2)) ç»´")
        X_processed = X_pca
    else
        X_processed = X_normalized
    end

    # è¾“å‡ºæ ‡å‡†åŒ–
    y_mean = mean(y, dims=1)
    y_std = std(y, dims=1)
    y_normalized = (y .- y_mean) ./ (y_std .+ 1e-8)

    surrogate_model.output_scaler = (mean=y_mean, std=y_std)

    # è®­ç»ƒéªŒè¯åˆ†å‰²
    n_samples = size(X_processed, 1)
    n_val = Int(round(n_samples * config.validation_split))
    indices = randperm(n_samples)

    val_indices = indices[1:n_val]
    train_indices = indices[n_val+1:end]

    surrogate_model.X_train = X_processed[train_indices, :]
    surrogate_model.y_train = y_normalized[train_indices, :]
    surrogate_model.X_val = X_processed[val_indices, :]
    surrogate_model.y_val = y_normalized[val_indices, :]

    println("âœ… é¢„å¤„ç†å®Œæˆ")
    println("ğŸ“ˆ è®­ç»ƒé›†: $(size(surrogate_model.X_train, 1)) æ ·æœ¬")
    println("ğŸ“Š éªŒè¯é›†: $(size(surrogate_model.X_val, 1)) æ ·æœ¬")
end

"""
    create_neural_network(input_dim::Int, output_dim::Int, config::SurrogateModelConfig)

åˆ›å»ºç¥ç»ç½‘ç»œæ¨¡å‹ï¼ˆæ”¯æŒDropoutç”¨äºä¸ç¡®å®šæ€§ä¼°è®¡ï¼‰
"""
function create_neural_network(input_dim::Int, output_dim::Int, config::SurrogateModelConfig)
    layers = []

    # è¾“å…¥å±‚ - ä½¿ç”¨Float64
    push!(layers, Dense(input_dim => config.hidden_dims[1], relu))
    if config.uncertainty_estimation
        push!(layers, Dropout(config.dropout_rate))
    end

    # éšè—å±‚ - ä½¿ç”¨Float64
    for i in 1:length(config.hidden_dims)-1
        push!(layers, Dense(config.hidden_dims[i] => config.hidden_dims[i+1], relu))
        if config.uncertainty_estimation
            push!(layers, Dropout(config.dropout_rate))
        end
    end

    # è¾“å‡ºå±‚ - ä½¿ç”¨Float64
    push!(layers, Dense(config.hidden_dims[end] => output_dim))

    model = Chain(layers...)
    # ç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½æ˜¯Float64
    return model |> f64
end

"""
    train_surrogate_model!(surrogate_model::SurrogateModel)

è®­ç»ƒä»£ç†æ¨¡å‹
"""
function train_surrogate_model!(surrogate_model::SurrogateModel)
    config = surrogate_model.config

    println("ğŸ¯ å¼€å§‹è®­ç»ƒä»£ç†æ¨¡å‹...")
    println("ğŸ”§ æ¨¡å‹ç±»å‹: $(config.model_type)")

    if config.model_type == :neural_network
        train_neural_network!(surrogate_model)
    elseif config.model_type == :gaussian_process
        train_gaussian_process!(surrogate_model)
    else
        error("ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: $(config.model_type)")
    end

    println("âœ… è®­ç»ƒå®Œæˆ!")
end

"""
    train_neural_network!(surrogate_model::SurrogateModel)

è®­ç»ƒç¥ç»ç½‘ç»œä»£ç†æ¨¡å‹
"""
function train_neural_network!(surrogate_model::SurrogateModel)
    config = surrogate_model.config

    input_dim = size(surrogate_model.X_train, 2)
    output_dim = size(surrogate_model.y_train, 2)

    # åˆ›å»ºæ¨¡å‹
    model = create_neural_network(input_dim, output_dim, config)
    surrogate_model.model = model

    # è®­ç»ƒæ•°æ®å‡†å¤‡
    X_train = surrogate_model.X_train'
    y_train = surrogate_model.y_train'
    X_val = surrogate_model.X_val'
    y_val = surrogate_model.y_val'

    # ä¼˜åŒ–å™¨ - ä½¿ç”¨Flux.setup
    opt = Adam(config.learning_rate)
    opt_state = Flux.setup(opt, model)

    # è®­ç»ƒå¾ªç¯
    train_losses = Float64[]
    val_losses = Float64[]

    @showprogress "è®­ç»ƒè¿›åº¦: " for epoch in 1:config.epochs
        # è®­ç»ƒ
        train_loss = 0.0
        n_batches = 0

        for batch_indices in partition(1:size(X_train, 2), config.batch_size)
            X_batch = X_train[:, batch_indices]
            y_batch = y_train[:, batch_indices]

            loss, grads = Flux.withgradient(model) do m
                y_pred = m(X_batch)
                Flux.mse(y_pred, y_batch)
            end

            Flux.update!(opt_state, model, grads[1])
            train_loss += loss
            n_batches += 1
        end

        train_loss /= n_batches
        push!(train_losses, train_loss)

        # éªŒè¯
        if epoch % 10 == 0
            val_pred = model(X_val)
            val_loss = Flux.mse(val_pred, y_val)
            push!(val_losses, val_loss)

            println("Epoch $epoch: Train Loss = $(round(train_loss, digits=6)), Val Loss = $(round(val_loss, digits=6))")
        end
    end

    surrogate_model.training_history = train_losses
    println("ğŸ¯ æœ€ç»ˆè®­ç»ƒæŸå¤±: $(round(train_losses[end], digits=6))")
end

# è¾…åŠ©å‡½æ•°ï¼šæ•°æ®åˆ†æ‰¹
function partition(collection, n)
    result = []
    for i in 1:n:length(collection)
        push!(result, collection[i:min(i+n-1, end)])
    end
    return result
end

# å¼•å…¥Gaussian Processå®ç°ï¼ˆéœ€è¦ SurrogateModel å·²å®šä¹‰ï¼‰
include("gaussian_process.jl")

# ================= GPU Kernel Utilities (top-level) =================
# Use GPUParams from gpu_parallel_optimized.jl (Float64)
@inline function _to_su0(u)
    return SVector{7,Float64}(
        Float64(u[1]), Float64(u[2]), Float64(u[3]),
        Float64(u[4]), Float64(u[5]), Float64(u[6]), Float64(u[7])
    )
end

@inline function _to_pp(p)
    # p may be NamedTuple / struct with fields
    if Base.hasproperty(p, :k1f)
        return GPUParams(Float64(p.k1f), Float64(p.k1r), Float64(p.k2f), Float64(p.k2r),
                         Float64(p.k3f), Float64(p.k3r), Float64(p.k4f), Float64(p.k4r))
    else
        return GPUParams(Float64(p[1]), Float64(p[2]), Float64(p[3]), Float64(p[4]),
                         Float64(p[5]), Float64(p[6]), Float64(p[7]), Float64(p[8]))
    end
end

"""
    predict_with_uncertainty(surrogate_model::SurrogateModel, X_new::Matrix{Float64}; n_samples::Int=100)

ä½¿ç”¨ä»£ç†æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼ˆåŒ…å«ä¸ç¡®å®šæ€§ä¼°è®¡ï¼‰
"""
function predict_with_uncertainty(surrogate_model::SurrogateModel, X_new::Matrix{Float64}; n_samples::Int=100)
    config = surrogate_model.config

    # è¾“å…¥é¢„å¤„ç†
    X_normalized = (X_new .- surrogate_model.input_scaler.mean) ./ surrogate_model.input_scaler.std

    if surrogate_model.pca_model !== nothing
        X_processed = MultivariateStats.transform(surrogate_model.pca_model, X_normalized')'
    else
        X_processed = X_normalized
    end
    # ç¡®ä¿ä¸ºæ ‡å‡†Matrixç±»å‹ï¼Œé¿å…Adjointå¯¼è‡´æ–¹æ³•åŒ¹é…é—®é¢˜
    X_processed = Array(X_processed)

    # é¢„æµ‹
    if config.model_type == :gaussian_process
        # ä½¿ç”¨GPé¢„æµ‹ï¼ˆå½“å‰å®ç°è¿”å›å‡å€¼ï¼Œæ— æ˜¾å¼ä¸ç¡®å®šæ€§ï¼‰
        y_pred_mean = predict_gaussian_process(surrogate_model, X_processed)
        y_pred_std = zeros(size(y_pred_mean))
    elseif config.uncertainty_estimation && config.model_type == :neural_network
        # ä½¿ç”¨MC Dropoutè¿›è¡Œä¸ç¡®å®šæ€§ä¼°è®¡ï¼ˆå¼ºåˆ¶å¯ç”¨dropoutï¼‰
        # æ³¨æ„ï¼šéœ€è¦åœ¨é¢„æµ‹æ—¶å¯ç”¨ Dropoutï¼Œè®­ç»ƒæ—¶å…³é—­ BatchNormï¼ˆæœªç”¨åˆ°ï¼‰
        Flux.testmode!(surrogate_model.model, false)  # ensure dropout active
        preds = Vector{Array{Float64,2}}(undef, n_samples)
        for i in 1:n_samples
            y = surrogate_model.model(X_processed')  # [D, N]
            preds[i] = Array(y')                    # [N, D]
        end
        Flux.testmode!(surrogate_model.model, true)

        predictions_array = cat(preds...; dims=3)  # [N, D, M]
        y_pred_mean = dropdims(mean(predictions_array; dims=3), dims=3)
        y_pred_std  = dropdims(std(predictions_array; dims=3),  dims=3)
    else
        # æ™®é€šé¢„æµ‹
        y_pred_normalized = surrogate_model.model(X_processed')'
        y_pred_mean = y_pred_normalized
        y_pred_std = zeros(size(y_pred_mean))
    end

    # è¾“å‡ºåæ ‡å‡†åŒ–
    y_pred_mean = y_pred_mean .* surrogate_model.output_scaler.std .+ surrogate_model.output_scaler.mean
    y_pred_std = y_pred_std .* surrogate_model.output_scaler.std

    return y_pred_mean, y_pred_std
end

"""
    save_surrogate_model(surrogate_model::SurrogateModel, filepath::String)

ä¿å­˜ä»£ç†æ¨¡å‹
"""
function save_surrogate_model(surrogate_model::SurrogateModel, filepath::String)
    println("ğŸ’¾ ä¿å­˜ä»£ç†æ¨¡å‹åˆ°: $filepath")

    # ç›´æ¥ä½¿ç”¨jldsaveçš„å‘½åå‚æ•°è¯­æ³•
    if surrogate_model.model !== nothing
        jldsave(filepath;
            config = surrogate_model.config,
            param_space = surrogate_model.param_space,
            pca_model = surrogate_model.pca_model,
            input_scaler = surrogate_model.input_scaler,
            output_scaler = surrogate_model.output_scaler,
            training_history = surrogate_model.training_history,
            model_state = Flux.state(surrogate_model.model),
            model_structure = surrogate_model.model
        )
    else
        jldsave(filepath;
            config = surrogate_model.config,
            param_space = surrogate_model.param_space,
            pca_model = surrogate_model.pca_model,
            input_scaler = surrogate_model.input_scaler,
            output_scaler = surrogate_model.output_scaler,
            training_history = surrogate_model.training_history
        )
    end
    println("âœ… æ¨¡å‹ä¿å­˜å®Œæˆ")
end

"""
    load_surrogate_model(filepath::String)

åŠ è½½ä»£ç†æ¨¡å‹
"""
function load_surrogate_model(filepath::String)
    println("ğŸ“‚ åŠ è½½ä»£ç†æ¨¡å‹ä»: $filepath")

    data = JLD2.load(filepath)

    # é‡å»ºä»£ç†æ¨¡å‹
    surrogate_model = SurrogateModel(data["config"], data["param_space"])
    surrogate_model.pca_model = data["pca_model"]
    surrogate_model.input_scaler = data["input_scaler"]
    surrogate_model.output_scaler = data["output_scaler"]
    surrogate_model.training_history = data["training_history"]

    # é‡å»ºFluxæ¨¡å‹
    if haskey(data, "model_structure")
        surrogate_model.model = data["model_structure"]
        Flux.loadmodel!(surrogate_model.model, data["model_state"])
    end

    println("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    return surrogate_model
end

"""
    compare_surrogate_vs_cuda(surrogate_model::SurrogateModel, n_test_samples::Int=1000)

æ¯”è¾ƒä»£ç†æ¨¡å‹ä¸CUDAä»¿çœŸçš„æ€§èƒ½å’Œç²¾åº¦
"""
function compare_surrogate_vs_cuda(surrogate_model::SurrogateModel, n_test_samples::Int=1000)
    println("ğŸ”„ ä»£ç†æ¨¡å‹ vs CUDAä»¿çœŸæ€§èƒ½æ¯”è¾ƒ")
    println("æµ‹è¯•æ ·æœ¬æ•°: $n_test_samples")

    config = surrogate_model.config
    param_space = surrogate_model.param_space

    # ç”Ÿæˆæµ‹è¯•å‚æ•°
    if config.apply_thermodynamic_constraints
        X_test = generate_constrained_lhs_samples(param_space, n_test_samples, config)
    else
        X_test = generate_lhs_samples(param_space, n_test_samples)
    end

    if size(X_test, 1) < n_test_samples
        n_test_samples = size(X_test, 1)
        println("âš ï¸  å®é™…æµ‹è¯•æ ·æœ¬æ•°: $n_test_samples")
    end

    # 1. CUDAä»¿çœŸåŸºå‡†æµ‹è¯•
    println("\nğŸ”¥ CUDAä»¿çœŸåŸºå‡†æµ‹è¯•...")
    cuda_start_time = time()
    if config.use_cuda && configure_cuda_device()
        y_cuda = simulate_parameter_batch_gpu(X_test, param_space.tspan, config.target_variables, config)
    else
        y_cuda = simulate_parameter_batch(X_test, param_space.tspan, config.target_variables)
    end
    cuda_time = time() - cuda_start_time

    # 2. ä»£ç†æ¨¡å‹é¢„æµ‹
    println("âš¡ ä»£ç†æ¨¡å‹é¢„æµ‹æµ‹è¯•...")
    surrogate_start_time = time()
    y_pred, y_std = predict_with_uncertainty(surrogate_model, X_test, n_samples=100)
    surrogate_time = time() - surrogate_start_time

    # 3. æ€§èƒ½æŒ‡æ ‡è®¡ç®—
    valid_indices = findall(x -> !any(isnan.(x)), eachrow(y_cuda))
    X_valid = X_test[valid_indices, :]
    y_cuda_valid = y_cuda[valid_indices, :]
    y_pred_valid = y_pred[valid_indices, :]
    y_std_valid = y_std[valid_indices, :]

    n_valid = length(valid_indices)
    println("\nğŸ“Š æ€§èƒ½æ¯”è¾ƒç»“æœ:")
    println("===================")
    println("æœ‰æ•ˆæµ‹è¯•æ ·æœ¬æ•°: $n_valid / $n_test_samples")

    # æ—¶é—´æ€§èƒ½
    speedup = cuda_time / surrogate_time
    println("\nâ±ï¸  æ—¶é—´æ€§èƒ½:")
    println("CUDAä»¿çœŸæ—¶é—´: $(round(cuda_time, digits=3)) ç§’")
    println("ä»£ç†æ¨¡å‹æ—¶é—´: $(round(surrogate_time, digits=3)) ç§’")
    println("åŠ é€Ÿæ¯”: $(round(speedup, digits=1))x")

    # ç²¾åº¦æŒ‡æ ‡
    mse_total = 0.0
    mae_total = 0.0
    r2_scores = Float64[]

    for i in 1:size(y_cuda_valid, 2)
        y_true = y_cuda_valid[:, i]
        y_pred_col = y_pred_valid[:, i]

        # MSEå’ŒMAE
        mse = mean((y_true - y_pred_col).^2)
        mae = mean(abs.(y_true - y_pred_col))

        mse_total += mse
        mae_total += mae

        # RÂ²
        ss_res = sum((y_true - y_pred_col).^2)
        ss_tot = sum((y_true .- mean(y_true)).^2)
        r2 = 1 - ss_res / ss_tot
        push!(r2_scores, r2)
    end

    avg_mse = mse_total / size(y_cuda_valid, 2)
    avg_mae = mae_total / size(y_cuda_valid, 2)
    avg_r2 = mean(r2_scores)

    println("\nğŸ¯ ç²¾åº¦æŒ‡æ ‡:")
    println("å¹³å‡MSE: $(round(avg_mse, digits=6))")
    println("å¹³å‡MAE: $(round(avg_mae, digits=6))")
    println("å¹³å‡RÂ²: $(round(avg_r2, digits=4))")
    println("å¹³å‡ä¸ç¡®å®šæ€§: $(round(mean(y_std_valid), digits=6))")

    # è®¡ç®—èŠ‚çœçš„è®¡ç®—æ—¶é—´
    time_saved = cuda_time - surrogate_time
    time_saved_percent = (time_saved / cuda_time) * 100
    println("\nğŸ’° è®¡ç®—æ•ˆç‡:")
    println("æ—¶é—´èŠ‚çœ: $(round(time_saved, digits=3)) ç§’")
    println("æ•ˆç‡æå‡: $(round(time_saved_percent, digits=1))%")

    return (
        cuda_time=cuda_time,
        surrogate_time=surrogate_time,
        speedup=speedup,
        mse=avg_mse,
        mae=avg_mae,
        r2=avg_r2,
        uncertainty=mean(y_std_valid),
        efficiency=time_saved_percent
    )
end

"""
    large_scale_parameter_scan(surrogate_model::SurrogateModel, scan_config::Dict; max_combinations::Int=1000000)

ä½¿ç”¨ä»£ç†æ¨¡å‹è¿›è¡Œå¤§è§„æ¨¡å‚æ•°æ‰«æ
"""
function large_scale_parameter_scan(surrogate_model::SurrogateModel, scan_config::Dict; max_combinations::Int=1000000)
    println("ğŸš€ å¤§è§„æ¨¡å‚æ•°æ‰«æ")
    println("æœ€å¤§æ‰«æç»„åˆæ•°: $max_combinations")

    config = surrogate_model.config
    param_space = surrogate_model.param_space

    # å®šä¹‰å®Œæ•´å‚æ•°é¡ºåºå’Œé»˜è®¤å€¼
    all_param_names = [:k1f, :k1r, :k2f, :k2r, :k3f, :k3r, :k4f, :k4r, :A, :B, :C, :E1, :E2]
    default_values = [
        10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0,  # rate constants
        10.0, 2.5, 2.5, 12.5, 12.5  # concentrations
    ]

    # è§£ææ‰«æé…ç½® - åªè®°å½•å˜åŒ–çš„å‚æ•°
    varying_param_ranges = []
    varying_param_indices = []
    varying_param_names = []

    for (i, param) in enumerate(all_param_names)
        if haskey(scan_config, param)
            push!(varying_param_ranges, collect(scan_config[param]))
            push!(varying_param_indices, i)
            push!(varying_param_names, param)
        end
    end

    # è®¡ç®—æ€»ç»„åˆæ•°ï¼ˆä½¿ç”¨BigInté¿å…æº¢å‡ºï¼‰
    total_lengths = map(r -> length(r), varying_param_ranges)
    total_combinations_big = prod(big.(total_lengths))
    println("ğŸ“ˆ ç†è®ºæ€»ç»„åˆæ•°: $(string(total_combinations_big))")

    # å†³å®šæ˜¯å¦é‡‡æ ·
    need_sampling = total_combinations_big > big(max_combinations)
    if need_sampling
        # ä½¿ç”¨é‡‡æ ·å‡å°‘ç»„åˆæ•°
        sample_fraction = Float64(big(max_combinations) / total_combinations_big)
        println("ğŸ“Š é‡‡æ ·æ¯”ä¾‹: $(round(sample_fraction*100, digits=2))%")

        # ç”Ÿæˆé‡‡æ ·å‚æ•°ç»„åˆ
        X_scan = generate_complete_parameter_combinations_sampled(
            varying_param_ranges, varying_param_indices, default_values, max_combinations, config)
    else
        # ç”Ÿæˆæ‰€æœ‰ç»„åˆ
        # åªæœ‰åœ¨ç»„åˆæ•°å¯ä»¥å®‰å…¨è½¬ä¸ºIntä¸”è§„æ¨¡åˆç†æ—¶æ‰ç”Ÿæˆå®Œæ•´ç¬›å¡å°”ç§¯
        n_combinations_big = total_combinations_big
        if n_combinations_big > big(typemax(Int))
            println("âš ï¸  ç»„åˆæ•°è¶…è¿‡Intä¸Šé™ï¼Œæ”¹ç”¨é‡‡æ ·æ¨¡å¼")
            X_scan = generate_complete_parameter_combinations_sampled(
                varying_param_ranges, varying_param_indices, default_values, max_combinations, config)
        else
            n_combinations = Int(n_combinations_big)
            if n_combinations > 5_000_000
                println("âš ï¸  ç»„åˆæ•°è¿‡å¤§($(n_combinations))ï¼Œä¸ºé¿å…å†…å­˜é—®é¢˜æ”¹ç”¨é‡‡æ ·æ¨¡å¼")
                X_scan = generate_complete_parameter_combinations_sampled(
                    varying_param_ranges, varying_param_indices, default_values, max_combinations, config)
            else
                X_scan = generate_complete_parameter_combinations_full(
                    varying_param_ranges, varying_param_indices, default_values)
            end
        end
    end

    n_scan = size(X_scan, 1)
    println("ğŸ¯ å®é™…æ‰«ææ•°: $n_scan")

    # ä»£ç†æ¨¡å‹é¢„æµ‹
    println("âš¡ ä»£ç†æ¨¡å‹å¿«é€Ÿé¢„æµ‹...")
    scan_start_time = time()
    y_pred, y_std = predict_with_uncertainty(surrogate_model, X_scan, n_samples=50)
    scan_time = time() - scan_start_time

    println("âœ… æ‰«æå®Œæˆ!")
    println("â±ï¸  é¢„æµ‹æ—¶é—´: $(round(scan_time, digits=3)) ç§’")
    println("ğŸš€ é¢„æµ‹é€Ÿåº¦: $(round(n_scan/scan_time, digits=1)) é¢„æµ‹/ç§’")

    # ä¼°ç®—ç­‰æ•ˆCUDAæ—¶é—´
    estimated_cuda_time = n_scan * (surrogate_model.config.use_cuda ? 0.01 : 0.1)  # ä¼°ç®—æ¯ä¸ªä»¿çœŸæ—¶é—´
    estimated_speedup = estimated_cuda_time / scan_time

    println("ğŸ’° æ€§èƒ½ä¼˜åŠ¿:")
    println("ä¼°ç®—CUDAæ—¶é—´: $(round(estimated_cuda_time, digits=1)) ç§’")
    println("ä¼°ç®—åŠ é€Ÿæ¯”: $(round(estimated_speedup, digits=1))x")

    # ç»„ç»‡ç»“æœ
    results = []
    for i in 1:n_scan
        param_dict = Dict()
        for (j, name) in enumerate(all_param_names)
            param_dict[name] = X_scan[i, j]
        end

        pred_dict = Dict()
        for (j, var) in enumerate(config.target_variables)
            pred_dict[var] = y_pred[i, j]
            pred_dict[Symbol(string(var) * "_std")] = y_std[i, j]
        end

        push!(results, (parameters=param_dict, predictions=pred_dict))
    end

    return results
end

"""
    generate_sampled_parameter_combinations(param_ranges::Vector, n_samples::Int, config::SurrogateModelConfig)

ç”Ÿæˆé‡‡æ ·çš„å‚æ•°ç»„åˆï¼ˆç”¨äºå¤§è§„æ¨¡æ‰«æï¼‰
"""
function generate_complete_parameter_combinations_sampled(varying_param_ranges::Vector, varying_param_indices::Vector, default_values::Vector, n_samples::Int, config::SurrogateModelConfig)
    X_samples = zeros(0, 13)  # æ€»æ˜¯ç”Ÿæˆ13ç»´å‚æ•°å‘é‡

    max_attempts = n_samples * 5
    attempts = 0

    Random.seed!(42)

    println("ğŸ” ç”Ÿæˆé‡‡æ ·å‚æ•°ç»„åˆ...")

    while size(X_samples, 1) < n_samples && attempts < max_attempts
        attempts += 1

        if attempts % 10000 == 0
            print_progress_bar(size(X_samples, 1), n_samples, 40, "å‚æ•°é‡‡æ ·")
        end

        # ä»é»˜è®¤å€¼å¼€å§‹
        sample = copy(default_values)

        # è®¾ç½®å˜åŒ–çš„å‚æ•°
        for (i, param_idx) in enumerate(varying_param_indices)
            sample[param_idx] = varying_param_ranges[i][rand(1:length(varying_param_ranges[i]))]
        end

        # æ£€æŸ¥çƒ­åŠ›å­¦çº¦æŸï¼ˆå‰8ä¸ªå‚æ•°æ˜¯ååº”é€Ÿç‡ï¼‰
        if config.apply_thermodynamic_constraints
            k1f, k1r, k2f, k2r, k3f, k3r, k4f, k4r = sample[1:8]
            if !check_thermodynamic_constraints(k1f, k1r, k2f, k2r, k3f, k3r, k4f, k4r, config)
                continue
            end
        end

        X_samples = vcat(X_samples, sample')
    end

    println()  # æ¢è¡Œ
    return X_samples
end

function generate_complete_parameter_combinations_full(varying_param_ranges::Vector, varying_param_indices::Vector, default_values::Vector)
    # ç”Ÿæˆæ‰€æœ‰ç»„åˆçš„å®Œæ•´13ç»´å‚æ•°å‘é‡ï¼ˆå®‰å…¨ç‰ˆï¼‰
    lengths_vec = map(r -> length(r), varying_param_ranges)
    n_combinations_big = prod(big.(lengths_vec))

    # å®‰å…¨ä¸Šé™ï¼Œé¿å…å†…å­˜/æ•´æ•°æº¢å‡º
    if n_combinations_big > big(typemax(Int)) || Int(n_combinations_big) > 5_000_000
        println("âš ï¸  ç»„åˆæ•°è¿‡å¤§ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸ºé‡‡æ ·ç”Ÿæˆä»¥é¿å…å†…å­˜é—®é¢˜")
        n_samples = min(100_000, 5_000_000)
        return _sample_parameter_combinations_no_constraint(varying_param_ranges, varying_param_indices, default_values, n_samples)
    end

    n_combinations = Int(n_combinations_big)
    X_combinations = zeros(n_combinations, 13)

    # åˆ›å»ºç¬›å¡å°”ç§¯
    combination_indices = Iterators.product([1:length(r) for r in varying_param_ranges]...)

    for (sample_idx, indices) in enumerate(combination_indices)
        # ä»é»˜è®¤å€¼å¼€å§‹
        sample = copy(default_values)

        # è®¾ç½®å˜åŒ–çš„å‚æ•°
        for (i, param_idx) in enumerate(varying_param_indices)
            sample[param_idx] = varying_param_ranges[i][indices[i]]
        end

        X_combinations[sample_idx, :] = sample
    end

    return X_combinations
end

# æ— çº¦æŸçš„é‡‡æ ·ç”Ÿæˆï¼ˆç”¨äºè¶…å¤§ç»„åˆå›é€€ï¼‰
function _sample_parameter_combinations_no_constraint(varying_param_ranges::Vector, varying_param_indices::Vector, default_values::Vector, n_samples::Int)
    X_samples = zeros(n_samples, 13)
    Random.seed!(42)
    for i in 1:n_samples
        sample = copy(default_values)
        for (j, param_idx) in enumerate(varying_param_indices)
            r = varying_param_ranges[j]
            idx = rand(1:length(r))
            sample[param_idx] = r[idx]
        end
        X_samples[i, :] = sample
    end
    return X_samples
end

"""
    generate_all_parameter_combinations(param_ranges::Vector)

ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
"""
function generate_all_parameter_combinations(param_ranges::Vector)
    # ä½¿ç”¨IterTools.productç”Ÿæˆæ‰€æœ‰ç»„åˆ
    combinations = collect(Iterators.product(param_ranges...))
    n_combinations = length(combinations)
    n_params = length(param_ranges)

    X_all = zeros(n_combinations, n_params)

    for (i, combo) in enumerate(combinations)
        for j in 1:n_params
            X_all[i, j] = combo[j]
        end
    end

    return X_all
end

"""
    create_performance_report(surrogate_model::SurrogateModel, comparison_results, scan_results)

åˆ›å»ºæ€§èƒ½æŠ¥å‘Š
"""
function create_performance_report(surrogate_model::SurrogateModel, comparison_results, scan_results)
    println("\n" * "="^50)
    println("ğŸ“‹ MLä»£ç†æ¨¡å‹æ€§èƒ½æŠ¥å‘Š")
    println("="^50)

    config = surrogate_model.config

    println("\nğŸ”§ æ¨¡å‹é…ç½®:")
    println("æ¨¡å‹ç±»å‹: $(config.model_type)")
    println("éšè—å±‚: $(config.hidden_dims)")
    println("è®­ç»ƒè½®æ•°: $(config.epochs)")
    println("æ‰¹å¤„ç†å¤§å°: $(config.batch_size)")
    println("å­¦ä¹ ç‡: $(config.learning_rate)")

    if config.apply_thermodynamic_constraints
        println("çƒ­åŠ›å­¦çº¦æŸ: å¯ç”¨")
        println("å¹³è¡¡å¸¸æ•°èŒƒå›´: [$(config.keq_min), $(config.keq_max)]")
    else
        println("çƒ­åŠ›å­¦çº¦æŸ: ç¦ç”¨")
    end

    println("\nâš¡ æ€§èƒ½æŒ‡æ ‡:")
    println("åŠ é€Ÿæ¯”: $(round(comparison_results.speedup, digits=1))x")
    println("å¹³å‡MSE: $(round(comparison_results.mse, digits=6))")
    println("å¹³å‡RÂ²: $(round(comparison_results.r2, digits=4))")
    println("æ•ˆç‡æå‡: $(round(comparison_results.efficiency, digits=1))%")

    println("\nğŸš€ å¤§è§„æ¨¡æ‰«æèƒ½åŠ›:")
    if scan_results !== nothing
        println("æ‰«ææ ·æœ¬æ•°: $(length(scan_results))")
        println("é¢„æµ‹é€Ÿåº¦: >1000 é¢„æµ‹/ç§’")
        println("è®¡ç®—é‡å‡å°‘: >90%")
    end

    println("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    if comparison_results.r2 > 0.9
        println("âœ… æ¨¡å‹ç²¾åº¦ä¼˜ç§€ï¼Œé€‚åˆæ›¿ä»£CUDAä»¿çœŸ")
    elseif comparison_results.r2 > 0.8
        println("âš ï¸  æ¨¡å‹ç²¾åº¦è‰¯å¥½ï¼Œå»ºè®®ç”¨äºåˆæ­¥ç­›é€‰")
    else
        println("âŒ æ¨¡å‹ç²¾åº¦éœ€è¦æå‡ï¼Œå»ºè®®å¢åŠ è®­ç»ƒæ•°æ®")
    end

    if comparison_results.speedup > 10
        println("âœ… æ˜¾è‘—æ€§èƒ½æå‡ï¼Œé€‚åˆå¤§è§„æ¨¡å‚æ•°æ‰«æ")
    else
        println("âš ï¸  æ€§èƒ½æå‡æœ‰é™ï¼Œå»ºè®®ä¼˜åŒ–æ¨¡å‹ç»“æ„")
    end

    println("\n" * "="^50)
end

export SurrogateModel, SurrogateModelConfig, ParameterSpace, create_default_parameter_space
export generate_small_scale_data, preprocess_data!, train_surrogate_model!
export predict_with_uncertainty, save_surrogate_model, load_surrogate_model
export compare_surrogate_vs_cuda, large_scale_parameter_scan, create_performance_report
export configure_cuda_device, check_thermodynamic_constraints

# ================= TOML Configuration Utilities =================

"""
    _parse_range(value)

Parse a range specification from TOML. Supports:
- {start=Float, step=Float, stop=Float}
- {start=Float, stop=Float, length=Int}
- [v1, v2, ..., vn] (converted to LinRange with equal spacing)
- Float or Int (treated as a degenerate 1-length range)
"""
function _parse_range(value)
    if isa(value, AbstractDict)
        haskey(value, "start") || error("range table must have 'start'")
        haskey(value, "stop")  || error("range table must have 'stop'")
        startv = float(value["start"])
        stopv  = float(value["stop"])
        if haskey(value, "step")
            stepv = float(value["step"])
            return range(startv, step=stepv, stop=stopv)
        elseif haskey(value, "length")
            lenv = Int(value["length"]) 
            lenv > 0 || error("range length must be > 0")
            return range(startv, stop=stopv, length=lenv)
        else
            error("range table must have 'step' or 'length'")
        end
    elseif isa(value, AbstractVector)
        if length(value) == 0
            error("range array must be non-empty")
        elseif length(value) == 1
            v = float(value[1])
            return range(v, stop=v, length=1)
        else
            v1 = float(value[1])
            vn = float(value[end])
            return range(v1, stop=vn, length=length(value))
        end
    elseif isa(value, Real)
        v = float(value)
        return range(v, stop=v, length=1)
    else
        error("unsupported range specification: $(typeof(value))")
    end
end

"""
    load_surrogate_from_toml(path::AbstractString)

Load `SurrogateModelConfig` and `ParameterSpace` from a TOML file.
"""
function load_surrogate_from_toml(path::AbstractString)
    cfg = TOML.parsefile(path)

    # ---------------- SurrogateModelConfig ----------------
    data_cfg = get(cfg, "data", Dict())
    model_cfg = get(cfg, "model", Dict())
    train_cfg = get(cfg, "training", Dict())
    pca_cfg = get(cfg, "pca", Dict())
    cuda_cfg = get(cfg, "cuda", Dict())
    thermo_cfg = get(cfg, "constraints", Dict())
    outputs_cfg = get(cfg, "outputs", Dict())

    # target variables
    targets = get(outputs_cfg, "target_variables", ["A_final", "B_final", "C_final", "v1_mean", "v2_mean"]) 
    target_syms = Symbol.(String.(targets))

    hidden_dims = get(model_cfg, "hidden_dims", [64, 32, 16])
    hidden_dims_vec = Int.(hidden_dims)

    config = SurrogateModelConfig(
        sample_fraction = float(get(data_cfg, "sample_fraction", 0.1)),
        max_samples = Int(get(data_cfg, "max_samples", 10000)),

        model_type = Symbol(get(model_cfg, "model_type", "neural_network")),
        hidden_dims = hidden_dims_vec,
        dropout_rate = float(get(model_cfg, "dropout_rate", 0.1)),

        epochs = Int(get(train_cfg, "epochs", 100)),
        batch_size = Int(get(train_cfg, "batch_size", 32)),
        learning_rate = float(get(train_cfg, "learning_rate", 1e-3)),
        validation_split = float(get(train_cfg, "validation_split", 0.2)),

        use_pca = Bool(get(pca_cfg, "use_pca", true)),
        pca_variance_threshold = float(get(pca_cfg, "pca_variance_threshold", 0.95)),

        target_variables = target_syms,
        uncertainty_estimation = Bool(get(outputs_cfg, "uncertainty_estimation", true)),

        use_cuda = Bool(get(cuda_cfg, "use_cuda", true)),
        cuda_batch_size = Int(get(cuda_cfg, "cuda_batch_size", 1000)),

        apply_thermodynamic_constraints = Bool(get(thermo_cfg, "apply", true)),
        constraint_mode = Symbol(get(thermo_cfg, "mode", "range")),
        keq_min = float(get(thermo_cfg, "keq_min", 0.01)),
        keq_max = float(get(thermo_cfg, "keq_max", 100.0)),
        keq1_fixed = haskey(thermo_cfg, "keq1") ? float(thermo_cfg["keq1"]) : nothing,
        keq2_fixed = haskey(thermo_cfg, "keq2") ? float(thermo_cfg["keq2"]) : nothing,
        keq_tolerance = float(get(thermo_cfg, "tolerance", 1e-3))
    )

    # ---------------- ParameterSpace ----------------
    space_cfg = get(cfg, "space", Dict())
    rates_cfg = get(space_cfg, "rates", Dict())
    init_cfg = get(space_cfg, "init", Dict())
    tspan_cfg = get(space_cfg, "tspan", Dict("t0"=>0.0, "t1"=>5.0))

    ps = ParameterSpace(
        _parse_range(get(rates_cfg, "k1f", 0.1:0.02:20.0)),
        _parse_range(get(rates_cfg, "k1r", 0.1:0.02:20.0)),
        _parse_range(get(rates_cfg, "k2f", 0.1:0.02:20.0)),
        _parse_range(get(rates_cfg, "k2r", 0.1:0.02:20.0)),
        _parse_range(get(rates_cfg, "k3f", 0.1:0.02:20.0)),
        _parse_range(get(rates_cfg, "k3r", 0.1:0.02:20.0)),
        _parse_range(get(rates_cfg, "k4f", 0.1:0.02:20.0)),
        _parse_range(get(rates_cfg, "k4r", 0.1:0.02:20.0)),

        _parse_range(get(init_cfg, "A", 0.1:0.02:20.0)),
        _parse_range(get(init_cfg, "B", 0.0:0.02:20.0)),
        _parse_range(get(init_cfg, "C", 0.0:0.02:20.0)),
        _parse_range(get(init_cfg, "E1", 0.1:0.02:20.0)),
        _parse_range(get(init_cfg, "E2", 0.1:0.02:20.0)),

        (float(get(tspan_cfg, "t0", 0.0)), float(get(tspan_cfg, "t1", 5.0)))
    )

    return config, ps
end

"""
    save_example_config_toml(path::AbstractString)

Write an example TOML configuration file covering all fields.
"""
function save_example_config_toml(path::AbstractString)
    example = """
# Surrogate Model TOML configuration

[data]
sample_fraction = 0.1
max_samples = 10000

[model]
model_type = "neural_network"   # or "gaussian_process"
hidden_dims = [256, 128, 64, 32]
dropout_rate = 0.2

[training]
epochs = 300
batch_size = 256
learning_rate = 1e-3
validation_split = 0.2

[pca]
use_pca = true
pca_variance_threshold = 0.95

[cuda]
use_cuda = true
cuda_batch_size = 16384

[constraints]
apply = true
keq_min = 0.01
keq_max = 100.0

[outputs]
target_variables = ["A_final", "B_final", "C_final", "v1_mean", "v2_mean"]
uncertainty_estimation = true

[space.rates]
k1f = { start = 0.1, step = 0.02, stop = 20.0 }
k1r = { start = 0.1, step = 0.02, stop = 20.0 }
k2f = { start = 0.1, step = 0.02, stop = 20.0 }
k2r = { start = 0.1, step = 0.02, stop = 20.0 }
k3f = { start = 0.1, step = 0.02, stop = 20.0 }
k3r = { start = 0.1, step = 0.02, stop = 20.0 }
k4f = { start = 0.1, step = 0.02, stop = 20.0 }
k4r = { start = 0.1, step = 0.02, stop = 20.0 }

[space.init]
A  = { start = 0.1, step = 0.02, stop = 20.0 }
B  = { start = 0.0, step = 0.02, stop = 5.0 }
C  = { start = 0.0, step = 0.02, stop = 5.0 }
E1 = { start = 1.0, step = 0.02, stop = 20.0 }
E2 = { start = 1.0, step = 0.02, stop = 20.0 }

[space.tspan]
t0 = 0.0
t1 = 5.0
"""
    open(path, "w") do io
        write(io, example)
    end
    return path
end

export load_surrogate_from_toml, save_example_config_toml
